components:
  schemas:
    AudioFileBinary:
      description: Audio file to transcribe
      format: binary
      type: string
    AudioFileUrl:
      description: Public HTTPS URL to audio file
      format: uri
      type: string
    AudioSpeechRequest:
      properties:
        input:
          description: Input text to generate the audio for
          type: string
        language:
          default: en
          description: Language of input text
          enum:
            - en
            - de
            - fr
            - es
            - hi
            - it
            - ja
            - ko
            - nl
            - pl
            - pt
            - ru
            - sv
            - tr
            - zh
          type: string
        model:
          anyOf:
            - enum:
                - cartesia/sonic
              type: string
            - type: string
          description: |
            The name of the model to query.<br> <br> [See all of Together AI's chat models](https://docs.together.ai/docs/serverless-models#audio-models)
          example: cartesia/sonic
        response_encoding:
          default: pcm_f32le
          description: Audio encoding of response
          enum:
            - pcm_f32le
            - pcm_s16le
            - pcm_mulaw
            - pcm_alaw
          type: string
        response_format:
          default: wav
          description: The format of audio output
          enum:
            - mp3
            - wav
            - raw
          type: string
        sample_rate:
          default: 44100
          description: Sampling rate to use for the output audio
          type: number
        stream:
          default: false
          description: "If true, output is streamed for several characters at a time instead of waiting for the full response. The stream terminates with `data: [DONE]`. If false, return the encoded audio as octet stream"
          type: boolean
        voice:
          anyOf:
            - enum:
                - laidback woman
                - polite man
                - storyteller lady
                - friendly sidekick
              type: string
            - type: string
          description: The voice to use for generating the audio. [View all supported voices here](https://docs.together.ai/docs/text-to-speech#voices-available).
      required:
        - model
        - input
        - voice
      type: object
    AudioSpeechStreamChunk:
      properties:
        b64:
          description: base64 encoded audio stream
          type: string
        model:
          example: cartesia/sonic
          type: string
        object:
          enum:
            - audio.tts.chunk
          type: string
      required:
        - object
        - model
        - b64
      type: object
    AudioSpeechStreamEvent:
      properties:
        data:
          $ref: "#/components/schemas/AudioSpeechStreamChunk"
      required:
        - data
      type: object
    AudioSpeechStreamResponse:
      oneOf:
        - $ref: "#/components/schemas/AudioSpeechStreamEvent"
        - $ref: "#/components/schemas/StreamSentinel"
    AudioTranscriptionJsonResponse:
      properties:
        text:
          description: The transcribed text
          example: Hello, world!
          type: string
      required:
        - text
      type: object
    AudioTranscriptionRequest:
      properties:
        file:
          description: Audio file upload or public HTTP/HTTPS URL. Supported formats .wav, .mp3, .m4a, .webm, .flac.
          oneOf:
            - $ref: "#/components/schemas/AudioFileBinary"
            - $ref: "#/components/schemas/AudioFileUrl"
        language:
          default: en
          description: Optional ISO 639-1 language code. If `auto` is provided, language is auto-detected.
          example: en
          type: string
        model:
          default: openai/whisper-large-v3
          description: Model to use for transcription
          enum:
            - openai/whisper-large-v3
          type: string
        prompt:
          description: Optional text to bias decoding.
          type: string
        response_format:
          default: json
          description: The format of the response
          enum:
            - json
            - verbose_json
          type: string
        temperature:
          default: 0.0
          description: Sampling temperature between 0.0 and 1.0
          format: float
          maximum: 1.0
          minimum: 0.0
          type: number
        timestamp_granularities:
          default: segment
          description: Controls level of timestamp detail in verbose_json. Only used when response_format is verbose_json. Can be a single granularity or an array to get multiple levels.
          example:
            - word
            - segment
          oneOf:
            - enum:
                - segment
                - word
              type: string
            - items:
                enum:
                  - segment
                  - word
                type: string
              maxItems: 2
              minItems: 1
              type: array
              uniqueItems: true
      required:
        - file
      type: object
    AudioTranscriptionResponse:
      oneOf:
        - $ref: "#/components/schemas/AudioTranscriptionJsonResponse"
        - $ref: "#/components/schemas/AudioTranscriptionVerboseJsonResponse"
    AudioTranscriptionSegment:
      properties:
        end:
          description: End time of the segment in seconds
          example: 3.5
          format: float
          type: number
        id:
          description: Unique identifier for the segment
          example: 0
          type: integer
        start:
          description: Start time of the segment in seconds
          example: 0.0
          format: float
          type: number
        text:
          description: The text content of the segment
          example: Hello, world!
          type: string
      required:
        - id
        - start
        - end
        - text
      type: object
    AudioTranscriptionVerboseJsonResponse:
      properties:
        duration:
          description: The duration of the audio in seconds
          example: 3.5
          format: float
          type: number
        language:
          description: The language of the audio
          example: english
          type: string
        segments:
          description: Array of transcription segments
          items:
            $ref: "#/components/schemas/AudioTranscriptionSegment"
          type: array
        task:
          description: The task performed
          enum:
            - transcribe
            - translate
          example: transcribe
          type: string
        text:
          description: The transcribed text
          example: Hello, world!
          type: string
        words:
          description: Array of transcription words (only when timestamp_granularities includes 'word')
          items:
            $ref: "#/components/schemas/AudioTranscriptionWord"
          type: array
      required:
        - task
        - language
        - duration
        - text
        - segments
      type: object
    AudioTranscriptionWord:
      properties:
        end:
          description: End time of the word in seconds
          example: 0.5
          format: float
          type: number
        start:
          description: Start time of the word in seconds
          example: 0.0
          format: float
          type: number
        word:
          description: The word
          example: Hello
          type: string
      required:
        - word
        - start
        - end
      type: object
    AudioTranslationJsonResponse:
      properties:
        text:
          description: The translated text
          example: Hello, world!
          type: string
      required:
        - text
      type: object
    AudioTranslationRequest:
      properties:
        file:
          description: Audio file upload or public HTTP/HTTPS URL. Supported formats .wav, .mp3, .m4a, .webm, .flac.
          oneOf:
            - description: Audio file to translate
              format: binary
              type: string
            - description: Public HTTP/HTTPS URL to audio file
              format: uri
              type: string
        language:
          default: en
          description: Target output language. Optional ISO 639-1 language code. If omitted, language is set to English.
          example: en
          type: string
        model:
          default: openai/whisper-large-v3
          description: Model to use for translation
          enum:
            - openai/whisper-large-v3
          type: string
        prompt:
          description: Optional text to bias decoding.
          type: string
        response_format:
          default: json
          description: The format of the response
          enum:
            - json
            - verbose_json
          type: string
        temperature:
          default: 0.0
          description: Sampling temperature between 0.0 and 1.0
          format: float
          maximum: 1.0
          minimum: 0.0
          type: number
        timestamp_granularities:
          default: segment
          description: Controls level of timestamp detail in verbose_json. Only used when response_format is verbose_json. Can be a single granularity or an array to get multiple levels.
          example:
            - word
            - segment
          oneOf:
            - enum:
                - segment
                - word
              type: string
            - items:
                enum:
                  - segment
                  - word
                type: string
              maxItems: 2
              minItems: 1
              type: array
              uniqueItems: true
      required:
        - file
      type: object
    AudioTranslationResponse:
      oneOf:
        - $ref: "#/components/schemas/AudioTranslationJsonResponse"
        - $ref: "#/components/schemas/AudioTranslationVerboseJsonResponse"
    AudioTranslationVerboseJsonResponse:
      properties:
        duration:
          description: The duration of the audio in seconds
          example: 3.5
          format: float
          type: number
        language:
          description: The target language of the translation
          example: english
          type: string
        segments:
          description: Array of translation segments
          items:
            $ref: "#/components/schemas/AudioTranscriptionSegment"
          type: array
        task:
          description: The task performed
          enum:
            - transcribe
            - translate
          example: translate
          type: string
        text:
          description: The translated text
          example: Hello, world!
          type: string
        words:
          description: Array of translation words (only when timestamp_granularities includes 'word')
          items:
            $ref: "#/components/schemas/AudioTranscriptionWord"
          type: array
      required:
        - task
        - language
        - duration
        - text
        - segments
      type: object
    Autoscaling:
      description: Configuration for automatic scaling of replicas based on demand.
      properties:
        max_replicas:
          description: The maximum number of replicas to scale up to under load
          examples:
            - 5
          format: int32
          type: integer
        min_replicas:
          description: The minimum number of replicas to maintain, even when there is no load
          examples:
            - 2
          format: int32
          type: integer
      required:
        - min_replicas
        - max_replicas
      type: object
    BatchErrorResponse:
      properties:
        error:
          type: string
      type: object
    BatchJob:
      properties:
        completed_at:
          example: "2024-01-15T15:45:30Z"
          format: date-time
          type: string
        created_at:
          example: "2024-01-15T14:30:00Z"
          format: date-time
          type: string
        endpoint:
          example: /v1/chat/completions
          type: string
        error:
          type: string
        error_file_id:
          example: file-errors456def789jkl
          type: string
        file_size_bytes:
          description: Size of input file in bytes
          example: 1048576
          format: int64
          type: integer
        id:
          example: 01234567-8901-2345-6789-012345678901
          format: uuid
          type: string
        input_file_id:
          example: file-input123abc456def
          type: string
        job_deadline:
          example: "2024-01-15T15:30:00Z"
          format: date-time
          type: string
        model_id:
          description: Model used for processing requests
          example: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
          type: string
        output_file_id:
          example: file-output789xyz012ghi
          type: string
        progress:
          description: Completion progress (0.0 to 100)
          example: 75.0
          format: float64
          type: number
        status:
          $ref: "#/components/schemas/BatchJobStatus"
        user_id:
          example: user_789xyz012
          type: string
      type: object
    BatchJobStatus:
      description: Current status of the batch job
      enum:
        - VALIDATING
        - IN_PROGRESS
        - COMPLETED
        - FAILED
        - EXPIRED
        - CANCELLED
      example: IN_PROGRESS
      type: string
    BatchJobWithWarning:
      properties:
        job:
          $ref: "#/components/schemas/BatchJob"
        warning:
          type: string
      type: object
    ChatCompletionAssistantMessageParam:
      properties:
        content:
          nullable: true
          type: string
        function_call:
          deprecated: true
          properties:
            arguments:
              type: string
            name:
              type: string
          required:
            - arguments
            - name
          type: object
        name:
          type: string
        role:
          enum:
            - assistant
          type: string
        tool_calls:
          items:
            $ref: "#/components/schemas/ToolChoice"
          type: array
      required:
        - role
      type: object
    ChatCompletionChoice:
      properties:
        delta:
          properties:
            content:
              nullable: true
              type: string
            function_call:
              deprecated: true
              nullable: true
              properties:
                arguments:
                  type: string
                name:
                  type: string
              required:
                - arguments
                - name
              type: object
            reasoning:
              nullable: true
              type: string
            role:
              enum:
                - system
                - user
                - assistant
                - function
                - tool
              type: string
            token_id:
              type: integer
            tool_calls:
              items:
                $ref: "#/components/schemas/ToolChoice"
              type: array
          required:
            - role
          title: ChatCompletionChoiceDelta
          type: object
        finish_reason:
          $ref: "#/components/schemas/FinishReason"
        index:
          type: integer
        logprobs:
          $ref: "#/components/schemas/LogprobsPart"
      required:
        - index
        - delta
        - finish_reason
      type: object
    ChatCompletionChoicesData:
      items:
        properties:
          finish_reason:
            $ref: "#/components/schemas/FinishReason"
          index:
            type: integer
          logprobs:
            allOf:
              - nullable: true
              - $ref: "#/components/schemas/LogprobsPart"
          message:
            $ref: "#/components/schemas/ChatCompletionMessage"
          seed:
            type: integer
          text:
            type: string
        type: object
      type: array
    ChatCompletionChunk:
      properties:
        choices:
          items:
            properties:
              delta:
                properties:
                  content:
                    nullable: true
                    type: string
                  function_call:
                    deprecated: true
                    nullable: true
                    properties:
                      arguments:
                        type: string
                      name:
                        type: string
                    required:
                      - arguments
                      - name
                    type: object
                  role:
                    enum:
                      - system
                      - user
                      - assistant
                      - function
                      - tool
                    type: string
                  token_id:
                    type: integer
                  tool_calls:
                    items:
                      $ref: "#/components/schemas/ToolChoice"
                    type: array
                required:
                  - role
                title: ChatCompletionChoiceDelta
                type: object
              finish_reason:
                $ref: "#/components/schemas/FinishReason"
                nullable: true
              index:
                type: integer
              logprobs:
                nullable: true
                type: number
              seed:
                nullable: true
                type: integer
            required:
              - index
              - delta
              - finish_reason
            type: object
          title: ChatCompletionChoices
          type: array
        created:
          type: integer
        id:
          type: string
        model:
          example: mistralai/Mixtral-8x7B-Instruct-v0.1
          type: string
        object:
          enum:
            - chat.completion.chunk
          type: string
        system_fingerprint:
          type: string
        usage:
          allOf:
            - $ref: "#/components/schemas/UsageData"
            - nullable: true
        warnings:
          items:
            $ref: "#/components/schemas/InferenceWarning"
          type: array
      required:
        - id
        - object
        - created
        - choices
        - model
      type: object
    ChatCompletionEvent:
      properties:
        data:
          $ref: "#/components/schemas/ChatCompletionChunk"
      required:
        - data
      type: object
    ChatCompletionFunctionMessageParam:
      deprecated: true
      properties:
        content:
          type: string
        name:
          type: string
        role:
          enum:
            - function
          type: string
      required:
        - content
        - role
        - name
      type: object
    ChatCompletionMessage:
      properties:
        content:
          nullable: true
          type: string
        function_call:
          deprecated: true
          properties:
            arguments:
              type: string
            name:
              type: string
          required:
            - arguments
            - name
          type: object
        reasoning:
          nullable: true
          type: string
        role:
          enum:
            - assistant
          type: string
        tool_calls:
          items:
            $ref: "#/components/schemas/ToolChoice"
          type: array
      required:
        - role
        - content
      type: object
    ChatCompletionMessageParam:
      oneOf:
        - $ref: "#/components/schemas/ChatCompletionSystemMessageParam"
        - $ref: "#/components/schemas/ChatCompletionUserMessageParam"
        - $ref: "#/components/schemas/ChatCompletionAssistantMessageParam"
        - $ref: "#/components/schemas/ChatCompletionToolMessageParam"
        - $ref: "#/components/schemas/ChatCompletionFunctionMessageParam"
    ChatCompletionRequest:
      properties:
        context_length_exceeded_behavior:
          default: error
          description: Defined the behavior of the API when max_tokens exceed the maximum context length of the model. When set to 'error', API will return 400 with appropriate error message. When set to 'truncate', override the max_tokens with maximum context length of the model.
          enum:
            - truncate
            - error
          type: string
        echo:
          description: If true, the response will contain the prompt. Can be used with `logprobs` to return prompt logprobs.
          type: boolean
        frequency_penalty:
          description: A number between -2.0 and 2.0 where a positive value decreases the likelihood of repeating tokens that have already been mentioned.
          format: float
          type: number
        function_call:
          oneOf:
            - enum:
                - none
                - auto
              type: string
            - properties:
                name:
                  type: string
              required:
                - name
              type: object
        logit_bias:
          additionalProperties:
            format: float
            type: number
          description: Adjusts the likelihood of specific tokens appearing in the generated output.
          example:
            "1024": -10.5
            "105": 21.4
          type: object
        logprobs:
          description: An integer between 0 and 20 of the top k tokens to return log probabilities for at each generation step, instead of just the sampled token. Log probabilities help assess model confidence in token predictions.
          maximum: 20
          minimum: 0
          type: integer
        max_tokens:
          description: The maximum number of tokens to generate.
          type: integer
        messages:
          description: A list of messages comprising the conversation so far.
          items:
            $ref: "#/components/schemas/ChatCompletionMessageParam"
          type: array
        min_p:
          description: A number between 0 and 1 that can be used as an alternative to top_p and top-k.
          format: float
          type: number
        model:
          anyOf:
            - enum:
                - Qwen/Qwen2.5-72B-Instruct-Turbo
                - Qwen/Qwen2.5-7B-Instruct-Turbo
                - meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo
                - meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo
                - meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
              type: string
            - type: string
          description: |
            The name of the model to query.<br> <br> [See all of Together AI's chat models](https://docs.together.ai/docs/serverless-models#chat-models)
          example: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
        n:
          description: The number of completions to generate for each prompt.
          maximum: 128
          minimum: 1
          type: integer
        presence_penalty:
          description: A number between -2.0 and 2.0 where a positive value increases the likelihood of a model talking about new topics.
          format: float
          type: number
        reasoning_effort:
          description: Controls the level of reasoning effort the model should apply when generating responses. Higher values may result in more thoughtful and detailed responses but may take longer to generate.
          enum:
            - low
            - medium
            - high
          example: medium
          type: string
        repetition_penalty:
          description: A number that controls the diversity of generated text by reducing the likelihood of repeated sequences. Higher values decrease repetition.
          type: number
        response_format:
          description: An object specifying the format that the model must output.
          properties:
            schema:
              additionalProperties: true
              description: The schema of the response format.
              type: object
            type:
              description: The type of the response format.
              example: json
              type: string
          type: object
        safety_model:
          description: The name of the moderation model used to validate tokens. Choose from the available moderation models found [here](https://docs.together.ai/docs/inference-models#moderation-models).
          example: safety_model_name
          type: string
        seed:
          description: Seed value for reproducibility.
          example: 42
          type: integer
        stop:
          description: A list of string sequences that will truncate (stop) inference text output. For example, "</s>" will stop generation as soon as the model generates the given token.
          items:
            type: string
          type: array
        stream:
          description: "If true, stream tokens as Server-Sent Events as the model generates them instead of waiting for the full model response. The stream terminates with `data: [DONE]`. If false, return a single JSON object containing the results."
          type: boolean
        temperature:
          description: A decimal number from 0-1 that determines the degree of randomness in the response. A temperature less than 1 favors more correctness and is appropriate for question answering or summarization. A value closer to 1 introduces more randomness in the output.
          format: float
          type: number
        tool_choice:
          description: Controls which (if any) function is called by the model. By default uses `auto`, which lets the model pick between generating a message or calling a function.
          oneOf:
            - example: tool_name
              type: string
            - $ref: "#/components/schemas/ToolChoice"
        tools:
          description: A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for.
          items:
            $ref: "#/components/schemas/ToolsPart"
          type: array
        top_k:
          description: An integer that's used to limit the number of choices for the next predicted word or token. It specifies the maximum number of tokens to consider at each step, based on their probability of occurrence. This technique helps to speed up the generation process and can improve the quality of the generated text by focusing on the most likely options.
          format: int32
          type: integer
        top_p:
          description: A percentage (also called the nucleus parameter) that's used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities. It specifies a probability threshold below which all less likely tokens are filtered out. This technique helps maintain diversity and generate more fluent and natural-sounding text.
          format: float
          type: number
      required:
        - model
        - messages
      type: object
    # End Message Params
    ChatCompletionResponse:
      properties:
        choices:
          $ref: "#/components/schemas/ChatCompletionChoicesData"
        created:
          type: integer
        id:
          type: string
        model:
          type: string
        object:
          enum:
            - chat.completion
          type: string
        usage:
          $ref: "#/components/schemas/UsageData"
        warnings:
          items:
            $ref: "#/components/schemas/InferenceWarning"
          type: array
      required:
        - choices
        - id
        - created
        - model
        - object
      type: object
    ChatCompletionStream:
      oneOf:
        - $ref: "#/components/schemas/ChatCompletionEvent"
        - $ref: "#/components/schemas/StreamSentinel"
    # Start Message Params
    ChatCompletionSystemMessageParam:
      properties:
        content:
          type: string
        name:
          type: string
        role:
          enum:
            - system
          type: string
      required:
        - content
        - role
      type: object
    ChatCompletionToken:
      properties:
        id:
          type: integer
        logprob:
          type: number
        special:
          type: boolean
        text:
          type: string
      required:
        - id
        - text
        - logprob
        - special
      type: object
    ChatCompletionTool:
      properties:
        function:
          properties:
            description:
              type: string
            name:
              type: string
            parameters:
              additionalProperties: true
              type: object
          required:
            - name
          type: object
        type:
          enum:
            - function
          type: string
      required:
        - type
        - function
      type: object
    ChatCompletionToolMessageParam:
      properties:
        content:
          type: string
        role:
          enum:
            - tool
          type: string
        tool_call_id:
          type: string
      required:
        - role
        - content
        - tool_call_id
      type: object
    ChatCompletionUserMessageContent:
      description: The content of the message, which can either be a simple string or a structured format.
      oneOf:
        - $ref: "#/components/schemas/ChatCompletionUserMessageContentString"
        - $ref: "#/components/schemas/ChatCompletionUserMessageContentMultimodal"
    ChatCompletionUserMessageContentMultimodal:
      description: A structured message with mixed content types.
      items:
        oneOf:
          - properties:
              text:
                type: string
              type:
                enum:
                  - text
                type: string
            required:
              - type
              - text
            type: object
          - properties:
              image_url:
                properties:
                  url:
                    description: The URL of the image
                    type: string
                required:
                  - url
                type: object
              type:
                enum:
                  - image_url
                type: string
            type: object
          - properties:
              type:
                enum:
                  - video_url
                type: string
              video_url:
                properties:
                  url:
                    description: The URL of the video
                    type: string
                required:
                  - url
                type: object
            required:
              - type
              - video_url
            title: Video
            type: object
          - properties:
              audio_url:
                properties:
                  url:
                    description: The URL of the audio
                    type: string
                required:
                  - url
                type: object
              type:
                enum:
                  - audio_url
                type: string
            required:
              - type
              - audio_url
            title: Audio
            type: object
          - properties:
              input_audio:
                properties:
                  data:
                    description: The base64 encoded audio data
                    type: string
                  format:
                    description: The format of the audio data
                    enum:
                      - wav
                    type: string
                required:
                  - data
                  - format
                type: object
              type:
                enum:
                  - input_audio
                type: string
            required:
              - type
              - input_audio
            title: Input Audio
            type: object
        type: object
      type: array
    ChatCompletionUserMessageContentString:
      description: A plain text message.
      type: string
    ChatCompletionUserMessageParam:
      properties:
        content:
          $ref: "#/components/schemas/ChatCompletionUserMessageContent"
        name:
          type: string
        role:
          enum:
            - user
          type: string
      required:
        - content
        - role
      type: object
    CompletionChoice:
      properties:
        delta:
          properties:
            content:
              nullable: true
              type: string
            function_call:
              deprecated: true
              nullable: true
              properties:
                arguments:
                  type: string
                name:
                  type: string
              required:
                - arguments
                - name
              type: object
            role:
              enum:
                - system
                - user
                - assistant
                - function
                - tool
              type: string
            token_id:
              type: integer
            tool_calls:
              items:
                $ref: "#/components/schemas/ToolChoice"
              type: array
          required:
            - role
          title: CompletionChoiceDelta
          type: object
        index:
          type: integer
        text:
          type: string
      required:
        - index
      type: object
    CompletionChoicesData:
      items:
        properties:
          finish_reason:
            $ref: "#/components/schemas/FinishReason"
          logprobs:
            $ref: "#/components/schemas/LogprobsPart"
          seed:
            type: integer
          text:
            example: The capital of France is Paris. It's located in the north-central part of the country and is one of the most populous and visited cities in the world, known for its iconic landmarks like the Eiffel Tower, Louvre Museum, Notre-Dame Cathedral, and more. Paris is also the capital of the Île-de-France region and is a major global center for art, fashion, gastronomy, and culture.
            type: string
        type: object
      type: array
    CompletionChunk:
      properties:
        choices:
          items:
            $ref: "#/components/schemas/CompletionChoice"
          title: CompletionChoices
          type: array
        created:
          type: integer
        finish_reason:
          allOf:
            - $ref: "#/components/schemas/FinishReason"
            - nullable: true
        id:
          type: string
        object:
          enum:
            - completion.chunk
          type: string
        seed:
          type: integer
        token:
          $ref: "#/components/schemas/CompletionToken"
        usage:
          allOf:
            - $ref: "#/components/schemas/UsageData"
            - nullable: true
      required:
        - id
        - token
        - choices
        - usage
        - finish_reason
      type: object
    CompletionEvent:
      properties:
        data:
          $ref: "#/components/schemas/CompletionChunk"
      required:
        - data
      type: object
    CompletionRequest:
      properties:
        echo:
          description: If true, the response will contain the prompt. Can be used with `logprobs` to return prompt logprobs.
          type: boolean
        frequency_penalty:
          description: A number between -2.0 and 2.0 where a positive value decreases the likelihood of repeating tokens that have already been mentioned.
          format: float
          type: number
        logit_bias:
          additionalProperties:
            format: float
            type: number
          description: Adjusts the likelihood of specific tokens appearing in the generated output.
          example:
            "1024": -10.5
            "105": 21.4
          type: object
        logprobs:
          description: An integer between 0 and 20 of the top k tokens to return log probabilities for at each generation step, instead of just the sampled token. Log probabilities help assess model confidence in token predictions.
          maximum: 20
          minimum: 0
          type: integer
        max_tokens:
          description: The maximum number of tokens to generate.
          type: integer
        min_p:
          description: A number between 0 and 1 that can be used as an alternative to top-p and top-k.
          format: float
          type: number
        model:
          anyOf:
            - enum:
                - meta-llama/Llama-2-70b-hf
                - mistralai/Mistral-7B-v0.1
                - mistralai/Mixtral-8x7B-v0.1
                - Meta-Llama/Llama-Guard-7b
              type: string
            - type: string
          description: |
            The name of the model to query.<br> <br> [See all of Together AI's chat models](https://docs.together.ai/docs/serverless-models#chat-models)
          example: mistralai/Mixtral-8x7B-Instruct-v0.1
          type: string
        n:
          description: The number of completions to generate for each prompt.
          maximum: 128
          minimum: 1
          type: integer
        presence_penalty:
          description: A number between -2.0 and 2.0 where a positive value increases the likelihood of a model talking about new topics.
          format: float
          type: number
        prompt:
          description: A string providing context for the model to complete.
          example: <s>[INST] What is the capital of France? [/INST]
          type: string
        repetition_penalty:
          description: A number that controls the diversity of generated text by reducing the likelihood of repeated sequences. Higher values decrease repetition.
          format: float
          type: number
        safety_model:
          anyOf:
            - enum:
                - Meta-Llama/Llama-Guard-7b
              type: string
            - type: string
          description: The name of the moderation model used to validate tokens. Choose from the available moderation models found [here](https://docs.together.ai/docs/inference-models#moderation-models).
          example: safety_model_name
          type: string
        seed:
          description: Seed value for reproducibility.
          example: 42
          type: integer
        stop:
          description: A list of string sequences that will truncate (stop) inference text output. For example, "</s>" will stop generation as soon as the model generates the given token.
          items:
            type: string
          type: array
        stream:
          description: "If true, stream tokens as Server-Sent Events as the model generates them instead of waiting for the full model response. The stream terminates with `data: [DONE]`. If false, return a single JSON object containing the results."
          type: boolean
        temperature:
          description: A decimal number from 0-1 that determines the degree of randomness in the response. A temperature less than 1 favors more correctness and is appropriate for question answering or summarization. A value closer to 1 introduces more randomness in the output.
          format: float
          type: number
        top_k:
          description: An integer that's used to limit the number of choices for the next predicted word or token. It specifies the maximum number of tokens to consider at each step, based on their probability of occurrence. This technique helps to speed up the generation process and can improve the quality of the generated text by focusing on the most likely options.
          format: int32
          type: integer
        top_p:
          description: A percentage (also called the nucleus parameter) that's used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities. It specifies a probability threshold below which all less likely tokens are filtered out. This technique helps maintain diversity and generate more fluent and natural-sounding text.
          format: float
          type: number
      required:
        - model
        - prompt
      type: object
    CompletionResponse:
      properties:
        choices:
          $ref: "#/components/schemas/CompletionChoicesData"
        created:
          type: integer
        id:
          type: string
        model:
          type: string
        object:
          enum:
            - text.completion
          type: string
        prompt:
          $ref: "#/components/schemas/PromptPart"
        usage:
          $ref: "#/components/schemas/UsageData"
      required:
        - id
        - choices
        - usage
        - created
        - model
        - object
      type: object
    CompletionStream:
      oneOf:
        - $ref: "#/components/schemas/CompletionEvent"
        - $ref: "#/components/schemas/StreamSentinel"
    CompletionToken:
      properties:
        id:
          type: integer
        logprob:
          type: number
        special:
          type: boolean
        text:
          type: string
      required:
        - id
        - text
        - logprob
        - special
      type: object
    CosineLRSchedulerArgs:
      properties:
        min_lr_ratio:
          default: 0.0
          description: The ratio of the final learning rate to the peak learning rate
          format: float
          type: number
        num_cycles:
          default: 0.5
          description: Number or fraction of cycles for the cosine learning rate scheduler
          format: float
          type: number
      required:
        - min_lr_ratio
        - num_cycles
      type: object
    CreateBatchRequest:
      properties:
        completion_window:
          description: Time window for batch completion (optional)
          example: 24h
          type: string
        endpoint:
          description: The endpoint to use for batch processing
          example: /v1/chat/completions
          type: string
        input_file_id:
          description: ID of the uploaded input file containing batch requests
          example: file-abc123def456ghi789
          type: string
        model_id:
          description: Model to use for processing batch requests
          example: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
          type: string
        priority:
          description: Priority for batch processing (optional)
          example: 1
          type: integer
      required:
        - endpoint
        - input_file_id
      type: object
    CreateEndpointRequest:
      properties:
        autoscaling:
          $ref: "#/components/schemas/Autoscaling"
          description: Configuration for automatic scaling of the endpoint
        disable_prompt_cache:
          default: false
          description: Whether to disable the prompt cache for this endpoint
          type: boolean
        disable_speculative_decoding:
          default: false
          description: Whether to disable speculative decoding for this endpoint
          type: boolean
        display_name:
          description: A human-readable name for the endpoint
          examples:
            - My Llama3 70b endpoint
          type: string
        hardware:
          description: The hardware configuration to use for this endpoint
          examples:
            - 1x_nvidia_a100_80gb_sxm
          type: string
        inactive_timeout:
          description: The number of minutes of inactivity after which the endpoint will be automatically stopped. Set to null, omit or set to 0 to disable automatic timeout.
          example: 60
          nullable: true
          type: integer
        model:
          description: The model to deploy on this endpoint
          examples:
            - meta-llama/Llama-3-8b-chat-hf
          type: string
        state:
          default: STARTED
          description: The desired state of the endpoint
          enum:
            - STARTED
            - STOPPED
          example: STARTED
          type: string
      required:
        - model
        - hardware
        - autoscaling
      type: object
    CreateVideoBody:
      description: Parameters for creating a new video generation job.
      properties:
        fps:
          description: Frames per second. Defaults to 24.
          type: integer
        frame_images:
          description: Array of images to guide video generation, like keyframes.  If size 1, starting frame, if size 2, starting and ending frame, if more than 2 then frame must be specified
          example:
            - - frame: 0
                input_image: aac49721-1964-481a-ae78-8a4e29b91402
              - frame: 48
                input_image: c00abf5f-6cdb-4642-a01d-1bfff7bc3cf7
              - frame: last
                input_image: 3ad204c3-a9de-4963-8a1a-c3911e3afafe
          items:
            $ref: "#/components/schemas/VideoFrameImageInput"
          type: array
        guidance_scale:
          description: Controls how closely the video generation follows your prompt. Higher values make the model adhere more strictly to your text description, while lower values allow more creative freedom. guidence_scale affects both visual content and temporal consistency.Recommended range is 6.0-10.0 for most video models. Values above 12 may cause over-guidance artifacts or unnatural motion patterns.
          type: integer
        height:
          type: integer
        model:
          description: The model to be used for the video creation request.
          type: string
        negative_prompt:
          description: Similar to prompt, but specifies what to avoid instead of what to include
          type: string
        output_format:
          $ref: "#/components/schemas/VideoOutputFormat"
          description: Specifies the format of the output video. Defaults to MP4.
        output_quality:
          description: Compression quality. Defaults to 20.
          type: integer
        prompt:
          description: Text prompt that describes the video to generate.
          maxLength: 32000
          minLength: 1
          type: string
        reference_images:
          description: TODO need to figure this out
          items:
            type: unknown
          type: array
        seconds:
          description: Clip duration in seconds.
          type: string
        seed:
          description: Seed to use in initializing the video generation.  Using the same seed allows deterministic video generation.  If not provided a random seed is generated for each request.
          type: integer
        steps:
          description: The number of denoising steps the model performs during video generation. More steps typically result in higher quality output but require longer processing time.
          maximum: 50
          minimum: 10
          type: integer
        width:
          type: integer
      required:
        - model
      title: Create video request
      type: object
    CreateVideoResponse:
      properties:
        id:
          description: Unique identifier for the video job.
          type: string
    DedicatedEndpoint:
      description: Details about a dedicated endpoint deployment
      properties:
        autoscaling:
          $ref: "#/components/schemas/Autoscaling"
          description: Configuration for automatic scaling of the endpoint
        created_at:
          description: Timestamp when the endpoint was created
          example: 2025-02-04T10:43:55.405Z
          format: date-time
          type: string
        display_name:
          description: Human-readable name for the endpoint
          example: My Llama3 70b endpoint
          type: string
        hardware:
          description: The hardware configuration used for this endpoint
          example: 1x_nvidia_a100_80gb_sxm
          type: string
        id:
          description: Unique identifier for the endpoint
          example: endpoint-d23901de-ef8f-44bf-b3e7-de9c1ca8f2d7
          type: string
        model:
          description: The model deployed on this endpoint
          example: meta-llama/Llama-3-8b-chat-hf
          type: string
        name:
          description: System name for the endpoint
          example: devuser/meta-llama/Llama-3-8b-chat-hf-a32b82a1
          type: string
        object:
          description: The type of object
          enum:
            - endpoint
          example: endpoint
          type: string
        owner:
          description: The owner of this endpoint
          example: devuser
          type: string
        state:
          description: Current state of the endpoint
          enum:
            - PENDING
            - STARTING
            - STARTED
            - STOPPING
            - STOPPED
            - ERROR
          example: STARTED
          type: string
        type:
          description: The type of endpoint
          enum:
            - dedicated
          example: dedicated
          type: string
      required:
        - object
        - id
        - name
        - display_name
        - model
        - hardware
        - type
        - owner
        - state
        - autoscaling
        - created_at
      type: object
    DisplayorExecuteOutput:
      properties:
        data:
          properties:
            application/geo+json:
              type: object
            application/javascript:
              type: string
            application/json:
              type: object
            application/pdf:
              format: byte
              type: string
            application/vnd.vega.v5+json:
              type: object
            application/vnd.vegalite.v4+json:
              type: object
            image/gif:
              format: byte
              type: string
            image/jpeg:
              format: byte
              type: string
            image/png:
              format: byte
              type: string
            image/svg+xml:
              type: string
            text/html:
              type: string
            text/latex:
              type: string
            text/markdown:
              type: string
            text/plain:
              type: string
          type: object
        type:
          enum:
            - display_data
            - execute_result
          type: string
      required:
        - type
        - data
      title: DisplayorExecuteOutput
    EmbeddingsRequest:
      properties:
        input:
          example: Our solar system orbits the Milky Way galaxy at about 515,000 mph
          oneOf:
            - description: A string providing the text for the model to embed.
              example: Our solar system orbits the Milky Way galaxy at about 515,000 mph
              type: string
            - items:
                description: A string providing the text for the model to embed.
                example: Our solar system orbits the Milky Way galaxy at about 515,000 mph
                type: string
              type: array
        model:
          anyOf:
            - enum:
                - WhereIsAI/UAE-Large-V1
                - BAAI/bge-large-en-v1.5
                - BAAI/bge-base-en-v1.5
                - togethercomputer/m2-bert-80M-8k-retrieval
              type: string
            - type: string
          description: |
            The name of the embedding model to use.<br> <br> [See all of Together AI's embedding models](https://docs.together.ai/docs/serverless-models#embedding-models)
          example: togethercomputer/m2-bert-80M-8k-retrieval
          type: string
      required:
        - model
        - input
      type: object
    EmbeddingsResponse:
      properties:
        data:
          items:
            properties:
              embedding:
                items:
                  type: number
                type: array
              index:
                type: integer
              object:
                enum:
                  - embedding
                type: string
            required:
              - index
              - object
              - embedding
            type: object
          type: array
        model:
          type: string
        object:
          enum:
            - list
          type: string
      required:
        - object
        - model
        - data
      type: object
    EndpointPricing:
      description: Pricing details for using an endpoint
      properties:
        cents_per_minute:
          description: Cost per minute of endpoint uptime in cents
          examples:
            - 5.42
          format: float
          type: number
      required:
        - cents_per_minute
      type: object
    Error:
      oneOf:
        - type: string
        - additionalProperties: true
          type: object
      title: Error
    ErrorData:
      properties:
        error:
          properties:
            code:
              default: null
              nullable: true
              type: string
            message:
              nullable: false
              type: string
            param:
              default: null
              nullable: true
              type: string
            type:
              nullable: false
              type: string
          required:
            - type
            - message
          type: object
      required:
        - error
      type: object
    ErrorOutput:
      description: Errors and exceptions that occurred. If this output type is present, your code did not execute successfully.
      properties:
        data:
          type: string
        type:
          enum:
            - error
          type: string
      required:
        - type
        - data
      title: ErrorOutput
    EvaluationClassifyParameters:
      properties:
        input_data_file_path:
          description: Data file ID
          example: file-1234-aefd
          type: string
        judge:
          $ref: "#/components/schemas/EvaluationJudgeModelConfig"
        labels:
          description: List of possible classification labels
          example:
            - "yes"
            - "no"
          items:
            type: string
          minItems: 2
          type: array
        model_to_evaluate:
          $ref: "#/components/schemas/EvaluationModelOrString"
        pass_labels:
          description: List of labels that are considered passing
          example:
            - "yes"
          items:
            type: string
          minItems: 1
          type: array
      required:
        - judge
        - labels
        - pass_labels
        - input_data_file_path
      type: object
    EvaluationClassifyResults:
      properties:
        generation_fail_count:
          description: Number of failed generations.
          example: 0
          format: integer
          nullable: true
          type: number
        invalid_label_count:
          description: Number of invalid labels
          example: 0
          format: float
          nullable: true
          type: number
        judge_fail_count:
          description: Number of failed judge generations
          example: 0
          format: integer
          nullable: true
          type: number
        label_counts:
          description: JSON string representing label counts
          example: '{"yes": 10, "no": 0}'
          type: string
        pass_percentage:
          description: Pecentage of pass labels.
          example: 10
          format: integer
          nullable: true
          type: number
        result_file_id:
          description: Data File ID
          example: file-1234-aefd
          type: string
      type: object
    EvaluationCompareParameters:
      properties:
        input_data_file_path:
          description: Data file name
          type: string
        judge:
          $ref: "#/components/schemas/EvaluationJudgeModelConfig"
        model_a:
          $ref: "#/components/schemas/EvaluationModelOrString"
        model_b:
          $ref: "#/components/schemas/EvaluationModelOrString"
      required:
        - judge
        - input_data_file_path
      type: object
    EvaluationCompareResults:
      properties:
        A_wins:
          description: Number of times model A won
          type: integer
        B_wins:
          description: Number of times model B won
          type: integer
        Ties:
          description: Number of ties
          type: integer
        generation_fail_count:
          description: Number of failed generations.
          example: 0
          format: integer
          nullable: true
          type: number
        judge_fail_count:
          description: Number of failed judge generations
          example: 0
          format: integer
          nullable: true
          type: number
        num_samples:
          description: Total number of samples compared
          type: integer
        result_file_id:
          description: Data File ID
          type: string
      type: object
    EvaluationJob:
      properties:
        created_at:
          description: When the job was created
          example: "2025-07-23T17:10:04.837888Z"
          format: date-time
          type: string
        owner_id:
          description: ID of the job owner (admin only)
          type: string
        parameters:
          additionalProperties: true
          description: The parameters used for this evaluation
          type: object
        results:
          description: Results of the evaluation (when completed)
          nullable: true
          oneOf:
            - $ref: "#/components/schemas/EvaluationClassifyResults"
            - $ref: "#/components/schemas/EvaluationScoreResults"
            - $ref: "#/components/schemas/EvaluationCompareResults"
            - properties:
                error:
                  type: string
              type: object
        status:
          description: Current status of the job
          enum:
            - pending
            - queued
            - running
            - completed
            - error
            - user_error
          example: completed
          type: string
        status_updates:
          description: History of status updates (admin only)
          items:
            $ref: "#/components/schemas/EvaluationJobStatusUpdate"
          type: array
        type:
          description: The type of evaluation
          enum:
            - classify
            - score
            - compare
          example: classify
          type: string
        updated_at:
          description: When the job was last updated
          example: "2025-07-23T17:10:04.837888Z"
          format: date-time
          type: string
        workflow_id:
          description: The evaluation job ID
          example: eval-1234aedf
          type: string
      type: object
    EvaluationJobStatusUpdate:
      properties:
        message:
          description: Additional message for this update
          example: Job is pending evaluation
          type: string
        status:
          description: The status at this update
          example: pending
          type: string
        timestamp:
          description: When this update occurred
          example: "2025-07-23T17:10:04.837888Z"
          format: date-time
          type: string
      type: object
    EvaluationJudgeModelConfig:
      properties:
        model_name:
          description: Name of the judge model
          example: meta-llama/Llama-3-70B-Instruct-Turbo
          type: string
        system_template:
          description: System prompt template for the judge
          example: Imagine you are a helpful assistant
          type: string
      required:
        - model_name
        - system_template
      type: object
    EvaluationModelOrString:
      oneOf:
        - description: Field name in the input data
          type: string
        - $ref: "#/components/schemas/EvaluationModelRequest"
    EvaluationModelRequest:
      properties:
        input_template:
          description: Input prompt template
          example: Please classify {{prompt}} based on the labels below
          type: string
        max_tokens:
          description: Maximum number of tokens to generate
          example: 512
          minimum: 1
          type: integer
        model_name:
          description: Name of the model to evaluate
          example: meta-llama/Llama-3-70B-Instruct-Turbo
          type: string
        system_template:
          description: System prompt template
          example: Imagine you are helpful assistant
          type: string
        temperature:
          description: Sampling temperature
          example: 0.7
          format: float
          maximum: 2
          minimum: 0
          type: number
      required:
        - model_name
        - max_tokens
        - temperature
        - system_template
        - input_template
      type: object
    EvaluationResponse:
      properties:
        status:
          description: Initial status of the job
          enum:
            - pending
          type: string
        workflow_id:
          description: The ID of the created evaluation job
          example: eval-1234-1244513
          type: string
      type: object
    EvaluationScoreParameters:
      properties:
        input_data_file_path:
          description: Data file ID
          example: file-01234567890123456789
          type: string
        judge:
          $ref: "#/components/schemas/EvaluationJudgeModelConfig"
        max_score:
          description: Maximum possible score
          example: 10.0
          format: float
          type: number
        min_score:
          description: Minimum possible score
          example: 0.0
          format: float
          type: number
        model_to_evaluate:
          $ref: "#/components/schemas/EvaluationModelOrString"
        pass_threshold:
          description: Score threshold for passing
          example: 7.0
          format: float
          type: number
      required:
        - judge
        - min_score
        - max_score
        - pass_threshold
        - input_data_file_path
      type: object
    EvaluationScoreResults:
      properties:
        aggregated_scores:
          properties:
            mean_score:
              format: float
              type: number
            pass_percentage:
              format: float
              type: number
            std_score:
              format: float
              type: number
          type: object
        failed_samples:
          description: number of failed samples generated from model
          format: integer
          type: number
        generation_fail_count:
          description: Number of failed generations.
          example: 0
          format: integer
          nullable: true
          type: number
        invalid_score_count:
          description: number of invalid scores generated from model
          format: integer
          type: number
        judge_fail_count:
          description: Number of failed judge generations
          example: 0
          format: integer
          nullable: true
          type: number
        result_file_id:
          description: Data File ID
          example: file-1234-aefd
          type: string
      type: object
    EvaluationTypedRequest:
      properties:
        parameters:
          description: Type-specific parameters for the evaluation
          oneOf:
            - $ref: "#/components/schemas/EvaluationClassifyParameters"
            - $ref: "#/components/schemas/EvaluationScoreParameters"
            - $ref: "#/components/schemas/EvaluationCompareParameters"
        type:
          description: The type of evaluation to perform
          enum:
            - classify
            - score
            - compare
          example: classify
          type: string
      required:
        - type
        - parameters
      type: object
    ExecuteRequest:
      properties:
        code:
          description: Code snippet to execute.
          example: print('Hello, world!')
          type: string
        files:
          description: Files to upload to the session. If present, files will be uploaded before executing the given code.
          items:
            properties:
              content:
                type: string
              encoding:
                description: Encoding of the file content. Use `string` for text files such as code, and `base64` for binary files, such as images.
                enum:
                  - string
                  - base64
                type: string
              name:
                type: string
            required:
              - name
              - encoding
              - content
            type: object
          type: array
        language:
          default: python
          description: Programming language for the code to execute. Currently only supports Python, but more will be added.
          enum:
            - python
        session_id:
          description: Identifier of the current session. Used to make follow-up calls. Requests will return an error if the session does not belong to the caller or has expired.
          example: ses_abcDEF123
          nullable: false
          type: string
      required:
        - language
        - code
      title: ExecuteRequest
    ExecuteResponse:
      description: The result of the execution. If successful, `data` contains the result and `errors` will be null. If unsuccessful, `data` will be null and `errors` will contain the errors.
      oneOf:
        - properties:
            data:
              nullable: false
              properties:
                outputs:
                  items:
                    discriminator:
                      propertyName: type
                    oneOf:
                      - description: Outputs that were printed to stdout or stderr
                        properties:
                          data:
                            type: string
                          type:
                            enum:
                              - stdout
                              - stderr
                            type: string
                        required:
                          - type
                          - data
                        title: StreamOutput
                        type: object
                      - description: Errors and exceptions that occurred. If this output type is present, your code did not execute successfully.
                        properties:
                          data:
                            type: string
                          type:
                            enum:
                              - error
                            type: string
                        required:
                          - type
                          - data
                        title: ErrorOutput
                      - properties:
                          data:
                            properties:
                              application/geo+json:
                                additionalProperties: true
                                type: object
                              application/javascript:
                                type: string
                              application/json:
                                additionalProperties: true
                                type: object
                              application/pdf:
                                format: byte
                                type: string
                              application/vnd.vega.v5+json:
                                additionalProperties: true
                                type: object
                              application/vnd.vegalite.v4+json:
                                additionalProperties: true
                                type: object
                              image/gif:
                                format: byte
                                type: string
                              image/jpeg:
                                format: byte
                                type: string
                              image/png:
                                format: byte
                                type: string
                              image/svg+xml:
                                type: string
                              text/html:
                                type: string
                              text/latex:
                                type: string
                              text/markdown:
                                type: string
                              text/plain:
                                type: string
                            type: object
                          type:
                            enum:
                              - display_data
                              - execute_result
                            type: string
                        required:
                          - type
                          - data
                        title: DisplayorExecuteOutput
                    title: InterpreterOutput
                  type: array
                session_id:
                  description: Identifier of the current session. Used to make follow-up calls.
                  example: ses_abcDEF123
                  nullable: false
                  type: string
                status:
                  description: Status of the execution. Currently only supports success.
                  enum:
                    - success
                  type: string
              required:
                - session_id
                - outputs
              type: object
            errors:
              type: "null"
          required:
            - data
            - errors
          title: SuccessfulExecution
          type: object
        - properties:
            data:
              type: "null"
            errors:
              items:
                oneOf:
                  - type: string
                  - additionalProperties: true
                    type: object
                title: Error
              type: array
          required:
            - data
            - errors
          title: FailedExecution
          type: object
      title: ExecuteResponse
      type: object
    FileDeleteResponse:
      properties:
        deleted:
          type: boolean
        id:
          type: string
      type: object
    FileList:
      properties:
        data:
          items:
            $ref: "#/components/schemas/FileResponse"
          type: array
      required:
        - data
      type: object
    FileObject:
      properties:
        filename:
          type: string
        id:
          type: string
        object:
          type: string
        size:
          type: integer
      type: object
    FilePurpose:
      description: The purpose of the file
      enum:
        - fine-tune
        - eval
        - eval-sample
        - eval-output
        - eval-summary
        - batch-generated
        - batch-api
      example: fine-tune
      type: string
    FileResponse:
      properties:
        FileType:
          $ref: "#/components/schemas/FileType"
        LineCount:
          type: integer
        Processed:
          type: boolean
        bytes:
          example: 2664
          type: integer
        created_at:
          example: 1715021438
          type: integer
        filename:
          example: my_file.jsonl
          type: string
        id:
          type: string
        object:
          example: file
          type: string
        purpose:
          $ref: "#/components/schemas/FilePurpose"
      required:
        - id
        - object
        - created_at
        - filename
        - bytes
        - purpose
        - FileType
        - Processed
        - LineCount
      type: object
    FileType:
      default: jsonl
      description: The type of the file
      enum:
        - csv
        - jsonl
        - parquet
      example: jsonl
      type: string
    FineTuneCheckpoint:
      properties:
        checkpoint_type:
          type: string
        created_at:
          type: string
        path:
          type: string
        step:
          type: integer
      required:
        - step
        - path
        - created_at
        - checkpoint_type
      type: object
    FineTuneEvent:
      properties:
        checkpoint_path:
          type: string
        created_at:
          type: string
        hash:
          type: string
        level:
          anyOf:
            - $ref: "#/components/schemas/FinetuneEventLevels"
        message:
          type: string
        model_path:
          type: string
        object:
          enum:
            - fine-tune-event
          type: string
        param_count:
          type: integer
        step:
          type: integer
        token_count:
          type: integer
        total_steps:
          type: integer
        training_offset:
          type: integer
        type:
          $ref: "#/components/schemas/FinetuneEventType"
        wandb_url:
          type: string
      required:
        - object
        - created_at
        - message
        - type
        - param_count
        - token_count
        - total_steps
        - wandb_url
        - step
        - checkpoint_path
        - model_path
        - training_offset
        - hash
      type: object
    FinetuneDeleteResponse:
      properties:
        message:
          description: Message indicating the result of the deletion
          type: string
      type: object
    FinetuneDownloadResult:
      properties:
        checkpoint_step:
          type: integer
        filename:
          type: string
        id:
          type: string
        object:
          enum:
            - null
            - local
        size:
          type: integer
      type: object
    FinetuneEventLevels:
      enum:
        - null
        - info
        - warning
        - error
        - legacy_info
        - legacy_iwarning
        - legacy_ierror
      type: string
    FinetuneEventType:
      enum:
        - job_pending
        - job_start
        - job_stopped
        - model_downloading
        - model_download_complete
        - training_data_downloading
        - training_data_download_complete
        - validation_data_downloading
        - validation_data_download_complete
        - wandb_init
        - training_start
        - checkpoint_save
        - billing_limit
        - epoch_complete
        - training_complete
        - model_compressing
        - model_compression_complete
        - model_uploading
        - model_upload_complete
        - job_complete
        - job_error
        - cancel_requested
        - job_restarted
        - refund
        - warning
      type: string
    FinetuneJobStatus:
      enum:
        - pending
        - queued
        - running
        - compressing
        - uploading
        - cancel_requested
        - cancelled
        - error
        - completed
      type: string
    FinetuneListCheckpoints:
      properties:
        data:
          items:
            $ref: "#/components/schemas/FineTuneCheckpoint"
          type: array
      required:
        - data
      type: object
    FinetuneListEvents:
      properties:
        data:
          items:
            $ref: "#/components/schemas/FineTuneEvent"
          type: array
      required:
        - data
      type: object
    FinetuneResponse:
      properties:
        batch_size:
          default: max
          oneOf:
            - type: integer
            - enum:
                - max
              type: string
        created_at:
          type: string
        epochs_completed:
          type: integer
        eval_steps:
          type: integer
        events:
          items:
            $ref: "#/components/schemas/FineTuneEvent"
          type: array
        from_checkpoint:
          type: string
        from_hf_model:
          type: string
        hf_model_revision:
          type: string
        id:
          format: uuid
          type: string
        job_id:
          type: string
        learning_rate:
          type: number
        lr_scheduler:
          $ref: "#/components/schemas/LRScheduler"
          type: object
        max_grad_norm:
          format: float
          type: number
        model:
          type: string
        model_output_name:
          type: string
        model_output_path:
          type: string
        n_checkpoints:
          type: integer
        n_epochs:
          type: integer
        n_evals:
          type: integer
        param_count:
          type: integer
        queue_depth:
          type: integer
        status:
          $ref: "#/components/schemas/FinetuneJobStatus"
        token_count:
          type: integer
        total_price:
          type: integer
        train_on_inputs:
          default: auto
          oneOf:
            - type: boolean
            - enum:
                - auto
              type: string
        training_file:
          type: string
        training_method:
          oneOf:
            - $ref: "#/components/schemas/TrainingMethodSFT"
            - $ref: "#/components/schemas/TrainingMethodDPO"
          type: object
        training_type:
          oneOf:
            - $ref: "#/components/schemas/FullTrainingType"
            - $ref: "#/components/schemas/LoRATrainingType"
          type: object
        trainingfile_numlines:
          type: integer
        trainingfile_size:
          type: integer
        updated_at:
          type: string
        validation_file:
          type: string
        wandb_project_name:
          type: string
        wandb_url:
          type: string
        warmup_ratio:
          type: number
        weight_decay:
          format: float
          type: number
      required:
        - id
        - status
      type: object
    FinetuneResponseTruncated:
      description: A truncated version of the fine-tune response, used for POST /fine-tunes, GET /fine-tunes and POST /fine-tunes/{id}/cancel endpoints
      example:
        created_at: "2023-05-17T17:35:45.123Z"
        events: [] # FineTuneTruncated object has no events
        id: ft-01234567890123456789
        model: meta-llama/Llama-2-7b-hf
        model_output_name: mynamespace/meta-llama/Llama-2-7b-hf-32162631
        n_epochs: 3
        owner_address: user@example.com
        status: completed
        token_count: 850000
        total_price: 1500
        training_file: file-01234567890123456789
        updated_at: "2023-05-17T18:46:23.456Z"
        user_id: user_01234567890123456789
        wandb_project_name: my-finetune-project
      properties:
        batch_size:
          description: Batch size used for training
          type: integer
        created_at:
          description: Creation timestamp of the fine-tune job
          format: date-time
          type: string
        events:
          description: Events related to this fine-tune job
          items:
            $ref: "#/components/schemas/FineTuneEvent"
          type: array
        from_checkpoint:
          description: Checkpoint used to continue training
          type: string
        from_hf_model:
          description: Hugging Face Hub repo to start training from
          type: string
        hf_model_revision:
          description: The revision of the Hugging Face Hub model to continue training from
          type: string
        id:
          description: Unique identifier for the fine-tune job
          type: string
        learning_rate:
          description: Learning rate used for training
          format: float
          type: number
        lr_scheduler:
          $ref: "#/components/schemas/LRScheduler"
          description: Learning rate scheduler configuration
        max_grad_norm:
          description: Maximum gradient norm for clipping
          format: float
          type: number
        model:
          description: Base model used for fine-tuning
          type: string
        model_output_name:
          type: string
        n_checkpoints:
          description: Number of checkpoints saved during training
          type: integer
        n_epochs:
          description: Number of training epochs
          type: integer
        n_evals:
          description: Number of evaluations during training
          type: integer
        owner_address:
          description: Owner address information
          type: string
        status:
          $ref: "#/components/schemas/FinetuneJobStatus"
        suffix:
          description: Suffix added to the fine-tuned model name
          type: string
        token_count:
          description: Count of tokens processed
          type: integer
        total_price:
          description: Total price for the fine-tuning job
          type: integer
        # FineTuneUserParams fields
        training_file:
          description: File-ID of the training file
          type: string
        training_method:
          description: Method of training used
          oneOf:
            - $ref: "#/components/schemas/TrainingMethodSFT"
            - $ref: "#/components/schemas/TrainingMethodDPO"
        training_type:
          description: Type of training used (full or LoRA)
          oneOf:
            - $ref: "#/components/schemas/FullTrainingType"
            - $ref: "#/components/schemas/LoRATrainingType"
        updated_at:
          description: Last update timestamp of the fine-tune job
          format: date-time
          type: string
        user_id:
          description: Identifier for the user who created the job
          type: string
        validation_file:
          description: File-ID of the validation file
          type: string
        wandb_name:
          description: Weights & Biases run name
          type: string
        wandb_project_name:
          description: Weights & Biases project name
          type: string
        warmup_ratio:
          description: Ratio of warmup steps
          format: float
          type: number
        weight_decay:
          description: Weight decay value used
          format: float
          type: number
      required:
        - id
        - status
        - created_at
        - updated_at
      type: object
    FinetuneTruncatedList:
      properties:
        data:
          items:
            $ref: "#/components/schemas/FinetuneResponseTruncated"
          type: array
      required:
        - data
      type: object
    FinishReason:
      enum:
        - stop
        - eos
        - length
        - tool_calls
        - function_call
      type: string
    FullTrainingType:
      properties:
        type:
          enum:
            - Full
          type: string
      required:
        - type
      type: object
    HardwareAvailability:
      description: Indicates the current availability status of a hardware configuration
      properties:
        status:
          description: The availability status of the hardware configuration
          enum:
            - available
            - unavailable
            - insufficient
          type: string
      required:
        - status
      type: object
    HardwareSpec:
      description: Detailed specifications of a hardware configuration
      properties:
        gpu_count:
          description: Number of GPUs in this configuration
          examples:
            - 2
          format: int32
          type: integer
        gpu_link:
          description: The GPU interconnect technology
          examples:
            - sxm
          type: string
        gpu_memory:
          description: Amount of GPU memory in GB
          examples:
            - 80
          format: float
          type: number
        gpu_type:
          description: The type/model of GPU
          examples:
            - a100-80gb
          type: string
      required:
        - gpu_type
        - gpu_link
        - gpu_memory
        - gpu_count
      type: object
    HardwareWithStatus:
      description: Hardware configuration details with optional availability status
      properties:
        availability:
          $ref: "#/components/schemas/HardwareAvailability"
        id:
          description: Unique identifier for the hardware configuration
          examples:
            - 2x_nvidia_a100_80gb_sxm
          type: string
        object:
          enum:
            - hardware
          type: string
        pricing:
          $ref: "#/components/schemas/EndpointPricing"
        specs:
          $ref: "#/components/schemas/HardwareSpec"
        updated_at:
          description: Timestamp of when the hardware status was last updated
          format: date-time
          type: string
      required:
        - object
        - id
        - pricing
        - specs
        - updated_at
      type: object
    ImageResponse:
      properties:
        data:
          items:
            discriminator:
              propertyName: type
            oneOf:
              - $ref: "#/components/schemas/ImageResponseDataB64"
              - $ref: "#/components/schemas/ImageResponseDataUrl"
          type: array
        id:
          type: string
        model:
          type: string
        object:
          enum:
            - list
          example: list
      required:
        - id
        - model
        - object
        - data
      type: object
    ImageResponseDataB64:
      properties:
        b64_json:
          type: string
        index:
          type: integer
        type:
          enum:
            - b64_json
          type: string
      required:
        - index
        - b64_json
        - type
      type: object
    ImageResponseDataUrl:
      properties:
        index:
          type: integer
        type:
          enum:
            - url
          type: string
        url:
          type: string
      required:
        - index
        - url
        - type
      type: object
    InferenceWarning:
      properties:
        message:
          type: string
      required:
        - message
      type: object
    InterpreterOutput:
      discriminator:
        propertyName: type
      oneOf:
        - description: Outputs that were printed to stdout or stderr
          properties:
            data:
              type: string
            type:
              enum:
                - stdout
                - stderr
              type: string
          required:
            - type
            - data
          title: StreamOutput
        - description: Errors and exceptions that occurred. If this output type is present, your code did not execute successfully.
          properties:
            data:
              type: string
            type:
              enum:
                - error
              type: string
          required:
            - type
            - data
          title: ErrorOutput
        - properties:
            data:
              properties:
                application/geo+json:
                  type: object
                application/javascript:
                  type: string
                application/json:
                  type: object
                application/pdf:
                  format: byte
                  type: string
                application/vnd.vega.v5+json:
                  type: object
                application/vnd.vegalite.v4+json:
                  type: object
                image/gif:
                  format: byte
                  type: string
                image/jpeg:
                  format: byte
                  type: string
                image/png:
                  format: byte
                  type: string
                image/svg+xml:
                  type: string
                text/html:
                  type: string
                text/latex:
                  type: string
                text/markdown:
                  type: string
                text/plain:
                  type: string
              type: object
            type:
              enum:
                - display_data
                - execute_result
              type: string
          required:
            - type
            - data
          title: DisplayorExecuteOutput
      title: InterpreterOutput
    JobInfoSuccessResponse:
      properties:
        args:
          properties:
            description:
              example: Finetuned Qwen2.5-72B-Instruct by Unsloth
              type: string
            modelName:
              example: necolinehubner/Qwen2.5-72B-Instruct
              type: string
            modelSource:
              example: unsloth/Qwen2.5-72B-Instruct
              type: string
          type: object
        created_at:
          example: "2025-03-11T22:05:43Z"
          format: date-time
          type: string
        job_id:
          example: job-a15dad11-8d8e-4007-97c5-a211304de284
          type: string
        status:
          enum:
            - Queued
            - Running
            - Complete
            - Failed
          example: Complete
          type: string
        status_updates:
          items:
            properties:
              message:
                example: Job is Complete
                type: string
              status:
                example: Complete
                type: string
              timestamp:
                example: "2025-03-11T22:36:12Z"
                format: date-time
                type: string
            required:
              - status
              - message
              - timestamp
            type: object
          type: array
        type:
          example: model_upload
          type: string
        updated_at:
          example: "2025-03-11T22:36:12Z"
          format: date-time
          type: string
      required:
        - type
        - job_id
        - status
        - status_updates
        - args
        - created_at
        - updated_at
      type: object
    JobsInfoSuccessResponse:
      properties:
        data:
          items:
            $ref: "#/components/schemas/JobInfoSuccessResponse"
          type: array
      required:
        - data
      type: object
    LRScheduler:
      properties:
        lr_scheduler_args:
          oneOf:
            - $ref: "#/components/schemas/LinearLRSchedulerArgs"
            - $ref: "#/components/schemas/CosineLRSchedulerArgs"
        lr_scheduler_type:
          enum:
            - linear
            - cosine
          type: string
      required:
        - lr_scheduler_type
      type: object
    LinearLRSchedulerArgs:
      properties:
        min_lr_ratio:
          default: 0.0
          description: The ratio of the final learning rate to the peak learning rate
          format: float
          type: number
      type: object
    ListEndpoint:
      description: Details about an endpoint when listed via the list endpoint
      properties:
        created_at:
          description: Timestamp when the endpoint was created
          example: 2024-02-28T21:34:35.444Z
          format: date-time
          type: string
        id:
          description: Unique identifier for the endpoint
          example: endpoint-d23901de-ef8f-44bf-b3e7-de9c1ca8f2d7
          type: string
        model:
          description: The model deployed on this endpoint
          example: allenai/OLMo-7B
          type: string
        name:
          description: System name for the endpoint
          example: allenai/OLMo-7B
          type: string
        object:
          description: The type of object
          enum:
            - endpoint
          example: endpoint
          type: string
        owner:
          description: The owner of this endpoint
          example: together
          type: string
        state:
          description: Current state of the endpoint
          enum:
            - PENDING
            - STARTING
            - STARTED
            - STOPPING
            - STOPPED
            - ERROR
          example: STARTED
          type: string
        type:
          description: The type of endpoint
          enum:
            - serverless
            - dedicated
          example: serverless
          type: string
      required:
        - id
        - object
        - name
        - model
        - type
        - owner
        - state
        - created_at
      type: object
    LoRATrainingType:
      properties:
        lora_alpha:
          type: integer
        lora_dropout:
          default: 0.0
          format: float
          type: number
        lora_r:
          type: integer
        lora_trainable_modules:
          default: all-linear
          type: string
        type:
          enum:
            - Lora
          type: string
      required:
        - type
        - lora_r
        - lora_alpha
      type: object
    LogprobsPart:
      properties:
        token_ids:
          description: List of token IDs corresponding to the logprobs
          items:
            type: number
          type: array
        token_logprobs:
          description: List of token log probabilities
          items:
            type: number
          type: array
        tokens:
          description: List of token strings
          items:
            type: string
          type: array
      type: object
    ModelInfo:
      properties:
        context_length:
          example: 2048
          type: integer
        created:
          example: 1692896905
          type: integer
        display_name:
          example: Chronos Hermes (13B)
          type: string
        id:
          example: Austism/chronos-hermes-13b
          type: string
        license:
          example: other
          type: string
        link:
          type: string
        object:
          example: model
          type: string
        organization:
          example: Austism
          type: string
        pricing:
          $ref: "#/components/schemas/Pricing"
        type:
          enum:
            - chat
            - language
            - code
            - image
            - embedding
            - moderation
            - rerank
          example: chat
      required:
        - id
        - object
        - created
        - type
      type: object
    ModelInfoList:
      items:
        $ref: "#/components/schemas/ModelInfo"
      type: array
    ModelUploadRequest:
      properties:
        base_model:
          description: The base model to use for an adapter if setting it to run against a serverless pool.  Only used for model_type `adapter`.
          example: Qwen/Qwen2.5-72B-Instruct
          type: string
        description:
          description: A description of your model
          example: Finetuned Qwen2.5-72B-Instruct by Unsloth
          type: string
        hf_token:
          description: Hugging Face token (if uploading from Hugging Face)
          example: hf_examplehuggingfacetoken
          type: string
        lora_model:
          description: The lora pool to use for an adapter if setting it to run against, say, a dedicated pool.  Only used for model_type `adapter`.
          example: my_username/Qwen2.5-72B-Instruct-lora
          type: string
        model_name:
          description: The name to give to your uploaded model
          example: Qwen2.5-72B-Instruct
          type: string
        model_source:
          description: The source location of the model (Hugging Face repo or S3 path)
          example: unsloth/Qwen2.5-72B-Instruct
          type: string
        model_type:
          default: model
          description: Whether the model is a full model or an adapter
          enum:
            - model
            - adapter
          example: model
          type: string
      required:
        - model_name
        - model_source
      type: object
    ModelUploadSuccessResponse:
      properties:
        data:
          properties:
            job_id:
              example: job-a15dad11-8d8e-4007-97c5-a211304de284
              type: string
            model_id:
              example: model-c0e32dfc-637e-47b2-bf4e-e9b2e58c9da7
              type: string
            model_name:
              example: necolinehubner/Qwen2.5-72B-Instruct
              type: string
            model_source:
              example: huggingface
              type: string
          required:
            - job_id
            - model_name
            - model_id
            - model_source
          type: object
        message:
          example: Processing model weights. Job created.
          type: string
      required:
        - data
        - message
      type: object
    MultipartAbortRequest:
      properties:
        file_id:
          description: File ID from initiate response
          example: file-def456
          type: string
        upload_id:
          description: Upload session ID from initiate response
          example: upload-abc123
          type: string
      required:
        - upload_id
        - file_id
      type: object
    MultipartCompleteRequest:
      properties:
        file_id:
          description: File ID from initiate response
          example: file-def456
          type: string
        parts:
          description: ETags for each successfully uploaded part
          items:
            properties:
              ETag:
                description: ETag returned from S3 part upload
                example: '"abc123def456"'
                type: string
              PartNumber:
                description: Part number (1-based)
                example: 1
                type: integer
            required:
              - PartNumber
              - ETag
            type: object
          type: array
        upload_id:
          description: Upload session ID from initiate response
          example: upload-abc123
          type: string
      required:
        - upload_id
        - file_id
        - parts
      type: object
    MultipartInitiateRequest:
      properties:
        file_size:
          description: Total size of the file in bytes
          example: 7516192768
          format: int64
          type: integer
        file_type:
          $ref: "#/components/schemas/FileType"
        filename:
          description: The name of the file being uploaded
          example: large_dataset.jsonl
          type: string
        num_parts:
          description: Number of parts to split the file into (1-250)
          example: 75
          maximum: 250
          minimum: 1
          type: integer
        purpose:
          $ref: "#/components/schemas/FilePurpose"
      required:
        - filename
        - file_size
        - num_parts
        - purpose
        - file_type
      type: object
    MultipartInitiateResponse:
      properties:
        file_id:
          description: File ID for the upload
          example: file-def456
          type: string
        parts:
          description: Presigned URLs and headers for each part
          items:
            $ref: "#/components/schemas/PartInfo"
          type: array
        upload_id:
          description: Unique identifier for this multipart upload session
          example: upload-abc123
          type: string
      required:
        - upload_id
        - file_id
        - parts
      type: object
    PartInfo:
      properties:
        Headers:
          additionalProperties:
            type: string
          description: Headers to include with the upload request
          example:
            Authorization: Bearer token
          type: object
        PartNumber:
          description: Part number (1-based)
          example: 1
          type: integer
        URL:
          description: Presigned URL for uploading this part
          example: https://s3.amazonaws.com/...
          type: string
      required:
        - PartNumber
        - URL
      type: object
    Pricing:
      properties:
        base:
          example: 0
          type: number
        finetune:
          example: 0
          type: number
        hourly:
          example: 0
          type: number
        input:
          example: 0.3
          type: number
        output:
          example: 0.3
          type: number
      required:
        - hourly
        - input
        - output
        - base
        - finetune
      type: object
    PromptPart:
      items:
        properties:
          logprobs:
            $ref: "#/components/schemas/LogprobsPart"
          text:
            example: <s>[INST] What is the capital of France? [/INST]
            type: string
        type: object
      type: array
    RerankRequest:
      additionalProperties: false
      properties:
        documents:
          description: List of documents, which can be either strings or objects.
          example:
            - text: The llama is a domesticated South American camelid, widely used as a meat and pack animal by Andean cultures since the pre-Columbian era.
              title: Llama
            - text: The giant panda (Ailuropoda melanoleuca), also known as the panda bear or simply panda, is a bear species endemic to China.
              title: Panda
            - text: The guanaco is a camelid native to South America, closely related to the llama. Guanacos are one of two wild South American camelids; the other species is the vicuña, which lives at higher elevations.
              title: Guanaco
            - text: The wild Bactrian camel (Camelus ferus) is an endangered species of camel endemic to Northwest China and southwestern Mongolia.
              title: Wild Bactrian camel
          oneOf:
            - items:
                additionalProperties: true
                type: object
              type: array
            - items:
                example: Our solar system orbits the Milky Way galaxy at about 515,000 mph
                type: string
              type: array
        model:
          anyOf:
            - enum:
                - Salesforce/Llama-Rank-v1
              type: string
            - type: string
          description: |
            The model to be used for the rerank request.<br> <br> [See all of Together AI's rerank models](https://docs.together.ai/docs/serverless-models#rerank-models)
          example: Salesforce/Llama-Rank-V1
          type: string
        query:
          description: The search query to be used for ranking.
          example: What animals can I find near Peru?
          type: string
        rank_fields:
          description: List of keys in the JSON Object document to rank by. Defaults to use all supplied keys for ranking.
          example:
            - title
            - text
          items:
            type: string
          type: array
        return_documents:
          description: Whether to return supplied documents with the response.
          example: true
          type: boolean
        top_n:
          description: The number of top results to return.
          example: 2
          type: integer
      required:
        - model
        - query
        - documents
      type: object
    RerankResponse:
      properties:
        id:
          description: Request ID
          example: 9dfa1a09-5ebc-4a40-970f-586cb8f4ae47
          type: string
        model:
          description: The model to be used for the rerank request.
          example: salesforce/turboranker-0.8-3778-6328
          type: string
        object:
          description: Object type
          enum:
            - rerank
          example: rerank
          type: string
        results:
          example:
            - document:
                text: '{"title":"Llama","text":"The llama is a domesticated South American camelid, widely used as a meat and pack animal by Andean cultures since the pre-Columbian era."}'
              index: 0
              relevance_score: 0.29980177813003117
            - document:
                text: '{"title":"Guanaco","text":"The guanaco is a camelid native to South America, closely related to the llama. Guanacos are one of two wild South American camelids; the other species is the vicuña, which lives at higher elevations."}'
              index: 2
              relevance_score: 0.2752447527354349
          items:
            properties:
              document:
                properties:
                  text:
                    nullable: true
                    type: string
                type: object
              index:
                type: integer
              relevance_score:
                type: number
            required:
              - index
              - relevance_score
              - document
            type: object
          type: array
        usage:
          $ref: "#/components/schemas/UsageData"
          example:
            completion_tokens: 0
            prompt_tokens: 1837
            total_tokens: 1837
      required:
        - object
        - model
        - results
      type: object
    Response:
      properties:
        errors:
          items:
            oneOf:
              - type: string
              - additionalProperties: true
                type: object
            title: Error
          type: array
      title: Response
      type: object
    SessionListResponse:
      allOf:
        - properties:
            errors:
              items:
                oneOf:
                  - type: string
                  - additionalProperties: true
                    type: object
                title: Error
              type: array
          title: Response
          type: object
        - properties:
            data:
              properties:
                sessions:
                  items:
                    properties:
                      execute_count:
                        type: integer
                      expires_at:
                        format: date-time
                        type: string
                      id:
                        description: Session Identifier. Used to make follow-up calls.
                        example: ses_abcDEF123
                        type: string
                      last_execute_at:
                        format: date-time
                        type: string
                      started_at:
                        format: date-time
                        type: string
                    required:
                      - execute_count
                      - expires_at
                      - id
                      - last_execute_at
                      - started_at
                    type: object
                  type: array
              required:
                - sessions
          type: object
      title: SessionListResponse
      type: object
    StreamOutput:
      description: Outputs that were printed to stdout or stderr
      properties:
        data:
          type: string
        type:
          enum:
            - stdout
            - stderr
          type: string
      required:
        - type
        - data
      title: StreamOutput
    StreamSentinel:
      properties:
        data:
          enum:
            - "[DONE]"
          title: stream_signal
          type: string
      required:
        - data
      type: object
    ToolChoice:
      properties:
        function:
          properties:
            arguments:
              type: string
            name:
              example: function_name
              type: string
          required:
            - name
            - arguments
          type: object
        id:
          type: string
        # TODO: is this the right place for index?
        index:
          type: number
        type:
          enum:
            - function
          type: string
      required:
        - id
        - type
        - function
        - index
      type: object
    ToolsPart:
      properties:
        function:
          properties:
            description:
              example: A description of the function.
              type: string
            name:
              example: function_name
              type: string
            parameters:
              additionalProperties: true
              description: A map of parameter names to their values.
              type: object
          type: object
        type:
          example: tool_type
          type: string
      type: object
    TrainingMethodDPO:
      properties:
        dpo_beta:
          default: 0.1
          format: float
          type: number
        dpo_normalize_logratios_by_length:
          default: false
          type: boolean
        dpo_reference_free:
          default: false
          type: boolean
        method:
          enum:
            - dpo
          type: string
        rpo_alpha:
          default: 0.0
          format: float
          type: number
        simpo_gamma:
          default: 0.0
          format: float
          type: number
      required:
        - method
      type: object
    TrainingMethodSFT:
      properties:
        method:
          enum:
            - sft
          type: string
        train_on_inputs:
          default: auto
          description: Whether to mask the user messages in conversational data or prompts in instruction data.
          oneOf:
            - type: boolean
            - enum:
                - auto
              type: string
          type: boolean
      required:
        - method
        - train_on_inputs
      type: object
    UsageData:
      nullable: true
      properties:
        completion_tokens:
          type: integer
        prompt_tokens:
          type: integer
        total_tokens:
          type: integer
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      type: object
    VideoFrameImageInput:
      properties:
        frame:
          anyOf:
            - type: number
            - enum:
                - first
                - last
              type: string
        input_image:
          description: idk
          type: string
      required:
        - input_image
        - frame
      type: object
    VideoJob:
      description: Structured information describing a generated video job.
      properties:
        completed_at:
          description: Unix timestamp (seconds) for when the job completed, if finished.
          type: number
        created_at:
          description: Unix timestamp (seconds) for when the job was created.
          type: number
        error:
          description: Error payload that explains why generation failed, if applicable.
          properties:
            code:
              type: string
            message:
              type: string
          required:
            - message
          type: object
        id:
          description: Unique identifier for the video job.
          type: string
        model:
          description: The video generation model that produced the job.
          type: string
        object:
          description: The object type, which is always video.
          enum:
            - video
          type: string
        outputs:
          description: Available upon completion, the outputs provides the cost charged and the hosted url to access the video
          properties:
            cost:
              description: The cost of generated video charged to the owners account.
              type: integer
            video_url:
              description: URL hosting the generated video
              type: string
          required:
            - cost
            - video_url
          type: object
        seconds:
          description: Duration of the generated clip in seconds.
          type: string
        size:
          description: The resolution of the generated video.
          type: string
        status:
          $ref: "#/components/schemas/VideoStatus"
          description: Current lifecycle status of the video job.
      required:
        - id
        - model
        - status
        - size
        - seconds
        - created_at
      title: Video job
      type: object
    VideoOutputFormat:
      enum:
        - MP4
        - WEBM
      type: string
    VideoStatus:
      description: Current lifecycle status of the video job.
      enum:
        - in_progress
        - completed
        - failed
      type: string
  securitySchemes:
    bearerAuth:
      scheme: bearer
      type: http
      x-bearer-format: bearer
      x-default: default
info:
  contact:
    name: Together Support
    url: https://www.together.ai/contact
  description: The Together REST API. Please see https://docs.together.ai for more details.
  license:
    name: MIT
    url: https://github.com/togethercomputer/openapi/blob/main/LICENSE
  termsOfService: https://www.together.ai/terms-of-service
  title: Together APIs
  version: 2.0.0
openapi: 3.1.0
paths:
  /audio/speech:
    post:
      description: Generate audio from input text
      operationId: audio-speech
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/AudioSpeechRequest"
      responses:
        "200":
          content:
            application/octet-stream:
              schema:
                format: binary
                type: string
            audio/mpeg:
              schema:
                format: binary
                type: string
            audio/wav:
              schema:
                format: binary
                type: string
            text/event-stream:
              schema:
                $ref: "#/components/schemas/AudioSpeechStreamResponse"
          description: OK
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: BadRequest
        "429":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: RateLimit
      summary: Create audio generation request
      tags:
        - Audio
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.audio.speech.create(
                model="cartesia/sonic-2",
                input="The quick brown fox jumps over the lazy dog.",
                voice="laidback woman",
            )

            response.stream_to_file("audio.wav")
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";
            import { createWriteStream } from "fs";
            import { join } from "path";
            import { pipeline } from "stream/promises";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.audio.create({
              model: "cartesia/sonic-2",
              input: "The quick brown fox jumps over the lazy dog.",
              voice: "laidback woman",
            });

            const filepath = join(process.cwd(), "audio.wav");
            const writeStream = createWriteStream(filepath);

            if (response.body) {
              await pipeline(response.body, writeStream);
            }
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";
            import { createWriteStream } from "fs";
            import { join } from "path";
            import { pipeline } from "stream/promises";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.audio.create({
              model: "cartesia/sonic-2",
              input: "The quick brown fox jumps over the lazy dog.",
              voice: "laidback woman",
            });

            const filepath = join(process.cwd(), "audio.wav");
            const writeStream = createWriteStream(filepath);

            if (response.body) {
              await pipeline(response.body, writeStream);
            }
        - label: cURL
          lang: Shell
          source: |
            curl -X POST "https://api.together.xyz/v1/audio/speech" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "model": "cartesia/sonic-2",
                   "input": "The quick brown fox jumps over the lazy dog.",
                   "voice": "laidback woman"
                 }' \
                 --output audio.wav
  /audio/transcriptions:
    post:
      description: Transcribes audio into text
      operationId: audio-transcriptions
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: "#/components/schemas/AudioTranscriptionRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AudioTranscriptionResponse"
          description: OK
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: BadRequest
        "401":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Unauthorized
        "429":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: RateLimit
      summary: Create audio transcription request
      tags:
        - Audio
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            file = open("audio.wav", "rb")

            response = client.audio.transcriptions.create(
                model="openai/whisper-large-v3",
                file=file,
            )

            print(response.text)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";
            import { readFileSync } from "fs";
            import { join } from "path";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const audioFilePath = join(process.cwd(), "audio.wav");
            const audioBuffer = readFileSync(audioFilePath);
            const audioFile = new File([audioBuffer], "audio.wav", { type: "audio/wav" });

            const response = await client.audio.transcriptions.create({
              model: "openai/whisper-large-v3",
              file: audioFile,
            });

            console.log(response.text);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";
            import { readFileSync } from "fs";
            import { join } from "path";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const audioFilePath = join(process.cwd(), "audio.wav");
            const audioBuffer = readFileSync(audioFilePath);
            const audioFile = new File([audioBuffer], "audio.wav", { type: "audio/wav" });

            const response = await client.audio.transcriptions.create({
              model: "openai/whisper-large-v3",
              file: audioFile,
            });

            console.log(response.text);
        - label: cURL
          lang: Shell
          source: |
            curl -X POST "https://api.together.xyz/v1/audio/transcriptions" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -F "file=@audio.wav" \
                 -F "model=openai/whisper-large-v3"
  /audio/translations:
    post:
      description: Translates audio into English
      operationId: audio-translations
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: "#/components/schemas/AudioTranslationRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AudioTranslationResponse"
          description: OK
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: BadRequest
        "401":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Unauthorized
        "429":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: RateLimit
      summary: Create audio translation request
      tags:
        - Audio
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            file = open("audio.wav", "rb")

            response = client.audio.translations.create(
                model="openai/whisper-large-v3",
                file=file,
                language="es",
            )

            print(response.text)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";
            import { readFileSync } from "fs";
            import { join } from "path";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const audioFilePath = join(process.cwd(), "audio.wav");
            const audioBuffer = readFileSync(audioFilePath);
            const audioFile = new File([audioBuffer], "audio.wav", { type: "audio/wav" });

            const response = await client.audio.translations.create({
              model: "openai/whisper-large-v3",
              file: audioFile,
              language: "es"
            });

            console.log(response.text);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";
            import { readFileSync } from "fs";
            import { join } from "path";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const audioFilePath = join(process.cwd(), "audio.wav");
            const audioBuffer = readFileSync(audioFilePath);
            const audioFile = new File([audioBuffer], "audio.wav", { type: "audio/wav" });

            const response = await client.audio.translations.create({
              model: "openai/whisper-large-v3",
              file: audioFile,
              language: "es"
            });

            console.log(response.text);
        - label: cURL
          lang: Shell
          source: |
            curl -X POST "https://api.together.xyz/v1/audio/transcriptions" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -F "file=@audio.wav" \
                 -F "model=openai/whisper-large-v3" \
                 -F "language=es"
  /batches:
    get:
      description: List all batch jobs for the authenticated user
      responses:
        "200":
          content:
            application/json:
              schema:
                items:
                  $ref: "#/components/schemas/BatchJob"
                type: array
          description: OK
        "401":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/BatchErrorResponse"
          description: Unauthorized
        "500":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/BatchErrorResponse"
          description: Internal Server Error
      security:
        - bearerAuth: []
      summary: List batch jobs
      tags:
        - Batches
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            batches = client.batches.list_batches()

            for batch in batches:
                print(batch.id)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const batches = await client.batches.list();

            console.log(batches);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const batches = await client.batches.list();

            console.log(batches);
        - label: cURL
          lang: Shell
          source: |
            curl "https://api.together.xyz/v1/batches" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
    post:
      description: Create a new batch job with the given input file and endpoint
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateBatchRequest"
        required: true
      responses:
        "201":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/BatchJobWithWarning"
          description: Job created (potentially with warnings)
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/BatchErrorResponse"
          description: Bad Request
        "401":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/BatchErrorResponse"
          description: Unauthorized
        "429":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/BatchErrorResponse"
          description: Too Many Requests
        "500":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/BatchErrorResponse"
          description: Internal Server Error
      security:
        - bearerAuth: []
      summary: Create a batch job
      tags:
        - Batches
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            batch = client.batches.create_batch("file_id", endpoint="/v1/chat/completions")

            print(batch.id)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const batch = await client.batches.create({
              endpoint: "/v1/chat/completions",
              input_file_id: "file-id",
            });

            console.log(batch);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const batch = await client.batches.create({
              endpoint: "/v1/chat/completions",
              input_file_id: "file-id",
            });

            console.log(batch);
        - label: cURL
          lang: Shell
          source: |
            curl -X POST "https://api.together.xyz/v1/batches" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "endpoint": "/v1/chat/completions",
                   "input_file_id": "file-id"
                 }'
  /batches/{id}:
    get:
      description: Get details of a batch job by ID
      parameters:
        - description: Job ID
          example: batch_job_abc123def456
          in: path
          name: id
          required: true
          schema:
            type: string
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/BatchJob"
          description: OK
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/BatchErrorResponse"
          description: Bad Request
        "401":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/BatchErrorResponse"
          description: Unauthorized
        "403":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/BatchErrorResponse"
          description: Forbidden
        "404":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/BatchErrorResponse"
          description: Not Found
        "500":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/BatchErrorResponse"
          description: Internal Server Error
      security:
        - bearerAuth: []
      summary: Get a batch job
      tags:
        - Batches
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            batch = client.batches.get_batch("batch_id")

            print(batch)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const batch = await client.batches.retrieve("batch-id");

            console.log(batch);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const batch = await client.batches.retrieve("batch-id");

            console.log(batch);
        - label: cURL
          lang: Shell
          source: |
            curl "https://api.together.xyz/v1/batches/ID" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
  /chat/completions:
    post:
      deprecated: false
      description: Query a chat model.
      operationId: chat-completions
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ChatCompletionRequest"
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ChatCompletionResponse"
            text/event-stream:
              schema:
                $ref: "#/components/schemas/ChatCompletionStream"
          description: "200"
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: BadRequest
        "401":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Unauthorized
        "404":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: NotFound
        "429":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: RateLimit
        "503":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Overloaded
        "504":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Timeout
      summary: Create chat completion
      tags:
        - Chat
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.chat.completions.create(
                model="meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "What are some fun things to do in New York?"},
                ]
            )

            print(response.choices[0].message.content)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.chat.completions.create({
              model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
              messages: [
                { role: "system", content: "You are a helpful assistant." },
                { role: "user", "content": "What are some fun things to do in New York?" },
              ],
            });

            console.log(response.choices[0].message?.content);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.chat.completions.create({
              model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
              messages: [
                { role: "system", content: "You are a helpful assistant." },
                { role: "user", "content": "What are some fun things to do in New York?" },
              ],
            });

            console.log(response.choices[0].message?.content);
        - label: cURL
          lang: Shell
          source: |
            curl -X POST "https://api.together.xyz/v1/chat/completions" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "model": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
                   "messages": [
                     {"role": "system", "content": "You are a helpful assistant."},
                     {"role": "user", "content": "What are some fun things to do in New York?"}
                   ]
                 }'
  /completions:
    post:
      deprecated: false
      description: Query a language, code, or image model.
      operationId: completions
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CompletionRequest"
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CompletionResponse"
            text/event-stream:
              schema:
                $ref: "#/components/schemas/CompletionStream"
          description: "200"
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: BadRequest
        "401":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Unauthorized
        "404":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: NotFound
        "429":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: RateLimit
        "503":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Overloaded
        "504":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Timeout
      summary: Create completion
      tags:
        - Completion
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.completions.create(
                model="meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
                prompt="The largest city in France is",
                max_tokens=1
            )

            print(response.choices[0].text)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.completions.create({
              model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
              prompt: "The largest city in France is",
              max_tokens: 1
            });

            console.log(response.choices[0].text);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.completions.create({
              model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
              prompt: "The largest city in France is",
              max_tokens: 1
            });

            console.log(response.choices[0].text);
        - label: cURL
          lang: Shell
          source: |
            curl -X POST "https://api.together.xyz/v1/completions" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "model": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
                   "prompt": "The largest city in France is",
                   "max_tokens": 1
                 }'
  /embeddings:
    post:
      deprecated: false
      description: Query an embedding model for a given string of text.
      operationId: embeddings
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/EmbeddingsRequest"
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/EmbeddingsResponse"
          description: "200"
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: BadRequest
        "401":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Unauthorized
        "404":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: NotFound
        "429":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: RateLimit
        "503":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Overloaded
        "504":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Timeout
      summary: Create embedding
      tags:
        - Embeddings
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.embeddings.create(
                model="BAAI/bge-large-en-v1.5",
                input="New York City",
            )

            print(response.data[0].embedding)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.embeddings.create({
              model: "BAAI/bge-large-en-v1.5",
              input: "New York City",
            });

            console.log(response.data[0].embedding);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.embeddings.create({
              model: "BAAI/bge-large-en-v1.5",
              input: "New York City",
            });

            console.log(response.data[0].embedding);
        - label: cURL
          lang: Shell
          source: |
            curl -X POST "https://api.together.xyz/v1/embeddings" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "model": "BAAI/bge-large-en-v1.5",
                   "input": "New York City"
                 }'
  /endpoints:
    get:
      description: Returns a list of all endpoints associated with your account. You can filter the results by type (dedicated or serverless).
      operationId: listEndpoints
      parameters:
        - description: Filter endpoints by type
          example: dedicated
          in: query
          name: type
          required: false
          schema:
            enum:
              - dedicated
              - serverless
            type: string
      responses:
        "200":
          content:
            application/json:
              schema:
                example:
                  data:
                    - created_at: "2024-02-28T21:34:35.444Z"
                      id: endpoint-5c0c20db-62fe-4f41-8ffc-d9e4ea1a264e
                      model: allenai/OLMo-7B
                      name: allenai/OLMo-7B
                      object: endpoint
                      owner: together
                      state: STARTED
                      type: serverless
                  object: list
                properties:
                  data:
                    items:
                      $ref: "#/components/schemas/ListEndpoint"
                    type: array
                  object:
                    enum:
                      - list
                    type: string
                required:
                  - object
                  - data
                type: object
          description: "200"
        "403":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Unauthorized
        "500":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Internal error
      summary: List all endpoints, can be filtered by type
      tags:
        - Endpoints
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            endpoints = client.endpoints.list()

            for endpoint in endpoints:
                print(endpoint.id)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoints = await client.endpoints.list();

            for (const endpoint of endpoints.data) {
              console.log(endpoint);
            }
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoints = await client.endpoints.list();

            for (const endpoint of endpoints.data) {
              console.log(endpoint);
            }
        - label: cURL
          lang: Shell
          source: |
            curl "https://api.together.xyz/v1/endpoints" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
    post:
      description: Creates a new dedicated endpoint for serving models. The endpoint will automatically start after creation. You can deploy any supported model on hardware configurations that meet the model's requirements.
      operationId: createEndpoint
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateEndpointRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DedicatedEndpoint"
          description: "200"
        "403":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Unauthorized
        "500":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Internal error
      summary: Create a dedicated endpoint, it will start automatically
      tags:
        - Endpoints
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            endpoint = client.endpoints.create(
                model="meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
                hardware="1x_nvidia_a100_80gb_sxm",
                min_replicas=2,
                max_replicas=5,
            )

            print(endpoint.id)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoint = await client.endpoints.create({
              model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
              hardware: "1x_nvidia_a100_80gb_sxm",
              autoscaling: {
                max_replicas: 5,
                min_replicas: 2,
              }
            });

            console.log(endpoint.id);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoint = await client.endpoints.create({
              model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
              hardware: "1x_nvidia_a100_80gb_sxm",
              autoscaling: {
                max_replicas: 5,
                min_replicas: 2,
              }
            });

            console.log(endpoint.id);
        - label: cURL
          lang: Shell
          source: |
            curl -X POST "https://api.together.xyz/v1/endpoints" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "model": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
                   "hardware": "1x_nvidia_a100_80gb_sxm",
                   "autoscaling": {
                     "max_replicas": 5,
                     "min_replicas": 2
                   }
                 }'
  /endpoints/{endpointId}:
    delete:
      description: Permanently deletes an endpoint. This action cannot be undone.
      operationId: deleteEndpoint
      parameters:
        - description: The ID of the endpoint to delete
          example: endpoint-d23901de-ef8f-44bf-b3e7-de9c1ca8f2d7
          in: path
          name: endpointId
          required: true
          schema:
            type: string
      responses:
        "204":
          description: No Content - Endpoint successfully deleted
        "403":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Unauthorized
        "404":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Not Found
        "500":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Internal error
      summary: Delete endpoint
      tags:
        - Endpoints
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            endpoint = client.endpoints.delete(
                endpoint_id="endpoint-id",
            )

            print(endpoint)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoint = await client.endpoints.delete("endpoint-id");

            console.log(endpoint);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoint = await client.endpoints.delete("endpoint-id");

            console.log(endpoint);
        - label: cURL
          lang: Shell
          source: |
            curl -X "DELETE" "https://api.together.xyz/v1/endpoints/endpoint-id" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY"
    get:
      description: Retrieves details about a specific endpoint, including its current state, configuration, and scaling settings.
      operationId: getEndpoint
      parameters:
        - description: The ID of the endpoint to retrieve
          example: endpoint-d23901de-ef8f-44bf-b3e7-de9c1ca8f2d7
          in: path
          name: endpointId
          required: true
          schema:
            type: string
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DedicatedEndpoint"
          description: "200"
        "403":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Unauthorized
        "404":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Not Found
        "500":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Internal error
      summary: Get endpoint by ID
      tags:
        - Endpoints
      x-codeSamples:
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoint = await client.endpoints.retrieve("endpoint-id");

            console.log(endpoint);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoint = await client.endpoints.retrieve("endpoint-id");

            console.log(endpoint);
        - label: cURL
          lang: Shell
          source: |
            curl "https://api.together.xyz/v1/endpoints/endpoint-id" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
    patch:
      description: Updates an existing endpoint's configuration. You can modify the display name, autoscaling settings, or change the endpoint's state (start/stop).
      operationId: updateEndpoint
      parameters:
        - description: The ID of the endpoint to update
          example: endpoint-d23901de-ef8f-44bf-b3e7-de9c1ca8f2d7
          in: path
          name: endpointId
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              properties:
                autoscaling:
                  $ref: "#/components/schemas/Autoscaling"
                  description: New autoscaling configuration for the endpoint
                display_name:
                  description: A human-readable name for the endpoint
                  example: My Llama3 70b endpoint
                  type: string
                inactive_timeout:
                  description: The number of minutes of inactivity after which the endpoint will be automatically stopped. Set to 0 to disable automatic timeout.
                  example: 60
                  nullable: true
                  type: integer
                state:
                  description: The desired state of the endpoint
                  enum:
                    - STARTED
                    - STOPPED
                  example: STARTED
                  type: string
              type: object
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DedicatedEndpoint"
          description: "200"
        "403":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Unauthorized
        "404":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Not Found
        "500":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Internal error
      summary: Update endpoint, this can also be used to start or stop a dedicated endpoint
      tags:
        - Endpoints
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            endpoint = client.endpoints.update(
                endpoint_id="endpoint-id",
                state="STOPPED"
            )

            print(endpoint)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoint = await client.endpoints.update("endpoint-id", {
              state: "STOPPED"
            });

            console.log(endpoint);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoint = await client.endpoints.update("endpoint-id", {
              state: "STOPPED"
            });

            console.log(endpoint);
        - label: cURL
          lang: Shell
          source: |
            curl -X PATCH "https://api.together.xyz/v1/endpoints/endpoint-id" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "state": "STOPPED"
                 }'
  /evaluation/{id}:
    get:
      description: Get details of a specific evaluation job
      operationId: evaluation-get
      parameters:
        - description: The evaluation job ID
          in: path
          name: id
          required: true
          schema:
            type: string
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/EvaluationJob"
          description: Successful response
        "404":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Job not found
        "500":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Internal server error
      summary: Get evaluation job details
      tags:
        - Evaluations
  /evaluation/{id}/status:
    get:
      description: Get the status and results of a specific evaluation job
      operationId: evaluation-status
      parameters:
        - description: The evaluation job ID
          in: path
          name: id
          required: true
          schema:
            type: string
      responses:
        "200":
          content:
            application/json:
              schema:
                properties:
                  results:
                    nullable: true
                    oneOf:
                      - $ref: "#/components/schemas/EvaluationClassifyResults"
                      - $ref: "#/components/schemas/EvaluationScoreResults"
                      - $ref: "#/components/schemas/EvaluationCompareResults"
                      - properties:
                          error:
                            type: string
                        type: object
                  status:
                    enum:
                      - pending
                      - queued
                      - running
                      - completed
                      - error
                      - user_error
                    example: completed
                    type: string
                type: object
          description: Successful response
        "404":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Job not found
        "500":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Internal server error
      summary: Get evaluation job status and results
      tags:
        - Evaluations
  /evaluations:
    get:
      description: Get a list of evaluation jobs with optional filtering
      operationId: evaluations-list
      parameters:
        - description: Filter by job status
          in: query
          name: status
          schema:
            enum:
              - pending
              - queued
              - running
              - completed
              - error
              - user_error
            type: string
        - description: Maximum number of results to return (max 100)
          in: query
          name: limit
          schema:
            default: 10
            maximum: 100
            minimum: 1
            type: integer
      responses:
        "200":
          content:
            application/json:
              schema:
                items:
                  $ref: "#/components/schemas/EvaluationJob"
                type: array
          description: Successful response
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Bad request
      summary: List evaluation jobs
      tags:
        - Evaluations
      x-stainless-resource-name: evaluationList
  /evaluations/model-list:
    get:
      description: Get the list of models that are allowed for evaluation
      operationId: evaluations-model-list
      responses:
        "200":
          content:
            application/json:
              schema:
                properties:
                  model_list:
                    items:
                      type: string
                    type: array
                type: object
          description: Successful response
        "500":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Internal server error
      summary: Get allowed models list
      tags:
        - Evaluations
  /files:
    get:
      description: List the metadata for all uploaded data files.
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FileList"
          description: List of files
      summary: List all files
      tags:
        - Files
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.files.list()

            for file in response.data:
                print(file.id)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.files.list();

            for (const file of response.data) {
              console.log(file.id);
            }
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.files.list();

            for (const file of response.data) {
              console.log(file.id);
            }
        - label: cURL
          lang: Shell
          source: |
            curl "https://api.together.xyz/v1/files" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
  /files/multipart/abort:
    post:
      description: Abort a multipart upload and clean up any uploaded parts.
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/MultipartAbortRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                properties:
                  success:
                    example: true
                    type: boolean
                type: object
          description: Multipart upload aborted successfully
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Bad Request
        "401":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Unauthorized
      summary: Abort multipart upload
      tags:
        - Files
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            client.files.multipart.abort(
                upload_id="upload-123",
                file_id="file-456"
            )
  /files/multipart/complete:
    post:
      description: Complete a multipart upload by providing ETags for all uploaded parts.
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/MultipartCompleteRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FileResponse"
          description: Multipart upload completed successfully
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Bad Request
        "401":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Unauthorized
      summary: Complete multipart upload
      tags:
        - Files
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.files.multipart.complete(
                upload_id="upload-123",
                file_id="file-456",
                parts=[
                    {"PartNumber": 1, "ETag": "etag1"},
                    {"PartNumber": 2, "ETag": "etag2"}
                ]
            )

            print(response.id)
  /files/multipart/initiate:
    post:
      description: Initiate a multipart upload for large files (>5GB) with presigned URLs for each part.
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/MultipartInitiateRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/MultipartInitiateResponse"
          description: Multipart upload initiated successfully
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Bad Request
        "401":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Unauthorized
      summary: Initiate multipart upload
      tags:
        - Files
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.files.multipart.initiate(
                filename="large_dataset.jsonl",
                file_size=7516192768,  # 7GB
                num_parts=75,
                purpose="fine-tune",
                file_type="jsonl"
            )

            print(response.upload_id)
  /files/upload:
    post:
      description: Upload a file with specified purpose, file name, and file type.
      requestBody:
        content:
          multipart/form-data:
            schema:
              properties:
                file:
                  description: The content of the file being uploaded
                  format: binary
                  type: string
                file_name:
                  description: The name of the file being uploaded
                  example: dataset.csv
                  type: string
                file_type:
                  $ref: "#/components/schemas/FileType"
                purpose:
                  $ref: "#/components/schemas/FilePurpose"
              required:
                - purpose
                - file_name
                - file
              type: object
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FileResponse"
          description: File uploaded successfully
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Bad Request
        "401":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Unauthorized
        "500":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Internal Server Error
      summary: Upload a file
      tags:
        - Files
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            current_dir = os.path.dirname(os.path.abspath(__file__))
            file_path = os.path.join(current_dir, "data.jsonl")
            file = client.files.upload(file=file_path)

            print(file.id)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import { upload } from "together-ai/lib/upload"
            import path from "path";
            import { fileURLToPath } from "url";

            const __filename = fileURLToPath(import.meta.url);
            const __dirname = path.dirname(__filename);
            const filepath = path.join(__dirname, "data.jsonl");
            const file = await upload(filepath);

            console.log(file.id);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import { upload } from "together-ai/lib/upload"
            import path from "path";
            import { fileURLToPath } from "url";

            const __filename = fileURLToPath(import.meta.url);
            const __dirname = path.dirname(__filename);
            const filepath = path.join(__dirname, "data.jsonl");
            const file = await upload(filepath);

            console.log(file.id);
        - label: cURL
          lang: Shell
          source: |
            curl "https://api.together.xyz/v1/files/upload" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -F "file=@/path/to/data.jsonl" \
                 -F "file_name=data.jsonl" \
                 -F "purpose=fine-tune"
  /files/{id}:
    delete:
      description: Delete a previously uploaded data file.
      parameters:
        - in: path
          name: id
          required: true
          schema:
            type: string
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FileDeleteResponse"
          description: File deleted successfully
      summary: Delete a file
      tags:
        - Files
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.files.delete(id="file-id")

            print(response)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.files.delete("file-id");

            console.log(response);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.files.delete("file-id");

            console.log(response);
        - label: cURL
          lang: Shell
          source: |
            curl -X "DELETE" "https://api.together.xyz/v1/files/file-id" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY"
    get:
      description: List the metadata for a single uploaded data file.
      parameters:
        - in: path
          name: id
          required: true
          schema:
            type: string
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FileResponse"
          description: File retrieved successfully
      summary: List file
      tags:
        - Files
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            file = client.files.retrieve(id="file-id")

            print(file)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const file = await client.files.retrieve("file-id");

            console.log(file);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const file = await client.files.retrieve("file-id");

            console.log(file);
        - label: cURL
          lang: Shell
          source: |
            curl "https://api.together.xyz/v1/files/ID" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
  /files/{id}/content:
    get:
      description: Get the contents of a single uploaded data file.
      parameters:
        - in: path
          name: id
          required: true
          schema:
            type: string
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FileObject"
          description: File content retrieved successfully
        "500":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Internal Server Error
      summary: Get file contents
      tags:
        - Files
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            file = client.files.retrieve_content(id="file-id")

            print(file.filename)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.files.content("file-id");
            const content = await response.text();

            console.log(content);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.files.content("file-id");
            const content = await response.text();

            console.log(content);
        - label: cURL
          lang: Shell
          source: |
            curl "https://api.together.xyz/v1/files/file-id/content" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
  /fine-tunes:
    get:
      description: List the metadata for all fine-tuning jobs. Returns a list of FinetuneResponseTruncated objects.
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FinetuneTruncatedList"
          description: List of fine-tune jobs
      summary: List all jobs
      tags:
        - Fine-tuning
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.fine_tuning.list()

            for fine_tune in response.data:
                print(f"ID: {fine_tune.id}, Status: {fine_tune.status}")
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.fineTune.list();

            for (const fineTune of response.data) {
              console.log(fineTune.id, fineTune.status);
            }
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.fineTune.list();

            for (const fineTune of response.data) {
              console.log(fineTune.id, fineTune.status);
            }
        - label: cURL
          lang: Shell
          source: |
            curl "https://api.together.xyz/v1/fine-tunes" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
    post:
      description: Create a fine-tuning job with the provided model and training data.
      requestBody:
        content:
          application/json:
            schema:
              properties:
                batch_size:
                  default: max
                  description: Number of training examples processed together (larger batches use more memory but may train faster). Defaults to "max". We use training optimizations like packing, so the effective batch size may be different than the value you set.
                  oneOf:
                    - type: integer
                    - enum:
                        - max
                      type: string
                from_checkpoint:
                  description: The checkpoint identifier to continue training from a previous fine-tuning job. Format is `{$JOB_ID}` or `{$OUTPUT_MODEL_NAME}` or `{$JOB_ID}:{$STEP}` or `{$OUTPUT_MODEL_NAME}:{$STEP}`. The step value is optional; without it, the final checkpoint will be used.
                  type: string
                from_hf_model:
                  description: The Hugging Face Hub repo to start training from. Should be as close as possible to the base model (specified by the `model` argument) in terms of architecture and size.
                  type: string
                hf_api_token:
                  description: The API token for the Hugging Face Hub.
                  type: string
                hf_model_revision:
                  description: The revision of the Hugging Face Hub model to continue training from. E.g., hf_model_revision=main (default, used if the argument is not provided) or hf_model_revision='607a30d783dfa663caf39e06633721c8d4cfcd7e' (specific commit).
                  type: string
                hf_output_repo_name:
                  description: The name of the Hugging Face repository to upload the fine-tuned model to.
                  type: string
                learning_rate:
                  default: 0.00001
                  description: Controls how quickly the model adapts to new information (too high may cause instability, too low may slow convergence)
                  format: float
                  type: number
                lr_scheduler:
                  $ref: "#/components/schemas/LRScheduler"
                  default: none
                  description: The learning rate scheduler to use. It specifies how the learning rate is adjusted during training.
                  type: object
                max_grad_norm:
                  default: 1.0
                  description: Max gradient norm to be used for gradient clipping. Set to 0 to disable.
                  format: float
                  type: number
                model:
                  description: Name of the base model to run fine-tune job on
                  type: string
                n_checkpoints:
                  default: 1
                  description: Number of intermediate model versions saved during training for evaluation
                  type: integer
                n_epochs:
                  default: 1
                  description: Number of complete passes through the training dataset (higher values may improve results but increase cost and risk of overfitting)
                  type: integer
                n_evals:
                  default: 0
                  description: Number of evaluations to be run on a given validation set during training
                  type: integer
                suffix:
                  description: Suffix that will be added to your fine-tuned model name
                  type: string
                train_on_inputs:
                  default: auto
                  deprecated: true
                  description: Whether to mask the user messages in conversational data or prompts in instruction data.
                  oneOf:
                    - type: boolean
                    - enum:
                        - auto
                      type: string
                  type: boolean
                training_file:
                  description: File-ID of a training file uploaded to the Together API
                  type: string
                training_method:
                  description: The training method to use. 'sft' for Supervised Fine-Tuning or 'dpo' for Direct Preference Optimization.
                  oneOf:
                    - $ref: "#/components/schemas/TrainingMethodSFT"
                    - $ref: "#/components/schemas/TrainingMethodDPO"
                  type: object
                training_type:
                  oneOf:
                    - $ref: "#/components/schemas/FullTrainingType"
                    - $ref: "#/components/schemas/LoRATrainingType"
                  type: object
                validation_file:
                  description: File-ID of a validation file uploaded to the Together API
                  type: string
                wandb_api_key:
                  description: Integration key for tracking experiments and model metrics on W&B platform
                  type: string
                wandb_base_url:
                  description: The base URL of a dedicated Weights & Biases instance.
                  type: string
                wandb_name:
                  description: The Weights & Biases name for your run.
                  type: string
                wandb_project_name:
                  description: The Weights & Biases project for your run. If not specified, will use `together` as the project name.
                  type: string
                warmup_ratio:
                  default: 0.0
                  description: The percent of steps at the start of training to linearly increase the learning rate.
                  format: float
                  type: number
                weight_decay:
                  default: 0.0
                  description: Weight decay. Regularization parameter for the optimizer.
                  format: float
                  type: number
              required:
                - training_file
                - model
              type: object
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FinetuneResponseTruncated"
          description: Fine-tuning job initiated successfully
      summary: Create job
      tags:
        - Fine-tuning
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.fine_tuning.create(
                model="meta-llama/Meta-Llama-3.1-8B-Instruct-Reference",
                training_file="file-id"
            )

            print(response)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.fineTune.create({
              model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Reference",
              training_file: "file-id",
            });

            console.log(response);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.fineTune.create({
              model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Reference",
              training_file: "file-id",
            });

            console.log(response);
        - label: cURL
          lang: Shell
          source: |
            curl -X POST "https://api.together.xyz/v1/fine-tunes" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "model": "meta-llama/Meta-Llama-3.1-8B-Instruct-Reference",
                   "training_file": "file-id"
                 }'
  /fine-tunes/{id}:
    delete:
      description: Delete a fine-tuning job.
      parameters:
        - in: path
          name: id
          required: true
          schema:
            type: string
        - in: query
          name: force
          required: true
          schema:
            default: null
            type: boolean
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FinetuneDeleteResponse"
          description: Fine-tune job deleted successfully
        "404":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Fine-tune job not found
        "500":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Internal server error
      summary: Delete a fine-tune job
      tags:
        - Fine-tuning
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.fine_tuning.delete(id="ft-id")

            print(response)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.fineTune.delete("ft-id");

            console.log(response);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.fineTune.delete("ft-id");

            console.log(response);
        - label: cURL
          lang: Shell
          source: |
            curl -X "DELETE" "https://api.together.xyz/v1/fine-tunes/ft-id?force=false" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
    get:
      description: List the metadata for a single fine-tuning job.
      parameters:
        - in: path
          name: id
          required: true
          schema:
            type: string
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FinetuneResponse"
          description: Fine-tune job details retrieved successfully
      summary: List job
      tags:
        - Fine-tuning
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            fine_tune = client.fine_tuning.retrieve(id="ft-id")

            print(fine_tune)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const fineTune = await client.fineTune.retrieve("ft-id");

            console.log(fineTune);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const fineTune = await client.fineTune.retrieve("ft-id");

            console.log(fineTune);
        - label: cURL
          lang: Shell
          source: |
            curl "https://api.together.xyz/v1/fine-tunes/ft-id" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
  /fine-tunes/{id}/cancel:
    post:
      description: Cancel a currently running fine-tuning job. Returns a FinetuneResponseTruncated object.
      parameters:
        - description: Fine-tune ID to cancel. A string that starts with `ft-`.
          in: path
          name: id
          required: true
          schema:
            type: string
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FinetuneResponseTruncated"
          description: Successfully cancelled the fine-tuning job.
        "400":
          description: Invalid request parameters.
        "404":
          description: Fine-tune ID not found.
      summary: Cancel job
      tags:
        - Fine-tuning
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.fine_tuning.cancel(id="ft-id")

            print(response)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.fineTune.cancel("ft-id");

            console.log(response);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.fineTune.cancel("ft-id");

            console.log(response);
        - label: cURL
          lang: Shell
          source: |
            curl -X POST "https://api.together.xyz/v1/fine-tunes/ft-id/cancel" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
  /fine-tunes/{id}/checkpoints:
    get:
      description: List the checkpoints for a single fine-tuning job.
      parameters:
        - in: path
          name: id
          required: true
          schema:
            type: string
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FinetuneListCheckpoints"
          description: List of fine-tune checkpoints
      summary: List checkpoints
      tags:
        - Fine-tuning
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            checkpoints = client.fine_tuning.list_checkpoints(id="ft-id")

            print(checkpoints)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const checkpoints = await client.fineTune.retrieveCheckpoints("ft-id");

            console.log(checkpoints);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const checkpoints = await client.fineTune.retrieveCheckpoints("ft-id");

            console.log(checkpoints);
        - label: cURL
          lang: Shell
          source: |
            curl "https://api.together.xyz/v1/fine-tunes/ft-id/checkpoints" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
  /fine-tunes/{id}/events:
    get:
      description: List the events for a single fine-tuning job.
      parameters:
        - in: path
          name: id
          required: true
          schema:
            type: string
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FinetuneListEvents"
          description: List of fine-tune events
      summary: List job events
      tags:
        - Fine-tuning
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            events = client.fine_tuning.list_events(id="ft-id")

            print(events)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const events = await client.fineTune.listEvents("ft-id");

            console.log(events);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const events = await client.fineTune.listEvents("ft-id");

            console.log(events);
        - label: cURL
          lang: Shell
          source: |
            curl "https://api.together.xyz/v1/fine-tunes/ft-id/events" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
  /finetune/download:
    get:
      description: Download a compressed fine-tuned model or checkpoint to local disk.
      parameters:
        - description: Fine-tune ID to download. A string that starts with `ft-`.
          in: query
          name: ft_id
          required: true
          schema:
            type: string
        - description: Specifies step number for checkpoint to download. Ignores `checkpoint` value if set.
          in: query
          name: checkpoint_step
          required: false
          schema:
            type: integer
        - description: Specifies checkpoint type to download - `merged` vs `adapter`. This field is required if the checkpoint_step is not set.
          in: query
          name: checkpoint
          schema:
            enum:
              - merged
              - adapter
            type: string
        - description: Specifies output file name for downloaded model. Defaults to `$PWD/{model_name}.{extension}`.
          in: query
          name: output
          required: false
          schema:
            type: string
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/FinetuneDownloadResult"
          description: Successfully downloaded the fine-tuned model or checkpoint.
        "400":
          description: Invalid request parameters.
        "404":
          description: Fine-tune ID not found.
      summary: Download model
      tags:
        - Fine-tuning
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.fine_tuning.download(id="ft-id")

            print(response)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.fineTune.download({
              ft_id: "ft-id",
              checkpoint: "merged",
            });

            console.log(response);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.fineTune.download({
              ft_id: "ft-id",
              checkpoint: "merged",
            });

            console.log(response);
        - label: cURL
          lang: Shell
          source: |
            curl "https://api.together.xyz/v1/finetune/download?ft_id=ft-id&checkpoint=merged"
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
  /hardware:
    get:
      description: |
        Returns a list of available hardware configurations for deploying models. When a model parameter is provided, it returns only hardware configurations compatible with that model, including their current availability status.
      operationId: listHardware
      parameters:
        - description: |
            Filter hardware configurations by model compatibility. When provided, the response includes availability status for each compatible configuration.
          example: meta-llama/Llama-3-70b-chat-hf
          in: query
          name: model
          required: false
          schema:
            type: string
      responses:
        "200":
          content:
            application/json:
              schema:
                properties:
                  data:
                    items:
                      $ref: "#/components/schemas/HardwareWithStatus"
                    type: array
                  object:
                    enum:
                      - list
                    type: string
                required:
                  - object
                  - data
                type: object
          description: List of available hardware configurations
        "403":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Unauthorized
        "500":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Internal error
      summary: List available hardware configurations
      tags:
        - Hardware
      x-codeSamples:
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const hardware = await client.hardware.list();

            console.log(hardware);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const hardware = await client.hardware.list();

            console.log(hardware);
        - label: cURL
          lang: Shell
          source: |
            curl "https://api.together.xyz/v1/hardware" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
  /images/generations:
    post:
      description: Use an image model to generate an image for a given prompt.
      requestBody:
        content:
          application/json:
            schema:
              properties:
                disable_safety_checker:
                  description: If true, disables the safety checker for image generation.
                  type: boolean
                guidance_scale:
                  default: 3.5
                  description: Adjusts the alignment of the generated image with the input prompt. Higher values (e.g., 8-10) make the output more faithful to the prompt, while lower values (e.g., 1-5) encourage more creative freedom.
                  type: number
                height:
                  default: 1024
                  description: Height of the image to generate in number of pixels.
                  type: integer
                image_loras:
                  description: An array of objects that define LoRAs (Low-Rank Adaptations) to influence the generated image.
                  items:
                    properties:
                      path:
                        description: The URL of the LoRA to apply (e.g. https://huggingface.co/strangerzonehf/Flux-Midjourney-Mix2-LoRA).
                        type: string
                      scale:
                        description: The strength of the LoRA's influence. Most LoRA's recommend a value of 1.
                        type: number
                    required:
                      - path
                      - scale
                    type: object
                  type: array
                image_url:
                  description: URL of an image to use for image models that support it.
                  type: string
                model:
                  anyOf:
                    - enum:
                        - black-forest-labs/FLUX.1-schnell-Free
                        - black-forest-labs/FLUX.1-schnell
                        - black-forest-labs/FLUX.1.1-pro
                      type: string
                    - type: string
                  description: |
                    The model to use for image generation.<br> <br> [See all of Together AI's image models](https://docs.together.ai/docs/serverless-models#image-models)
                  example: black-forest-labs/FLUX.1-schnell
                  type: string
                n:
                  default: 1
                  description: Number of image results to generate.
                  type: integer
                negative_prompt:
                  description: The prompt or prompts not to guide the image generation.
                  type: string
                output_format:
                  default: jpeg
                  description: The format of the image response. Can be either be `jpeg` or `png`. Defaults to `jpeg`.
                  enum:
                    - jpeg
                    - png
                  type: string
                prompt:
                  description: A description of the desired images. Maximum length varies by model.
                  example: cat floating in space, cinematic
                  type: string
                response_format:
                  description: Format of the image response. Can be either a base64 string or a URL.
                  enum:
                    - base64
                    - url
                  type: string
                seed:
                  description: Seed used for generation. Can be used to reproduce image generations.
                  type: integer
                steps:
                  default: 20
                  description: Number of generation steps.
                  type: integer
                width:
                  default: 1024
                  description: Width of the image to generate in number of pixels.
                  type: integer
              required:
                - prompt
                - model
              type: object
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ImageResponse"
          description: Image generated successfully
      summary: Create image
      tags:
        - Images
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.images.generate(
                model="black-forest-labs/FLUX.1-schnell",
                steps=4,
                prompt="A cartoon of an astronaut riding a horse on the moon",
            )

            print(response.data[0].url)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.images.create({
              model: "black-forest-labs/FLUX.1-schnell",
              prompt: "A cartoon of an astronaut riding a horse on the moon",
            });

            console.log(response.data[0].url);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.images.create({
              model: "black-forest-labs/FLUX.1-schnell",
              prompt: "A cartoon of an astronaut riding a horse on the moon",
            });

            console.log(response.data[0].url);
        - label: cURL
          lang: Shell
          source: |
            curl -X POST "https://api.together.xyz/v1/images/generations" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "model": "black-forest-labs/FLUX.1-schnell",
                   "prompt": "A cartoon of an astronaut riding a horse on the moon"
                 }'
  /jobs:
    get:
      description: List all jobs and their statuses
      operationId: listJobs
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/JobsInfoSuccessResponse"
          description: Jobs retrieved successfully
      summary: List all jobs
      tags:
        - Jobs
  /jobs/{jobId}:
    get:
      description: Get the status of a specific job
      operationId: getJob
      parameters:
        - description: The ID of the job to retrieve
          example: job-a15dad11-8d8e-4007-97c5-a211304de284
          in: path
          name: jobId
          required: true
          schema:
            type: string
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/JobInfoSuccessResponse"
          description: Job status retrieved successfully
      summary: Get job status
      tags:
        - Jobs
  /models:
    get:
      deprecated: false
      description: Lists all of Together's open-source models
      operationId: models
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ModelInfoList"
          description: "200"
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: BadRequest
        "401":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Unauthorized
        "404":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: NotFound
        "429":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: RateLimit
        "504":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Timeout
      summary: List all models
      tags:
        - Models
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            models = client.models.list()

            for model in models:
                print(model.id)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const models = await client.models.list();

            for (const model of models) {
              console.log(model.id);
            }
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const models = await client.models.list();

            for (const model of models) {
              console.log(model.id);
            }
        - label: cURL
          lang: Shell
          source: |
            curl "https://api.together.xyz/v1/models" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
    post:
      description: Upload a custom model or adapter from Hugging Face or S3
      operationId: uploadModel
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ModelUploadRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ModelUploadSuccessResponse"
          description: Model / adapter upload job created successfully
      summary: Upload a custom model or adapter
      tags:
        - Models
      x-codeSamples:
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.models.upload({
              model_name: "My-Fine-Tuned-Model",
              model_source: "https://ml-models.s3.us-west-2.amazonaws.com/models/my-fine-tuned-model.tar.gz",
            })

            console.log(response);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.models.upload({
              model_name: "My-Fine-Tuned-Model",
              model_source: "https://ml-models.s3.us-west-2.amazonaws.com/models/my-fine-tuned-model.tar.gz",
            })

            console.log(response);
        - label: cURL
          lang: Shell
          source: |
            curl -X POST "https://api.together.xyz/v1/models" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                    "model_name": "My-Fine-Tuned-Model",
                    "model_source": "https://ml-models.s3.us-west-2.amazonaws.com/models/my-fine-tuned-model.tar.gz"
                  }'
  /rerank:
    post:
      deprecated: false
      description: Query a reranker model
      operationId: rerank
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/RerankRequest"
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RerankResponse"
          description: "200"
        "400":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: BadRequest
        "401":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Unauthorized
        "404":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: NotFound
        "429":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: RateLimit
        "503":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Overloaded
        "504":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ErrorData"
          description: Timeout
      summary: Create a rerank request
      tags:
        - Rerank
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            documents = [
                {
                    "title": "Llama",
                    "text": "The llama is a domesticated South American camelid, widely used as a meat and pack animal by Andean cultures since the pre-Columbian era."
                },
                {
                    "title": "Panda",
                    "text": "The giant panda (Ailuropoda melanoleuca), also known as the panda bear or simply panda, is a bear species endemic to China."
                },
                {
                    "title": "Guanaco",
                    "text": "The guanaco is a camelid native to South America, closely related to the llama. Guanacos are one of two wild South American camelids; the other species is the vicuña, which lives at higher elevations."
                },
                {
                    "title": "Wild Bactrian camel",
                    "text": "The wild Bactrian camel (Camelus ferus) is an endangered species of camel endemic to Northwest China and southwestern Mongolia."
                }
            ]

            response = client.rerank.create(
                model="Salesforce/Llama-Rank-v1",
                query="What animals can I find near Peru?",
                documents=documents,
            )

            for result in response.results:
                print(f"Rank: {result.index + 1}")
                print(f"Title: {documents[result.index]['title']}")
                print(f"Text: {documents[result.index]['text']}")
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const documents = [{
              "title": "Llama",
              "text": "The llama is a domesticated South American camelid, widely used as a meat and pack animal by Andean cultures since the pre-Columbian era."
            },
            {
              "title": "Panda",
              "text": "The giant panda (Ailuropoda melanoleuca), also known as the panda bear or simply panda, is a bear species endemic to China."
            },
            {
              "title": "Guanaco",
              "text": "The guanaco is a camelid native to South America, closely related to the llama. Guanacos are one of two wild South American camelids; the other species is the vicuña, which lives at higher elevations."
            },
            {
              "title": "Wild Bactrian camel",
              "text": "The wild Bactrian camel (Camelus ferus) is an endangered species of camel endemic to Northwest China and southwestern Mongolia."
            }];

            const response = await client.rerank({
              model: "Salesforce/Llama-Rank-v1",
              query: "What animals can I find near Peru?",
              documents,
            });

            for (const result of response.results) {
              console.log(`Rank: ${result.index + 1}`);
              console.log(`Title: ${documents[result.index].title}`);
              console.log(`Text: ${documents[result.index].text}`);
            }
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const documents = [{
              "title": "Llama",
              "text": "The llama is a domesticated South American camelid, widely used as a meat and pack animal by Andean cultures since the pre-Columbian era."
            },
            {
              "title": "Panda",
              "text": "The giant panda (Ailuropoda melanoleuca), also known as the panda bear or simply panda, is a bear species endemic to China."
            },
            {
              "title": "Guanaco",
              "text": "The guanaco is a camelid native to South America, closely related to the llama. Guanacos are one of two wild South American camelids; the other species is the vicuña, which lives at higher elevations."
            },
            {
              "title": "Wild Bactrian camel",
              "text": "The wild Bactrian camel (Camelus ferus) is an endangered species of camel endemic to Northwest China and southwestern Mongolia."
            }];

            const response = await client.rerank({
              model: "Salesforce/Llama-Rank-v1",
              query: "What animals can I find near Peru?",
              documents,
            });

            for (const result of response.results) {
              console.log(`Rank: ${result.index + 1}`);
              console.log(`Title: ${documents[result.index].title}`);
              console.log(`Text: ${documents[result.index].text}`);
            }
        - label: cURL
          lang: Shell
          source: |
            curl -X POST "https://api.together.xyz/v1/rerank" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "model": "Salesforce/Llama-Rank-v1",
                   "query": "What animals can I find near Peru?",
                   "documents": [{
                      "title": "Llama",
                      "text": "The llama is a domesticated South American camelid, widely used as a meat and pack animal by Andean cultures since the pre-Columbian era."
                    },
                    {
                      "title": "Panda",
                      "text": "The giant panda (Ailuropoda melanoleuca), also known as the panda bear or simply panda, is a bear species endemic to China."
                    },
                    {
                      "title": "Guanaco",
                      "text": "The guanaco is a camelid native to South America, closely related to the llama. Guanacos are one of two wild South American camelids; the other species is the vicuña, which lives at higher elevations."
                    },
                    {
                      "title": "Wild Bactrian camel",
                      "text": "The wild Bactrian camel (Camelus ferus) is an endangered species of camel endemic to Northwest China and southwestern Mongolia."
                    }]
                 }'
  /tci/execute:
    post:
      callbacks: {}
      description: |
        Executes the given code snippet and returns the output. Without a session_id, a new session will be created to run the code. If you do pass in a valid session_id, the code will be run in that session. This is useful for running multiple code snippets in the same environment, because dependencies and similar things are persisted
        between calls to the same session.
      operationId: tci/execute
      parameters: []
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ExecuteRequest"
        description: Execute Request
        required: false
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ExecuteResponse"
          description: Execute Response
      tags:
        - Code Interpreter
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.code_interpreter.run(
                code="print('Hello world!')",
                language="python",
            )

            print(response.data.outputs[0].data);
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.codeInterpreter.execute({
              code: "print('Hello world!')",
              language: "python"
            });

            console.log(response.data?.outputs?.[0]?.data);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.codeInterpreter.execute({
              code: "print('Hello world!')",
              language: "python"
            });

            console.log(response.data?.outputs?.[0]?.data);
        - label: cURL
          lang: Shell
          source: |
            curl -X POST "https://api.together.xyz/v1/tci/execute" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "code": "print(\'Hello world!\')",
                   "language": "python"
                 }'
  /tci/sessions:
    get:
      callbacks: {}
      description: |
        Lists all your currently active sessions.
      operationId: sessions/list
      parameters: []
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/SessionListResponse"
          description: List Response
      tags:
        - Code Interpreter
      x-codeSamples:
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.codeInterpreter.sessions.list();

            for (const session of response.data?.sessions) {
              console.log(session.id);
            }
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.codeInterpreter.sessions.list();

            for (const session of response.data?.sessions) {
              console.log(session.id);
            }
        - label: cURL
          lang: Shell
          source: |
            curl "https://api.together.xyz/v1/tci/sessions" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
  /videos:
    post:
      description: Create a video
      operationId: createVideo
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateVideoBody"
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateVideoResponse"
          description: Success
      servers:
        - url: https://api.together.xyz/v2
      summary: Create video
      tags:
        - Video
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.videos.create(
                model="meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
                prompt="A cartoon of an astronaut riding a horse on the moon"
            )

            print(response.id)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.videos.create({
              model: "together/video-model",
              prompt: "A cartoon of an astronaut riding a horse on the moon",
            });

            console.log(response.id);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.videos.create({
              model: "together/video-model",
              prompt: "A cartoon of an astronaut riding a horse on the moon",
            });

            console.log(response.id);
  /videos/{id}:
    get:
      description: Fetch video metadata
      operationId: retrieveVideo
      parameters:
        - description: Identifier of video from create response.
          in: path
          name: id
          required: true
          schema:
            type: string
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VideoJob"
          description: Success
        "400":
          description: Invalid request parameters.
        "404":
          description: Video ID not found.
      servers:
        - url: https://api.together.xyz/v2
      summary: Fetch video metadata
      tags:
        - Video
      x-codeSamples:
        - label: Together AI SDK (Python)
          lang: Python
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.videos.retrieve(video_id)

            print(response.id)
        - label: Together AI SDK (TypeScript)
          lang: TypeScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.videos.retrieve(videoId);

            console.log(response.status);
        - label: Together AI SDK (JavaScript)
          lang: JavaScript
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.videos.retrieve(videoId);

            console.log(response.status);
security:
  - bearerAuth: []
servers:
  - url: https://api.together.xyz/v1
