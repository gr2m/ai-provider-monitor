{
  "description": "Create a fine-tuning job with the provided model and training data.",
  "requestBody": {
    "content": {
      "application/json": {
        "schema": {
          "properties": {
            "batch_size": {
              "default": "max",
              "description": "Number of training examples processed together (larger batches use more memory but may train faster). Defaults to \"max\". We use training optimizations like packing, so the effective batch size may be different than the value you set.",
              "oneOf": [
                {
                  "type": "integer"
                },
                {
                  "enum": [
                    "max"
                  ],
                  "type": "string"
                }
              ]
            },
            "from_checkpoint": {
              "description": "The checkpoint identifier to continue training from a previous fine-tuning job. Format is `{$JOB_ID}` or `{$OUTPUT_MODEL_NAME}` or `{$JOB_ID}:{$STEP}` or `{$OUTPUT_MODEL_NAME}:{$STEP}`. The step value is optional; without it, the final checkpoint will be used.",
              "type": "string"
            },
            "from_hf_model": {
              "description": "The Hugging Face Hub repo to start training from. Should be as close as possible to the base model (specified by the `model` argument) in terms of architecture and size.",
              "type": "string"
            },
            "hf_api_token": {
              "description": "The API token for the Hugging Face Hub.",
              "type": "string"
            },
            "hf_model_revision": {
              "description": "The revision of the Hugging Face Hub model to continue training from. E.g., hf_model_revision=main (default, used if the argument is not provided) or hf_model_revision='607a30d783dfa663caf39e06633721c8d4cfcd7e' (specific commit).",
              "type": "string"
            },
            "hf_output_repo_name": {
              "description": "The name of the Hugging Face repository to upload the fine-tuned model to.",
              "type": "string"
            },
            "learning_rate": {
              "default": 0.00001,
              "description": "Controls how quickly the model adapts to new information (too high may cause instability, too low may slow convergence)",
              "format": "float",
              "type": "number"
            },
            "lr_scheduler": {
              "default": "none",
              "description": "The learning rate scheduler to use. It specifies how the learning rate is adjusted during training.",
              "type": "object",
              "properties": {
                "lr_scheduler_args": {
                  "oneOf": [
                    {
                      "properties": {
                        "min_lr_ratio": {
                          "default": 0,
                          "description": "The ratio of the final learning rate to the peak learning rate",
                          "format": "float",
                          "type": "number"
                        }
                      },
                      "type": "object"
                    },
                    {
                      "properties": {
                        "min_lr_ratio": {
                          "default": 0,
                          "description": "The ratio of the final learning rate to the peak learning rate",
                          "format": "float",
                          "type": "number"
                        },
                        "num_cycles": {
                          "default": 0.5,
                          "description": "Number or fraction of cycles for the cosine learning rate scheduler",
                          "format": "float",
                          "type": "number"
                        }
                      },
                      "required": [
                        "min_lr_ratio",
                        "num_cycles"
                      ],
                      "type": "object"
                    }
                  ]
                },
                "lr_scheduler_type": {
                  "enum": [
                    "linear",
                    "cosine"
                  ],
                  "type": "string"
                }
              },
              "required": [
                "lr_scheduler_type"
              ]
            },
            "max_grad_norm": {
              "default": 1,
              "description": "Max gradient norm to be used for gradient clipping. Set to 0 to disable.",
              "format": "float",
              "type": "number"
            },
            "model": {
              "description": "Name of the base model to run fine-tune job on",
              "type": "string"
            },
            "n_checkpoints": {
              "default": 1,
              "description": "Number of intermediate model versions saved during training for evaluation",
              "type": "integer"
            },
            "n_epochs": {
              "default": 1,
              "description": "Number of complete passes through the training dataset (higher values may improve results but increase cost and risk of overfitting)",
              "type": "integer"
            },
            "n_evals": {
              "default": 0,
              "description": "Number of evaluations to be run on a given validation set during training",
              "type": "integer"
            },
            "suffix": {
              "description": "Suffix that will be added to your fine-tuned model name",
              "type": "string"
            },
            "train_on_inputs": {
              "default": "auto",
              "deprecated": true,
              "description": "Whether to mask the user messages in conversational data or prompts in instruction data.",
              "oneOf": [
                {
                  "type": "boolean"
                },
                {
                  "enum": [
                    "auto"
                  ],
                  "type": "string"
                }
              ],
              "type": "boolean"
            },
            "training_file": {
              "description": "File-ID of a training file uploaded to the Together API",
              "type": "string"
            },
            "training_method": {
              "description": "The training method to use. 'sft' for Supervised Fine-Tuning or 'dpo' for Direct Preference Optimization.",
              "oneOf": [
                {
                  "properties": {
                    "method": {
                      "enum": [
                        "sft"
                      ],
                      "type": "string"
                    },
                    "train_on_inputs": {
                      "default": "auto",
                      "description": "Whether to mask the user messages in conversational data or prompts in instruction data.",
                      "oneOf": [
                        {
                          "type": "boolean"
                        },
                        {
                          "enum": [
                            "auto"
                          ],
                          "type": "string"
                        }
                      ],
                      "type": "boolean"
                    }
                  },
                  "required": [
                    "method",
                    "train_on_inputs"
                  ],
                  "type": "object"
                },
                {
                  "properties": {
                    "dpo_beta": {
                      "default": 0.1,
                      "format": "float",
                      "type": "number"
                    },
                    "dpo_normalize_logratios_by_length": {
                      "default": false,
                      "type": "boolean"
                    },
                    "dpo_reference_free": {
                      "default": false,
                      "type": "boolean"
                    },
                    "method": {
                      "enum": [
                        "dpo"
                      ],
                      "type": "string"
                    },
                    "rpo_alpha": {
                      "default": 0,
                      "format": "float",
                      "type": "number"
                    },
                    "simpo_gamma": {
                      "default": 0,
                      "format": "float",
                      "type": "number"
                    }
                  },
                  "required": [
                    "method"
                  ],
                  "type": "object"
                }
              ],
              "type": "object"
            },
            "training_type": {
              "oneOf": [
                {
                  "properties": {
                    "type": {
                      "enum": [
                        "Full"
                      ],
                      "type": "string"
                    }
                  },
                  "required": [
                    "type"
                  ],
                  "type": "object"
                },
                {
                  "properties": {
                    "lora_alpha": {
                      "type": "integer"
                    },
                    "lora_dropout": {
                      "default": 0,
                      "format": "float",
                      "type": "number"
                    },
                    "lora_r": {
                      "type": "integer"
                    },
                    "lora_trainable_modules": {
                      "default": "all-linear",
                      "type": "string"
                    },
                    "type": {
                      "enum": [
                        "Lora"
                      ],
                      "type": "string"
                    }
                  },
                  "required": [
                    "type",
                    "lora_r",
                    "lora_alpha"
                  ],
                  "type": "object"
                }
              ],
              "type": "object"
            },
            "validation_file": {
              "description": "File-ID of a validation file uploaded to the Together API",
              "type": "string"
            },
            "wandb_api_key": {
              "description": "Integration key for tracking experiments and model metrics on W&B platform",
              "type": "string"
            },
            "wandb_base_url": {
              "description": "The base URL of a dedicated Weights & Biases instance.",
              "type": "string"
            },
            "wandb_name": {
              "description": "The Weights & Biases name for your run.",
              "type": "string"
            },
            "wandb_project_name": {
              "description": "The Weights & Biases project for your run. If not specified, will use `together` as the project name.",
              "type": "string"
            },
            "warmup_ratio": {
              "default": 0,
              "description": "The percent of steps at the start of training to linearly increase the learning rate.",
              "format": "float",
              "type": "number"
            },
            "weight_decay": {
              "default": 0,
              "description": "Weight decay. Regularization parameter for the optimizer.",
              "format": "float",
              "type": "number"
            }
          },
          "required": [
            "training_file",
            "model"
          ],
          "type": "object"
        }
      }
    },
    "required": true
  },
  "responses": {
    "200": {
      "content": {
        "application/json": {
          "schema": {
            "description": "A truncated version of the fine-tune response, used for POST /fine-tunes, GET /fine-tunes and POST /fine-tunes/{id}/cancel endpoints",
            "example": {
              "created_at": "2023-05-17T17:35:45.123Z",
              "events": [],
              "id": "ft-01234567890123456789",
              "model": "meta-llama/Llama-2-7b-hf",
              "model_output_name": "mynamespace/meta-llama/Llama-2-7b-hf-32162631",
              "n_epochs": 3,
              "owner_address": "user@example.com",
              "status": "completed",
              "token_count": 850000,
              "total_price": 1500,
              "training_file": "file-01234567890123456789",
              "updated_at": "2023-05-17T18:46:23.456Z",
              "user_id": "user_01234567890123456789",
              "wandb_project_name": "my-finetune-project"
            },
            "properties": {
              "batch_size": {
                "description": "Batch size used for training",
                "type": "integer"
              },
              "created_at": {
                "description": "Creation timestamp of the fine-tune job",
                "format": "date-time",
                "type": "string"
              },
              "events": {
                "description": "Events related to this fine-tune job",
                "items": {
                  "properties": {
                    "checkpoint_path": {
                      "type": "string"
                    },
                    "created_at": {
                      "type": "string"
                    },
                    "hash": {
                      "type": "string"
                    },
                    "level": {
                      "anyOf": [
                        {
                          "enum": [
                            null,
                            "info",
                            "warning",
                            "error",
                            "legacy_info",
                            "legacy_iwarning",
                            "legacy_ierror"
                          ],
                          "type": "string"
                        }
                      ]
                    },
                    "message": {
                      "type": "string"
                    },
                    "model_path": {
                      "type": "string"
                    },
                    "object": {
                      "enum": [
                        "fine-tune-event"
                      ],
                      "type": "string"
                    },
                    "param_count": {
                      "type": "integer"
                    },
                    "step": {
                      "type": "integer"
                    },
                    "token_count": {
                      "type": "integer"
                    },
                    "total_steps": {
                      "type": "integer"
                    },
                    "training_offset": {
                      "type": "integer"
                    },
                    "type": {
                      "enum": [
                        "job_pending",
                        "job_start",
                        "job_stopped",
                        "model_downloading",
                        "model_download_complete",
                        "training_data_downloading",
                        "training_data_download_complete",
                        "validation_data_downloading",
                        "validation_data_download_complete",
                        "wandb_init",
                        "training_start",
                        "checkpoint_save",
                        "billing_limit",
                        "epoch_complete",
                        "training_complete",
                        "model_compressing",
                        "model_compression_complete",
                        "model_uploading",
                        "model_upload_complete",
                        "job_complete",
                        "job_error",
                        "cancel_requested",
                        "job_restarted",
                        "refund",
                        "warning"
                      ],
                      "type": "string"
                    },
                    "wandb_url": {
                      "type": "string"
                    }
                  },
                  "required": [
                    "object",
                    "created_at",
                    "message",
                    "type",
                    "param_count",
                    "token_count",
                    "total_steps",
                    "wandb_url",
                    "step",
                    "checkpoint_path",
                    "model_path",
                    "training_offset",
                    "hash"
                  ],
                  "type": "object"
                },
                "type": "array"
              },
              "from_checkpoint": {
                "description": "Checkpoint used to continue training",
                "type": "string"
              },
              "from_hf_model": {
                "description": "Hugging Face Hub repo to start training from",
                "type": "string"
              },
              "hf_model_revision": {
                "description": "The revision of the Hugging Face Hub model to continue training from",
                "type": "string"
              },
              "id": {
                "description": "Unique identifier for the fine-tune job",
                "type": "string"
              },
              "learning_rate": {
                "description": "Learning rate used for training",
                "format": "float",
                "type": "number"
              },
              "lr_scheduler": {
                "description": "Learning rate scheduler configuration",
                "properties": {
                  "lr_scheduler_args": {
                    "oneOf": [
                      {
                        "properties": {
                          "min_lr_ratio": {
                            "default": 0,
                            "description": "The ratio of the final learning rate to the peak learning rate",
                            "format": "float",
                            "type": "number"
                          }
                        },
                        "type": "object"
                      },
                      {
                        "properties": {
                          "min_lr_ratio": {
                            "default": 0,
                            "description": "The ratio of the final learning rate to the peak learning rate",
                            "format": "float",
                            "type": "number"
                          },
                          "num_cycles": {
                            "default": 0.5,
                            "description": "Number or fraction of cycles for the cosine learning rate scheduler",
                            "format": "float",
                            "type": "number"
                          }
                        },
                        "required": [
                          "min_lr_ratio",
                          "num_cycles"
                        ],
                        "type": "object"
                      }
                    ]
                  },
                  "lr_scheduler_type": {
                    "enum": [
                      "linear",
                      "cosine"
                    ],
                    "type": "string"
                  }
                },
                "required": [
                  "lr_scheduler_type"
                ],
                "type": "object"
              },
              "max_grad_norm": {
                "description": "Maximum gradient norm for clipping",
                "format": "float",
                "type": "number"
              },
              "model": {
                "description": "Base model used for fine-tuning",
                "type": "string"
              },
              "model_output_name": {
                "type": "string"
              },
              "n_checkpoints": {
                "description": "Number of checkpoints saved during training",
                "type": "integer"
              },
              "n_epochs": {
                "description": "Number of training epochs",
                "type": "integer"
              },
              "n_evals": {
                "description": "Number of evaluations during training",
                "type": "integer"
              },
              "owner_address": {
                "description": "Owner address information",
                "type": "string"
              },
              "status": {
                "enum": [
                  "pending",
                  "queued",
                  "running",
                  "compressing",
                  "uploading",
                  "cancel_requested",
                  "cancelled",
                  "error",
                  "completed"
                ],
                "type": "string"
              },
              "suffix": {
                "description": "Suffix added to the fine-tuned model name",
                "type": "string"
              },
              "token_count": {
                "description": "Count of tokens processed",
                "type": "integer"
              },
              "total_price": {
                "description": "Total price for the fine-tuning job",
                "type": "integer"
              },
              "training_file": {
                "description": "File-ID of the training file",
                "type": "string"
              },
              "training_method": {
                "description": "Method of training used",
                "oneOf": [
                  {
                    "properties": {
                      "method": {
                        "enum": [
                          "sft"
                        ],
                        "type": "string"
                      },
                      "train_on_inputs": {
                        "default": "auto",
                        "description": "Whether to mask the user messages in conversational data or prompts in instruction data.",
                        "oneOf": [
                          {
                            "type": "boolean"
                          },
                          {
                            "enum": [
                              "auto"
                            ],
                            "type": "string"
                          }
                        ],
                        "type": "boolean"
                      }
                    },
                    "required": [
                      "method",
                      "train_on_inputs"
                    ],
                    "type": "object"
                  },
                  {
                    "properties": {
                      "dpo_beta": {
                        "default": 0.1,
                        "format": "float",
                        "type": "number"
                      },
                      "dpo_normalize_logratios_by_length": {
                        "default": false,
                        "type": "boolean"
                      },
                      "dpo_reference_free": {
                        "default": false,
                        "type": "boolean"
                      },
                      "method": {
                        "enum": [
                          "dpo"
                        ],
                        "type": "string"
                      },
                      "rpo_alpha": {
                        "default": 0,
                        "format": "float",
                        "type": "number"
                      },
                      "simpo_gamma": {
                        "default": 0,
                        "format": "float",
                        "type": "number"
                      }
                    },
                    "required": [
                      "method"
                    ],
                    "type": "object"
                  }
                ]
              },
              "training_type": {
                "description": "Type of training used (full or LoRA)",
                "oneOf": [
                  {
                    "properties": {
                      "type": {
                        "enum": [
                          "Full"
                        ],
                        "type": "string"
                      }
                    },
                    "required": [
                      "type"
                    ],
                    "type": "object"
                  },
                  {
                    "properties": {
                      "lora_alpha": {
                        "type": "integer"
                      },
                      "lora_dropout": {
                        "default": 0,
                        "format": "float",
                        "type": "number"
                      },
                      "lora_r": {
                        "type": "integer"
                      },
                      "lora_trainable_modules": {
                        "default": "all-linear",
                        "type": "string"
                      },
                      "type": {
                        "enum": [
                          "Lora"
                        ],
                        "type": "string"
                      }
                    },
                    "required": [
                      "type",
                      "lora_r",
                      "lora_alpha"
                    ],
                    "type": "object"
                  }
                ]
              },
              "updated_at": {
                "description": "Last update timestamp of the fine-tune job",
                "format": "date-time",
                "type": "string"
              },
              "user_id": {
                "description": "Identifier for the user who created the job",
                "type": "string"
              },
              "validation_file": {
                "description": "File-ID of the validation file",
                "type": "string"
              },
              "wandb_name": {
                "description": "Weights & Biases run name",
                "type": "string"
              },
              "wandb_project_name": {
                "description": "Weights & Biases project name",
                "type": "string"
              },
              "warmup_ratio": {
                "description": "Ratio of warmup steps",
                "format": "float",
                "type": "number"
              },
              "weight_decay": {
                "description": "Weight decay value used",
                "format": "float",
                "type": "number"
              }
            },
            "required": [
              "id",
              "status",
              "created_at",
              "updated_at"
            ],
            "type": "object"
          }
        }
      },
      "description": "Fine-tuning job initiated successfully"
    }
  },
  "summary": "Create job",
  "tags": [
    "Fine-tuning"
  ]
}
