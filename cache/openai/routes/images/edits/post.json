{
  "description": "You can call this endpoint with either:\n\n- `multipart/form-data`: use binary uploads via `image` (and optional `mask`).\n- `application/json`: use `images` (and optional `mask`) as references with either `image_url` or `file_id`.\n\nNote that JSON requests use `images` (array) instead of the multipart `image` field.\n",
  "operationId": "createImageEdit",
  "requestBody": {
    "content": {
      "application/json": {
        "examples": {
          "json_with_file_id": {
            "summary": "JSON request with uploaded file id",
            "value": {
              "images": [
                {
                  "file_id": "file-abc123"
                }
              ],
              "mask": {
                "file_id": "file-mask123"
              },
              "model": "gpt-image-1.5",
              "output_compression": 100,
              "output_format": "png",
              "prompt": "Replace the background with a snowy mountain scene"
            }
          },
          "json_with_url": {
            "summary": "JSON request with image URL",
            "value": {
              "images": [
                {
                  "image_url": "https://example.com/source-image.png"
                }
              ],
              "model": "gpt-image-1.5",
              "prompt": "Add a watercolor effect to this image",
              "quality": "high",
              "size": "1024x1024"
            }
          }
        },
        "schema": {
          "$ref": "#/components/schemas/EditImageBodyJsonParam"
        }
      },
      "multipart/form-data": {
        "examples": {
          "multipart_edit": {
            "summary": "Multipart form upload (binary image + prompt)",
            "value": {
              "image": "<binary image file>",
              "model": "gpt-image-1.5",
              "prompt": "Add a watercolor effect to this image",
              "quality": "high",
              "size": "1024x1024"
            }
          }
        },
        "schema": {
          "$ref": "#/components/schemas/CreateImageEditRequest"
        }
      }
    },
    "required": true
  },
  "responses": {
    "200": {
      "content": {
        "application/json": {
          "schema": {
            "$ref": "#/components/schemas/ImagesResponse"
          }
        },
        "text/event-stream": {
          "schema": {
            "$ref": "#/components/schemas/ImageEditStreamEvent"
          }
        }
      },
      "description": "OK"
    }
  },
  "summary": "Creates an edited or extended image given one or more source images and a prompt. This endpoint supports GPT Image models (`gpt-image-1.5`, `gpt-image-1`, `gpt-image-1-mini`, and `chatgpt-image-latest`) and `dall-e-2`.",
  "tags": [
    "Images"
  ],
  "components": {
    "schemas": {
      "EditImageBodyJsonParam": {
        "description": "JSON request body for image edits.\n\nUse `images` (array of `ImageRefParam`) instead of multipart `image` uploads.\nYou can reference images via external URLs, data URLs, or uploaded file IDs.\nJSON edits support GPT image models only; DALL-E edits require multipart (`dall-e-2` only).\n",
        "properties": {
          "background": {
            "anyOf": [
              {
                "enum": [
                  "transparent",
                  "opaque",
                  "auto"
                ],
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "default": "auto",
            "description": "Background behavior for generated image output.",
            "example": "transparent"
          },
          "images": {
            "description": "Input image references to edit.\nFor GPT image models, you can provide up to 16 images.\n",
            "items": {
              "$ref": "#/components/schemas/ImageRefParam"
            },
            "maxItems": 16,
            "minItems": 1,
            "type": "array"
          },
          "input_fidelity": {
            "anyOf": [
              {
                "enum": [
                  "high",
                  "low"
                ],
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "description": "Controls fidelity to the original input image(s)."
          },
          "mask": {
            "$ref": "#/components/schemas/ImageRefParam"
          },
          "model": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "enum": [
                  "gpt-image-1.5",
                  "gpt-image-1",
                  "gpt-image-1-mini",
                  "chatgpt-image-latest"
                ],
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "default": "gpt-image-1.5",
            "description": "The model to use for image editing.",
            "example": "gpt-image-1.5"
          },
          "moderation": {
            "anyOf": [
              {
                "enum": [
                  "low",
                  "auto"
                ],
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "default": "auto",
            "description": "Moderation level for GPT image models.",
            "example": "auto"
          },
          "n": {
            "anyOf": [
              {
                "maximum": 10,
                "minimum": 1,
                "type": "integer"
              },
              {
                "type": "null"
              }
            ],
            "default": 1,
            "description": "The number of edited images to generate.",
            "example": 1
          },
          "output_compression": {
            "anyOf": [
              {
                "maximum": 100,
                "minimum": 0,
                "type": "integer"
              },
              {
                "type": "null"
              }
            ],
            "description": "Compression level for `jpeg` or `webp` output.",
            "example": 100
          },
          "output_format": {
            "anyOf": [
              {
                "enum": [
                  "png",
                  "jpeg",
                  "webp"
                ],
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "default": "png",
            "description": "Output image format. Supported for GPT image models.",
            "example": "png"
          },
          "partial_images": {
            "$ref": "#/components/schemas/PartialImages"
          },
          "prompt": {
            "description": "A text description of the desired image edit.",
            "example": "Add a watercolor effect and keep the subject centered",
            "maxLength": 32000,
            "minLength": 1,
            "type": "string"
          },
          "quality": {
            "anyOf": [
              {
                "enum": [
                  "low",
                  "medium",
                  "high",
                  "auto"
                ],
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "default": "auto",
            "description": "Output quality for GPT image models.\n",
            "example": "high"
          },
          "size": {
            "anyOf": [
              {
                "enum": [
                  "auto",
                  "1024x1024",
                  "1536x1024",
                  "1024x1536"
                ],
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "default": "auto",
            "description": "Requested output image size.",
            "example": "1024x1024"
          },
          "stream": {
            "anyOf": [
              {
                "type": "boolean"
              },
              {
                "type": "null"
              }
            ],
            "default": false,
            "description": "Stream partial image results as events.",
            "example": false
          },
          "user": {
            "description": "A unique identifier representing your end-user, which can help OpenAI\nmonitor and detect abuse.\n",
            "example": "user-1234",
            "type": "string"
          }
        },
        "required": [
          "images",
          "prompt"
        ],
        "type": "object"
      },
      "CreateImageEditRequest": {
        "properties": {
          "background": {
            "default": "auto",
            "description": "Allows to set transparency for the background of the generated image(s).\nThis parameter is only supported for the GPT image models. Must be one of\n`transparent`, `opaque` or `auto` (default value). When `auto` is used, the\nmodel will automatically determine the best background for the image.\n\nIf `transparent`, the output format needs to support transparency, so it\nshould be set to either `png` (default value) or `webp`.\n",
            "enum": [
              "transparent",
              "opaque",
              "auto"
            ],
            "example": "transparent",
            "nullable": true,
            "type": "string"
          },
          "image": {
            "anyOf": [
              {
                "format": "binary",
                "type": "string"
              },
              {
                "items": {
                  "format": "binary",
                  "type": "string"
                },
                "maxItems": 16,
                "type": "array"
              }
            ],
            "description": "The image(s) to edit. Must be a supported image file or an array of images.\n\nFor the GPT image models (`gpt-image-1`, `gpt-image-1-mini`, and `gpt-image-1.5`), each image should be a `png`, `webp`, or `jpg`\nfile less than 50MB. You can provide up to 16 images.\n`chatgpt-image-latest` follows the same input constraints as GPT image models.\n\nFor `dall-e-2`, you can only provide one image, and it should be a square\n`png` file less than 4MB.\n"
          },
          "input_fidelity": {
            "anyOf": [
              {
                "$ref": "#/components/schemas/InputFidelity"
              },
              {
                "type": "null"
              }
            ]
          },
          "mask": {
            "description": "An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. If there are multiple images provided, the mask will be applied on the first image. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`.",
            "format": "binary",
            "type": "string"
          },
          "model": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "enum": [
                  "gpt-image-1.5",
                  "dall-e-2",
                  "gpt-image-1",
                  "gpt-image-1-mini",
                  "chatgpt-image-latest"
                ],
                "type": "string"
              }
            ],
            "default": "gpt-image-1.5",
            "description": "The model to use for image generation. Defaults to `gpt-image-1.5`.",
            "example": "gpt-image-1.5",
            "nullable": true
          },
          "n": {
            "default": 1,
            "description": "The number of images to generate. Must be between 1 and 10.",
            "example": 1,
            "maximum": 10,
            "minimum": 1,
            "nullable": true,
            "type": "integer"
          },
          "output_compression": {
            "default": 100,
            "description": "The compression level (0-100%) for the generated images. This parameter\nis only supported for the GPT image models with the `webp` or `jpeg` output\nformats, and defaults to 100.\n",
            "example": 100,
            "nullable": true,
            "type": "integer"
          },
          "output_format": {
            "default": "png",
            "description": "The format in which the generated images are returned. This parameter is\nonly supported for the GPT image models. Must be one of `png`, `jpeg`, or `webp`.\nThe default value is `png`.\n",
            "enum": [
              "png",
              "jpeg",
              "webp"
            ],
            "example": "png",
            "nullable": true,
            "type": "string"
          },
          "partial_images": {
            "$ref": "#/components/schemas/PartialImages"
          },
          "prompt": {
            "description": "A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2`, and 32000 characters for the GPT image models.",
            "example": "A cute baby sea otter wearing a beret",
            "type": "string"
          },
          "quality": {
            "default": "auto",
            "description": "The quality of the image that will be generated for GPT image models. Defaults to `auto`.\n",
            "enum": [
              "standard",
              "low",
              "medium",
              "high",
              "auto"
            ],
            "example": "high",
            "nullable": true,
            "type": "string"
          },
          "response_format": {
            "description": "The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated. This parameter is only supported for `dall-e-2` (default is `url` for `dall-e-2`), as GPT image models always return base64-encoded images.",
            "enum": [
              "url",
              "b64_json"
            ],
            "example": "url",
            "nullable": true,
            "type": "string"
          },
          "size": {
            "default": "1024x1024",
            "description": "The size of the generated images. Must be one of `1024x1024`, `1536x1024` (landscape), `1024x1536` (portrait), or `auto` (default value) for the GPT image models, and one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`.",
            "enum": [
              "256x256",
              "512x512",
              "1024x1024",
              "1536x1024",
              "1024x1536",
              "auto"
            ],
            "example": "1024x1024",
            "nullable": true,
            "type": "string"
          },
          "stream": {
            "default": false,
            "description": "Edit the image in streaming mode. Defaults to `false`. See the\n[Image generation guide](/docs/guides/image-generation) for more information.\n",
            "example": false,
            "nullable": true,
            "type": "boolean"
          },
          "user": {
            "description": "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).\n",
            "example": "user-1234",
            "type": "string"
          }
        },
        "required": [
          "prompt",
          "image"
        ],
        "type": "object"
      },
      "ImagesResponse": {
        "description": "The response from the image generation endpoint.",
        "properties": {
          "background": {
            "description": "The background parameter used for the image generation. Either `transparent` or `opaque`.",
            "enum": [
              "transparent",
              "opaque"
            ],
            "type": "string"
          },
          "created": {
            "description": "The Unix timestamp (in seconds) of when the image was created.",
            "type": "integer"
          },
          "data": {
            "description": "The list of generated images.",
            "items": {
              "$ref": "#/components/schemas/Image"
            },
            "type": "array"
          },
          "output_format": {
            "description": "The output format of the image generation. Either `png`, `webp`, or `jpeg`.",
            "enum": [
              "png",
              "webp",
              "jpeg"
            ],
            "type": "string"
          },
          "quality": {
            "description": "The quality of the image generated. Either `low`, `medium`, or `high`.",
            "enum": [
              "low",
              "medium",
              "high"
            ],
            "type": "string"
          },
          "size": {
            "description": "The size of the image generated. Either `1024x1024`, `1024x1536`, or `1536x1024`.",
            "enum": [
              "1024x1024",
              "1024x1536",
              "1536x1024"
            ],
            "type": "string"
          },
          "usage": {
            "$ref": "#/components/schemas/ImageGenUsage"
          }
        },
        "required": [
          "created"
        ],
        "title": "Image generation response",
        "type": "object"
      },
      "ImageEditStreamEvent": {
        "anyOf": [
          {
            "$ref": "#/components/schemas/ImageEditPartialImageEvent"
          },
          {
            "$ref": "#/components/schemas/ImageEditCompletedEvent"
          }
        ],
        "discriminator": {
          "propertyName": "type"
        }
      },
      "ImageRefParam": {
        "additionalProperties": false,
        "anyOf": [
          {
            "required": [
              "image_url"
            ]
          },
          {
            "required": [
              "file_id"
            ]
          }
        ],
        "description": "Reference an input image by either URL or uploaded file ID.\nProvide exactly one of `image_url` or `file_id`.\n",
        "not": {
          "required": [
            "image_url",
            "file_id"
          ]
        },
        "properties": {
          "file_id": {
            "description": "The File API ID of an uploaded image to use as input.",
            "example": "file-abc123",
            "type": "string"
          },
          "image_url": {
            "description": "A fully qualified URL or base64-encoded data URL.",
            "example": "https://example.com/source-image.png",
            "maxLength": 20971520,
            "type": "string"
          }
        },
        "type": "object"
      },
      "PartialImages": {
        "anyOf": [
          {
            "default": 0,
            "description": "The number of partial images to generate. This parameter is used for\nstreaming responses that return partial images. Value must be between 0 and 3.\nWhen set to 0, the response will be a single image sent in one streaming event.\n\nNote that the final image may be sent before the full number of partial images\nare generated if the full image is generated more quickly.\n",
            "example": 1,
            "maximum": 3,
            "minimum": 0,
            "type": "integer"
          },
          {
            "type": "null"
          }
        ]
      },
      "InputFidelity": {
        "description": "Control how much effort the model will exert to match the style and features, especially facial features, of input images. This parameter is only supported for `gpt-image-1` and `gpt-image-1.5` and later models, unsupported for `gpt-image-1-mini`. Supports `high` and `low`. Defaults to `low`.",
        "enum": [
          "high",
          "low"
        ],
        "type": "string"
      },
      "Image": {
        "description": "Represents the content or the URL of an image generated by the OpenAI API.",
        "properties": {
          "b64_json": {
            "description": "The base64-encoded JSON of the generated image. Returned by default for the GPT image models, and only present if `response_format` is set to `b64_json` for `dall-e-2` and `dall-e-3`.",
            "type": "string"
          },
          "revised_prompt": {
            "description": "For `dall-e-3` only, the revised prompt that was used to generate the image.",
            "type": "string"
          },
          "url": {
            "description": "When using `dall-e-2` or `dall-e-3`, the URL of the generated image if `response_format` is set to `url` (default value). Unsupported for the GPT image models.",
            "type": "string"
          }
        },
        "type": "object"
      },
      "ImageGenUsage": {
        "description": "For `gpt-image-1` only, the token usage information for the image generation.",
        "properties": {
          "input_tokens": {
            "description": "The number of tokens (images and text) in the input prompt.",
            "type": "integer"
          },
          "input_tokens_details": {
            "$ref": "#/components/schemas/ImageGenInputUsageDetails"
          },
          "output_tokens": {
            "description": "The number of output tokens generated by the model.",
            "type": "integer"
          },
          "output_tokens_details": {
            "$ref": "#/components/schemas/ImageGenOutputTokensDetails"
          },
          "total_tokens": {
            "description": "The total number of tokens (images and text) used for the image generation.",
            "type": "integer"
          }
        },
        "required": [
          "input_tokens",
          "total_tokens",
          "output_tokens",
          "input_tokens_details"
        ],
        "title": "Image generation usage",
        "type": "object"
      },
      "ImageEditPartialImageEvent": {
        "description": "Emitted when a partial image is available during image editing streaming.\n",
        "properties": {
          "b64_json": {
            "description": "Base64-encoded partial image data, suitable for rendering as an image.\n",
            "type": "string"
          },
          "background": {
            "description": "The background setting for the requested edited image.\n",
            "enum": [
              "transparent",
              "opaque",
              "auto"
            ],
            "type": "string"
          },
          "created_at": {
            "description": "The Unix timestamp when the event was created.\n",
            "type": "integer"
          },
          "output_format": {
            "description": "The output format for the requested edited image.\n",
            "enum": [
              "png",
              "webp",
              "jpeg"
            ],
            "type": "string"
          },
          "partial_image_index": {
            "description": "0-based index for the partial image (streaming).\n",
            "type": "integer"
          },
          "quality": {
            "description": "The quality setting for the requested edited image.\n",
            "enum": [
              "low",
              "medium",
              "high",
              "auto"
            ],
            "type": "string"
          },
          "size": {
            "description": "The size of the requested edited image.\n",
            "enum": [
              "1024x1024",
              "1024x1536",
              "1536x1024",
              "auto"
            ],
            "type": "string"
          },
          "type": {
            "description": "The type of the event. Always `image_edit.partial_image`.\n",
            "enum": [
              "image_edit.partial_image"
            ],
            "type": "string"
          }
        },
        "required": [
          "type",
          "b64_json",
          "created_at",
          "size",
          "quality",
          "background",
          "output_format",
          "partial_image_index"
        ],
        "type": "object"
      },
      "ImageEditCompletedEvent": {
        "description": "Emitted when image editing has completed and the final image is available.\n",
        "properties": {
          "b64_json": {
            "description": "Base64-encoded final edited image data, suitable for rendering as an image.\n",
            "type": "string"
          },
          "background": {
            "description": "The background setting for the edited image.\n",
            "enum": [
              "transparent",
              "opaque",
              "auto"
            ],
            "type": "string"
          },
          "created_at": {
            "description": "The Unix timestamp when the event was created.\n",
            "type": "integer"
          },
          "output_format": {
            "description": "The output format for the edited image.\n",
            "enum": [
              "png",
              "webp",
              "jpeg"
            ],
            "type": "string"
          },
          "quality": {
            "description": "The quality setting for the edited image.\n",
            "enum": [
              "low",
              "medium",
              "high",
              "auto"
            ],
            "type": "string"
          },
          "size": {
            "description": "The size of the edited image.\n",
            "enum": [
              "1024x1024",
              "1024x1536",
              "1536x1024",
              "auto"
            ],
            "type": "string"
          },
          "type": {
            "description": "The type of the event. Always `image_edit.completed`.\n",
            "enum": [
              "image_edit.completed"
            ],
            "type": "string"
          },
          "usage": {
            "$ref": "#/components/schemas/ImagesUsage"
          }
        },
        "required": [
          "type",
          "b64_json",
          "created_at",
          "size",
          "quality",
          "background",
          "output_format",
          "usage"
        ],
        "type": "object"
      },
      "ImageGenInputUsageDetails": {
        "description": "The input tokens detailed information for the image generation.",
        "properties": {
          "image_tokens": {
            "description": "The number of image tokens in the input prompt.",
            "type": "integer"
          },
          "text_tokens": {
            "description": "The number of text tokens in the input prompt.",
            "type": "integer"
          }
        },
        "required": [
          "text_tokens",
          "image_tokens"
        ],
        "title": "Input usage details",
        "type": "object"
      },
      "ImageGenOutputTokensDetails": {
        "description": "The output token details for the image generation.",
        "properties": {
          "image_tokens": {
            "description": "The number of image output tokens generated by the model.",
            "type": "integer"
          },
          "text_tokens": {
            "description": "The number of text output tokens generated by the model.",
            "type": "integer"
          }
        },
        "required": [
          "image_tokens",
          "text_tokens"
        ],
        "title": "Image generation output token details",
        "type": "object"
      },
      "ImagesUsage": {
        "description": "For the GPT image models only, the token usage information for the image generation.\n",
        "properties": {
          "input_tokens": {
            "description": "The number of tokens (images and text) in the input prompt.",
            "type": "integer"
          },
          "input_tokens_details": {
            "description": "The input tokens detailed information for the image generation.",
            "properties": {
              "image_tokens": {
                "description": "The number of image tokens in the input prompt.",
                "type": "integer"
              },
              "text_tokens": {
                "description": "The number of text tokens in the input prompt.",
                "type": "integer"
              }
            },
            "required": [
              "text_tokens",
              "image_tokens"
            ],
            "type": "object"
          },
          "output_tokens": {
            "description": "The number of image tokens in the output image.",
            "type": "integer"
          },
          "total_tokens": {
            "description": "The total number of tokens (images and text) used for the image generation.\n",
            "type": "integer"
          }
        },
        "required": [
          "total_tokens",
          "input_tokens",
          "output_tokens",
          "input_tokens_details"
        ],
        "type": "object"
      }
    }
  }
}
