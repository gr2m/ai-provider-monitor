{
  "description": "Creates an edited or extended image given one or more source images and a prompt. This endpoint only supports `gpt-image-1` and `dall-e-2`.",
  "operationId": "createImageEdit",
  "requestBody": {
    "content": {
      "multipart/form-data": {
        "schema": {
          "properties": {
            "background": {
              "default": "auto",
              "description": "Allows to set transparency for the background of the generated image(s).\nThis parameter is only supported for `gpt-image-1`. Must be one of\n`transparent`, `opaque` or `auto` (default value). When `auto` is used, the\nmodel will automatically determine the best background for the image.\n\nIf `transparent`, the output format needs to support transparency, so it\nshould be set to either `png` (default value) or `webp`.\n",
              "enum": [
                "transparent",
                "opaque",
                "auto"
              ],
              "example": "transparent",
              "nullable": true,
              "type": "string"
            },
            "image": {
              "anyOf": [
                {
                  "format": "binary",
                  "type": "string"
                },
                {
                  "items": {
                    "format": "binary",
                    "type": "string"
                  },
                  "maxItems": 16,
                  "type": "array"
                }
              ],
              "description": "The image(s) to edit. Must be a supported image file or an array of images.\n\nFor `gpt-image-1`, each image should be a `png`, `webp`, or `jpg` file less\nthan 50MB. You can provide up to 16 images.\n\nFor `dall-e-2`, you can only provide one image, and it should be a square\n`png` file less than 4MB.\n"
            },
            "input_fidelity": {
              "anyOf": [
                {
                  "default": "low",
                  "description": "Control how much effort the model will exert to match the style and features,\nespecially facial features, of input images. This parameter is only supported\nfor `gpt-image-1`. Unsupported for `gpt-image-1-mini`. Supports `high` and `low`. Defaults to `low`.\n",
                  "enum": [
                    "high",
                    "low"
                  ],
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ]
            },
            "mask": {
              "description": "An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. If there are multiple images provided, the mask will be applied on the first image. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`.",
              "format": "binary",
              "type": "string"
            },
            "model": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "enum": [
                    "dall-e-2",
                    "gpt-image-1",
                    "gpt-image-1-mini"
                  ],
                  "type": "string"
                }
              ],
              "description": "The model to use for image generation. Only `dall-e-2` and `gpt-image-1` are supported. Defaults to `dall-e-2` unless a parameter specific to `gpt-image-1` is used.",
              "nullable": true
            },
            "n": {
              "default": 1,
              "description": "The number of images to generate. Must be between 1 and 10.",
              "example": 1,
              "maximum": 10,
              "minimum": 1,
              "nullable": true,
              "type": "integer"
            },
            "output_compression": {
              "default": 100,
              "description": "The compression level (0-100%) for the generated images. This parameter\nis only supported for `gpt-image-1` with the `webp` or `jpeg` output\nformats, and defaults to 100.\n",
              "example": 100,
              "nullable": true,
              "type": "integer"
            },
            "output_format": {
              "default": "png",
              "description": "The format in which the generated images are returned. This parameter is\nonly supported for `gpt-image-1`. Must be one of `png`, `jpeg`, or `webp`.\nThe default value is `png`.\n",
              "enum": [
                "png",
                "jpeg",
                "webp"
              ],
              "example": "png",
              "nullable": true,
              "type": "string"
            },
            "partial_images": {
              "anyOf": [
                {
                  "default": 0,
                  "description": "The number of partial images to generate. This parameter is used for\nstreaming responses that return partial images. Value must be between 0 and 3.\nWhen set to 0, the response will be a single image sent in one streaming event.\n\nNote that the final image may be sent before the full number of partial images\nare generated if the full image is generated more quickly.\n",
                  "example": 1,
                  "maximum": 3,
                  "minimum": 0,
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ]
            },
            "prompt": {
              "description": "A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2`, and 32000 characters for `gpt-image-1`.",
              "example": "A cute baby sea otter wearing a beret",
              "type": "string"
            },
            "quality": {
              "default": "auto",
              "description": "The quality of the image that will be generated. `high`, `medium` and `low` are only supported for `gpt-image-1`. `dall-e-2` only supports `standard` quality. Defaults to `auto`.\n",
              "enum": [
                "standard",
                "low",
                "medium",
                "high",
                "auto"
              ],
              "example": "high",
              "nullable": true,
              "type": "string"
            },
            "response_format": {
              "default": "url",
              "description": "The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated. This parameter is only supported for `dall-e-2`, as `gpt-image-1` will always return base64-encoded images.",
              "enum": [
                "url",
                "b64_json"
              ],
              "example": "url",
              "nullable": true,
              "type": "string"
            },
            "size": {
              "default": "1024x1024",
              "description": "The size of the generated images. Must be one of `1024x1024`, `1536x1024` (landscape), `1024x1536` (portrait), or `auto` (default value) for `gpt-image-1`, and one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`.",
              "enum": [
                "256x256",
                "512x512",
                "1024x1024",
                "1536x1024",
                "1024x1536",
                "auto"
              ],
              "example": "1024x1024",
              "nullable": true,
              "type": "string"
            },
            "stream": {
              "default": false,
              "description": "Edit the image in streaming mode. Defaults to `false`. See the\n[Image generation guide](https://platform.openai.com/docs/guides/image-generation) for more information.\n",
              "example": false,
              "nullable": true,
              "type": "boolean"
            },
            "user": {
              "description": "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n",
              "example": "user-1234",
              "type": "string"
            }
          },
          "required": [
            "prompt",
            "image"
          ],
          "type": "object"
        }
      }
    },
    "required": true
  },
  "responses": {
    "200": {
      "content": {
        "application/json": {
          "schema": {
            "description": "The response from the image generation endpoint.",
            "properties": {
              "background": {
                "description": "The background parameter used for the image generation. Either `transparent` or `opaque`.",
                "enum": [
                  "transparent",
                  "opaque"
                ],
                "type": "string"
              },
              "created": {
                "description": "The Unix timestamp (in seconds) of when the image was created.",
                "type": "integer"
              },
              "data": {
                "description": "The list of generated images.",
                "items": {
                  "description": "Represents the content or the URL of an image generated by the OpenAI API.",
                  "properties": {
                    "b64_json": {
                      "description": "The base64-encoded JSON of the generated image. Default value for `gpt-image-1`, and only present if `response_format` is set to `b64_json` for `dall-e-2` and `dall-e-3`.",
                      "type": "string"
                    },
                    "revised_prompt": {
                      "description": "For `dall-e-3` only, the revised prompt that was used to generate the image.",
                      "type": "string"
                    },
                    "url": {
                      "description": "When using `dall-e-2` or `dall-e-3`, the URL of the generated image if `response_format` is set to `url` (default value). Unsupported for `gpt-image-1`.",
                      "type": "string"
                    }
                  },
                  "type": "object"
                },
                "type": "array"
              },
              "output_format": {
                "description": "The output format of the image generation. Either `png`, `webp`, or `jpeg`.",
                "enum": [
                  "png",
                  "webp",
                  "jpeg"
                ],
                "type": "string"
              },
              "quality": {
                "description": "The quality of the image generated. Either `low`, `medium`, or `high`.",
                "enum": [
                  "low",
                  "medium",
                  "high"
                ],
                "type": "string"
              },
              "size": {
                "description": "The size of the image generated. Either `1024x1024`, `1024x1536`, or `1536x1024`.",
                "enum": [
                  "1024x1024",
                  "1024x1536",
                  "1536x1024"
                ],
                "type": "string"
              },
              "usage": {
                "description": "For `gpt-image-1` only, the token usage information for the image generation.",
                "properties": {
                  "input_tokens": {
                    "description": "The number of tokens (images and text) in the input prompt.",
                    "type": "integer"
                  },
                  "input_tokens_details": {
                    "description": "The input tokens detailed information for the image generation.",
                    "properties": {
                      "image_tokens": {
                        "description": "The number of image tokens in the input prompt.",
                        "type": "integer"
                      },
                      "text_tokens": {
                        "description": "The number of text tokens in the input prompt.",
                        "type": "integer"
                      }
                    },
                    "required": [
                      "text_tokens",
                      "image_tokens"
                    ],
                    "title": "Input usage details",
                    "type": "object"
                  },
                  "output_tokens": {
                    "description": "The number of output tokens generated by the model.",
                    "type": "integer"
                  },
                  "total_tokens": {
                    "description": "The total number of tokens (images and text) used for the image generation.",
                    "type": "integer"
                  }
                },
                "required": [
                  "input_tokens",
                  "total_tokens",
                  "output_tokens",
                  "input_tokens_details"
                ],
                "title": "Image generation usage",
                "type": "object"
              }
            },
            "required": [
              "created"
            ],
            "title": "Image generation response",
            "type": "object"
          }
        },
        "text/event-stream": {
          "schema": {
            "anyOf": [
              {
                "description": "Emitted when a partial image is available during image editing streaming.\n",
                "properties": {
                  "b64_json": {
                    "description": "Base64-encoded partial image data, suitable for rendering as an image.\n",
                    "type": "string"
                  },
                  "background": {
                    "description": "The background setting for the requested edited image.\n",
                    "enum": [
                      "transparent",
                      "opaque",
                      "auto"
                    ],
                    "type": "string"
                  },
                  "created_at": {
                    "description": "The Unix timestamp when the event was created.\n",
                    "type": "integer"
                  },
                  "output_format": {
                    "description": "The output format for the requested edited image.\n",
                    "enum": [
                      "png",
                      "webp",
                      "jpeg"
                    ],
                    "type": "string"
                  },
                  "partial_image_index": {
                    "description": "0-based index for the partial image (streaming).\n",
                    "type": "integer"
                  },
                  "quality": {
                    "description": "The quality setting for the requested edited image.\n",
                    "enum": [
                      "low",
                      "medium",
                      "high",
                      "auto"
                    ],
                    "type": "string"
                  },
                  "size": {
                    "description": "The size of the requested edited image.\n",
                    "enum": [
                      "1024x1024",
                      "1024x1536",
                      "1536x1024",
                      "auto"
                    ],
                    "type": "string"
                  },
                  "type": {
                    "description": "The type of the event. Always `image_edit.partial_image`.\n",
                    "enum": [
                      "image_edit.partial_image"
                    ],
                    "type": "string"
                  }
                },
                "required": [
                  "type",
                  "b64_json",
                  "created_at",
                  "size",
                  "quality",
                  "background",
                  "output_format",
                  "partial_image_index"
                ],
                "type": "object"
              },
              {
                "description": "Emitted when image editing has completed and the final image is available.\n",
                "properties": {
                  "b64_json": {
                    "description": "Base64-encoded final edited image data, suitable for rendering as an image.\n",
                    "type": "string"
                  },
                  "background": {
                    "description": "The background setting for the edited image.\n",
                    "enum": [
                      "transparent",
                      "opaque",
                      "auto"
                    ],
                    "type": "string"
                  },
                  "created_at": {
                    "description": "The Unix timestamp when the event was created.\n",
                    "type": "integer"
                  },
                  "output_format": {
                    "description": "The output format for the edited image.\n",
                    "enum": [
                      "png",
                      "webp",
                      "jpeg"
                    ],
                    "type": "string"
                  },
                  "quality": {
                    "description": "The quality setting for the edited image.\n",
                    "enum": [
                      "low",
                      "medium",
                      "high",
                      "auto"
                    ],
                    "type": "string"
                  },
                  "size": {
                    "description": "The size of the edited image.\n",
                    "enum": [
                      "1024x1024",
                      "1024x1536",
                      "1536x1024",
                      "auto"
                    ],
                    "type": "string"
                  },
                  "type": {
                    "description": "The type of the event. Always `image_edit.completed`.\n",
                    "enum": [
                      "image_edit.completed"
                    ],
                    "type": "string"
                  },
                  "usage": {
                    "description": "For `gpt-image-1` only, the token usage information for the image generation.\n",
                    "properties": {
                      "input_tokens": {
                        "description": "The number of tokens (images and text) in the input prompt.",
                        "type": "integer"
                      },
                      "input_tokens_details": {
                        "description": "The input tokens detailed information for the image generation.",
                        "properties": {
                          "image_tokens": {
                            "description": "The number of image tokens in the input prompt.",
                            "type": "integer"
                          },
                          "text_tokens": {
                            "description": "The number of text tokens in the input prompt.",
                            "type": "integer"
                          }
                        },
                        "required": [
                          "text_tokens",
                          "image_tokens"
                        ],
                        "type": "object"
                      },
                      "output_tokens": {
                        "description": "The number of image tokens in the output image.",
                        "type": "integer"
                      },
                      "total_tokens": {
                        "description": "The total number of tokens (images and text) used for the image generation.\n",
                        "type": "integer"
                      }
                    },
                    "required": [
                      "total_tokens",
                      "input_tokens",
                      "output_tokens",
                      "input_tokens_details"
                    ],
                    "type": "object"
                  }
                },
                "required": [
                  "type",
                  "b64_json",
                  "created_at",
                  "size",
                  "quality",
                  "background",
                  "output_format",
                  "usage"
                ],
                "type": "object"
              }
            ],
            "discriminator": {
              "propertyName": "type"
            }
          }
        }
      },
      "description": "OK"
    }
  },
  "summary": "Create image edit",
  "tags": [
    "Images"
  ]
}
