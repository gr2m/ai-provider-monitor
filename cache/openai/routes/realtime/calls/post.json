{
  "description": "Create a new Realtime API call over WebRTC and receive the SDP answer needed\nto complete the peer connection.",
  "operationId": "create-realtime-call",
  "requestBody": {
    "content": {
      "application/sdp": {
        "schema": {
          "description": "WebRTC SDP offer. Use this variant when you have previously created an\nephemeral **session token** and are authenticating the request with it.\nRealtime session parameters will be retrieved from the session token.",
          "type": "string"
        }
      },
      "multipart/form-data": {
        "encoding": {
          "sdp": {
            "contentType": "application/sdp"
          },
          "session": {
            "contentType": "application/json"
          }
        },
        "schema": {
          "additionalProperties": false,
          "description": "Parameters required to initiate a realtime call and receive the SDP answer\nneeded to complete a WebRTC peer connection. Provide an SDP offer generated\nby your client and optionally configure the session that will answer the call.",
          "properties": {
            "sdp": {
              "description": "WebRTC Session Description Protocol (SDP) offer generated by the caller.",
              "type": "string"
            },
            "session": {
              "allOf": [
                {
                  "description": "Realtime session object configuration.",
                  "properties": {
                    "audio": {
                      "description": "Configuration for input and output audio.\n",
                      "properties": {
                        "input": {
                          "properties": {
                            "format": {
                              "description": "The format of the input audio.",
                              "anyOf": [
                                {
                                  "description": "The PCM audio format. Only a 24kHz sample rate is supported.",
                                  "properties": {
                                    "rate": {
                                      "description": "The sample rate of the audio. Always `24000`.",
                                      "enum": [
                                        24000
                                      ],
                                      "type": "integer"
                                    },
                                    "type": {
                                      "description": "The audio format. Always `audio/pcm`.",
                                      "enum": [
                                        "audio/pcm"
                                      ],
                                      "type": "string"
                                    }
                                  },
                                  "title": "PCM audio format",
                                  "type": "object"
                                },
                                {
                                  "description": "The G.711 Î¼-law format.",
                                  "properties": {
                                    "type": {
                                      "description": "The audio format. Always `audio/pcmu`.",
                                      "enum": [
                                        "audio/pcmu"
                                      ],
                                      "type": "string"
                                    }
                                  },
                                  "title": "PCMU audio format",
                                  "type": "object"
                                },
                                {
                                  "description": "The G.711 A-law format.",
                                  "properties": {
                                    "type": {
                                      "description": "The audio format. Always `audio/pcma`.",
                                      "enum": [
                                        "audio/pcma"
                                      ],
                                      "type": "string"
                                    }
                                  },
                                  "title": "PCMA audio format",
                                  "type": "object"
                                }
                              ],
                              "discriminator": {
                                "propertyName": "type"
                              }
                            },
                            "noise_reduction": {
                              "description": "Configuration for input audio noise reduction. This can be set to `null` to turn off.\nNoise reduction filters audio added to the input audio buffer before it is sent to VAD and the model.\nFiltering the audio can improve VAD and turn detection accuracy (reducing false positives) and model performance by improving perception of the input audio.\n",
                              "properties": {
                                "type": {
                                  "description": "Type of noise reduction. `near_field` is for close-talking microphones such as headphones, `far_field` is for far-field microphones such as laptop or conference room microphones.\n",
                                  "enum": [
                                    "near_field",
                                    "far_field"
                                  ],
                                  "type": "string"
                                }
                              },
                              "type": "object"
                            },
                            "transcription": {
                              "properties": {
                                "language": {
                                  "description": "The language of the input audio. Supplying the input language in\n[ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. `en`) format\nwill improve accuracy and latency.\n",
                                  "type": "string"
                                },
                                "model": {
                                  "description": "The model to use for transcription. Current options are `whisper-1`, `gpt-4o-transcribe-latest`, `gpt-4o-mini-transcribe`, and `gpt-4o-transcribe`.\n",
                                  "enum": [
                                    "whisper-1",
                                    "gpt-4o-transcribe-latest",
                                    "gpt-4o-mini-transcribe",
                                    "gpt-4o-transcribe"
                                  ],
                                  "type": "string"
                                },
                                "prompt": {
                                  "description": "An optional text to guide the model's style or continue a previous audio\nsegment.\nFor `whisper-1`, the [prompt is a list of keywords](https://platform.openai.com/docs/guides/speech-to-text#prompting).\nFor `gpt-4o-transcribe` models, the prompt is a free text string, for example \"expect words related to technology\".\n",
                                  "type": "string"
                                }
                              },
                              "type": "object",
                              "description": "Configuration for input audio transcription, defaults to off and can be set to `null` to turn off once on. Input audio transcription is not native to the model, since the model consumes audio directly. Transcription runs asynchronously through [the /audio/transcriptions endpoint](https://platform.openai.com/docs/api-reference/audio/createTranscription) and should be treated as guidance of input audio content rather than precisely what the model heard. The client can optionally set the language and prompt for transcription, these offer additional guidance to the transcription service.\n"
                            },
                            "turn_detection": {
                              "anyOf": [
                                {
                                  "anyOf": [
                                    {
                                      "description": "Server-side voice activity detection (VAD) which flips on when user speech is detected and off after a period of silence.",
                                      "properties": {
                                        "create_response": {
                                          "default": true,
                                          "description": "Whether or not to automatically generate a response when a VAD stop event occurs.\n",
                                          "type": "boolean"
                                        },
                                        "idle_timeout_ms": {
                                          "anyOf": [
                                            {
                                              "description": "Optional timeout after which a model response will be triggered automatically. This is\nuseful for situations in which a long pause from the user is unexpected, such as a phone\ncall. The model will effectively prompt the user to continue the conversation based\non the current context.\n\nThe timeout value will be applied after the last model response's audio has finished playing,\ni.e. it's set to the `response.done` time plus audio playback duration.\n\nAn `input_audio_buffer.timeout_triggered` event (plus events\nassociated with the Response) will be emitted when the timeout is reached.\nIdle timeout is currently only supported for `server_vad` mode.\n",
                                              "maximum": 30000,
                                              "minimum": 5000,
                                              "type": "integer"
                                            },
                                            {
                                              "type": "null"
                                            }
                                          ]
                                        },
                                        "interrupt_response": {
                                          "default": true,
                                          "description": "Whether or not to automatically interrupt any ongoing response with output to the default\nconversation (i.e. `conversation` of `auto`) when a VAD start event occurs.\n",
                                          "type": "boolean"
                                        },
                                        "prefix_padding_ms": {
                                          "description": "Used only for `server_vad` mode. Amount of audio to include before the VAD detected speech (in\nmilliseconds). Defaults to 300ms.\n",
                                          "type": "integer"
                                        },
                                        "silence_duration_ms": {
                                          "description": "Used only for `server_vad` mode. Duration of silence to detect speech stop (in milliseconds). Defaults\nto 500ms. With shorter values the model will respond more quickly,\nbut may jump in on short pauses from the user.\n",
                                          "type": "integer"
                                        },
                                        "threshold": {
                                          "description": "Used only for `server_vad` mode. Activation threshold for VAD (0.0 to 1.0), this defaults to 0.5. A\nhigher threshold will require louder audio to activate the model, and\nthus might perform better in noisy environments.\n",
                                          "type": "number"
                                        },
                                        "type": {
                                          "const": "server_vad",
                                          "default": "server_vad",
                                          "description": "Type of turn detection, `server_vad` to turn on simple Server VAD.\n",
                                          "type": "string"
                                        }
                                      },
                                      "required": [
                                        "type"
                                      ],
                                      "title": "Server VAD",
                                      "type": "object"
                                    },
                                    {
                                      "description": "Server-side semantic turn detection which uses a model to determine when the user has finished speaking.",
                                      "properties": {
                                        "create_response": {
                                          "default": true,
                                          "description": "Whether or not to automatically generate a response when a VAD stop event occurs.\n",
                                          "type": "boolean"
                                        },
                                        "eagerness": {
                                          "default": "auto",
                                          "description": "Used only for `semantic_vad` mode. The eagerness of the model to respond. `low` will wait longer for the user to continue speaking, `high` will respond more quickly. `auto` is the default and is equivalent to `medium`. `low`, `medium`, and `high` have max timeouts of 8s, 4s, and 2s respectively.\n",
                                          "enum": [
                                            "low",
                                            "medium",
                                            "high",
                                            "auto"
                                          ],
                                          "type": "string"
                                        },
                                        "interrupt_response": {
                                          "default": true,
                                          "description": "Whether or not to automatically interrupt any ongoing response with output to the default\nconversation (i.e. `conversation` of `auto`) when a VAD start event occurs.\n",
                                          "type": "boolean"
                                        },
                                        "type": {
                                          "const": "semantic_vad",
                                          "description": "Type of turn detection, `semantic_vad` to turn on Semantic VAD.\n",
                                          "type": "string"
                                        }
                                      },
                                      "required": [
                                        "type"
                                      ],
                                      "title": "Semantic VAD",
                                      "type": "object"
                                    }
                                  ],
                                  "description": "Configuration for turn detection, ether Server VAD or Semantic VAD. This can be set to `null` to turn off, in which case the client must manually trigger model response.\n\nServer VAD means that the model will detect the start and end of speech based on audio volume and respond at the end of user speech.\n\nSemantic VAD is more advanced and uses a turn detection model (in conjunction with VAD) to semantically estimate whether the user has finished speaking, then dynamically sets a timeout based on this probability. For example, if user audio trails off with \"uhhm\", the model will score a low probability of turn end and wait longer for the user to continue speaking. This can be useful for more natural conversations, but may have a higher latency.\n",
                                  "discriminator": {
                                    "propertyName": "type"
                                  },
                                  "title": "Realtime Turn Detection"
                                },
                                {
                                  "type": "null"
                                }
                              ]
                            }
                          },
                          "type": "object"
                        },
                        "output": {
                          "properties": {
                            "format": {
                              "description": "The format of the output audio.",
                              "anyOf": [
                                {
                                  "description": "The PCM audio format. Only a 24kHz sample rate is supported.",
                                  "properties": {
                                    "rate": {
                                      "description": "The sample rate of the audio. Always `24000`.",
                                      "enum": [
                                        24000
                                      ],
                                      "type": "integer"
                                    },
                                    "type": {
                                      "description": "The audio format. Always `audio/pcm`.",
                                      "enum": [
                                        "audio/pcm"
                                      ],
                                      "type": "string"
                                    }
                                  },
                                  "title": "PCM audio format",
                                  "type": "object"
                                },
                                {
                                  "description": "The G.711 Î¼-law format.",
                                  "properties": {
                                    "type": {
                                      "description": "The audio format. Always `audio/pcmu`.",
                                      "enum": [
                                        "audio/pcmu"
                                      ],
                                      "type": "string"
                                    }
                                  },
                                  "title": "PCMU audio format",
                                  "type": "object"
                                },
                                {
                                  "description": "The G.711 A-law format.",
                                  "properties": {
                                    "type": {
                                      "description": "The audio format. Always `audio/pcma`.",
                                      "enum": [
                                        "audio/pcma"
                                      ],
                                      "type": "string"
                                    }
                                  },
                                  "title": "PCMA audio format",
                                  "type": "object"
                                }
                              ],
                              "discriminator": {
                                "propertyName": "type"
                              }
                            },
                            "speed": {
                              "default": 1,
                              "description": "The speed of the model's spoken response as a multiple of the original speed.\n1.0 is the default speed. 0.25 is the minimum speed. 1.5 is the maximum speed. This value can only be changed in between model turns, not while a response is in progress.\n\nThis parameter is a post-processing adjustment to the audio after it is generated, it's\nalso possible to prompt the model to speak faster or slower.\n",
                              "maximum": 1.5,
                              "minimum": 0.25,
                              "type": "number"
                            },
                            "voice": {
                              "default": "alloy",
                              "description": "The voice the model uses to respond. Voice cannot be changed during the\nsession once the model has responded with audio at least once. Current\nvoice options are `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`,\n`shimmer`, `verse`, `marin`, and `cedar`. We recommend `marin` and `cedar` for\nbest quality.\n",
                              "anyOf": [
                                {
                                  "type": "string"
                                },
                                {
                                  "enum": [
                                    "alloy",
                                    "ash",
                                    "ballad",
                                    "coral",
                                    "echo",
                                    "sage",
                                    "shimmer",
                                    "verse",
                                    "marin",
                                    "cedar"
                                  ],
                                  "type": "string"
                                }
                              ],
                              "example": "ash"
                            }
                          },
                          "type": "object"
                        }
                      },
                      "type": "object"
                    },
                    "include": {
                      "description": "Additional fields to include in server outputs.\n\n`item.input_audio_transcription.logprobs`: Include logprobs for input audio transcription.\n",
                      "items": {
                        "enum": [
                          "item.input_audio_transcription.logprobs"
                        ],
                        "type": "string"
                      },
                      "type": "array"
                    },
                    "instructions": {
                      "description": "The default system instructions (i.e. system message) prepended to model calls. This field allows the client to guide the model on desired responses. The model can be instructed on response content and format, (e.g. \"be extremely succinct\", \"act friendly\", \"here are examples of good responses\") and on audio behavior (e.g. \"talk quickly\", \"inject emotion into your voice\", \"laugh frequently\"). The instructions are not guaranteed to be followed by the model, but they provide guidance to the model on the desired behavior.\n\nNote that the server sets default instructions which will be used if this field is not set and are visible in the `session.created` event at the start of the session.\n",
                      "type": "string"
                    },
                    "max_output_tokens": {
                      "anyOf": [
                        {
                          "type": "integer"
                        },
                        {
                          "enum": [
                            "inf"
                          ],
                          "type": "string"
                        }
                      ],
                      "description": "Maximum number of output tokens for a single assistant response,\ninclusive of tool calls. Provide an integer between 1 and 4096 to\nlimit output tokens, or `inf` for the maximum available tokens for a\ngiven model. Defaults to `inf`.\n"
                    },
                    "model": {
                      "anyOf": [
                        {
                          "type": "string"
                        },
                        {
                          "enum": [
                            "gpt-realtime",
                            "gpt-realtime-2025-08-28",
                            "gpt-4o-realtime-preview",
                            "gpt-4o-realtime-preview-2024-10-01",
                            "gpt-4o-realtime-preview-2024-12-17",
                            "gpt-4o-realtime-preview-2025-06-03",
                            "gpt-4o-mini-realtime-preview",
                            "gpt-4o-mini-realtime-preview-2024-12-17",
                            "gpt-realtime-mini",
                            "gpt-realtime-mini-2025-10-06",
                            "gpt-audio-mini",
                            "gpt-audio-mini-2025-10-06"
                          ],
                          "type": "string"
                        }
                      ],
                      "description": "The Realtime model used for this session.\n"
                    },
                    "output_modalities": {
                      "default": [
                        "audio"
                      ],
                      "description": "The set of modalities the model can respond with. It defaults to `[\"audio\"]`, indicating\nthat the model will respond with audio plus a transcript. `[\"text\"]` can be used to make\nthe model respond with text only. It is not possible to request both `text` and `audio` at the same time.\n",
                      "items": {
                        "enum": [
                          "text",
                          "audio"
                        ],
                        "type": "string"
                      },
                      "type": "array"
                    },
                    "prompt": {
                      "anyOf": [
                        {
                          "description": "Reference to a prompt template and its variables.\n[Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n",
                          "properties": {
                            "id": {
                              "description": "The unique identifier of the prompt template to use.",
                              "type": "string"
                            },
                            "variables": {
                              "anyOf": [
                                {
                                  "additionalProperties": {
                                    "anyOf": [
                                      {
                                        "type": "string"
                                      },
                                      {
                                        "description": "A text input to the model.",
                                        "properties": {
                                          "text": {
                                            "description": "The text input to the model.",
                                            "type": "string"
                                          },
                                          "type": {
                                            "default": "input_text",
                                            "description": "The type of the input item. Always `input_text`.",
                                            "enum": [
                                              "input_text"
                                            ],
                                            "type": "string"
                                          }
                                        },
                                        "required": [
                                          "type",
                                          "text"
                                        ],
                                        "title": "Input text",
                                        "type": "object"
                                      },
                                      {
                                        "description": "An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).",
                                        "properties": {
                                          "detail": {
                                            "description": "The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.",
                                            "enum": [
                                              "low",
                                              "high",
                                              "auto"
                                            ],
                                            "type": "string"
                                          },
                                          "file_id": {
                                            "anyOf": [
                                              {
                                                "description": "The ID of the file to be sent to the model.",
                                                "type": "string"
                                              },
                                              {
                                                "type": "null"
                                              }
                                            ]
                                          },
                                          "image_url": {
                                            "anyOf": [
                                              {
                                                "description": "The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.",
                                                "type": "string"
                                              },
                                              {
                                                "type": "null"
                                              }
                                            ]
                                          },
                                          "type": {
                                            "default": "input_image",
                                            "description": "The type of the input item. Always `input_image`.",
                                            "enum": [
                                              "input_image"
                                            ],
                                            "type": "string"
                                          }
                                        },
                                        "required": [
                                          "type",
                                          "detail"
                                        ],
                                        "title": "Input image",
                                        "type": "object"
                                      },
                                      {
                                        "description": "A file input to the model.",
                                        "properties": {
                                          "file_data": {
                                            "description": "The content of the file to be sent to the model.\n",
                                            "type": "string"
                                          },
                                          "file_id": {
                                            "anyOf": [
                                              {
                                                "description": "The ID of the file to be sent to the model.",
                                                "type": "string"
                                              },
                                              {
                                                "type": "null"
                                              }
                                            ]
                                          },
                                          "file_url": {
                                            "description": "The URL of the file to be sent to the model.",
                                            "type": "string"
                                          },
                                          "filename": {
                                            "description": "The name of the file to be sent to the model.",
                                            "type": "string"
                                          },
                                          "type": {
                                            "default": "input_file",
                                            "description": "The type of the input item. Always `input_file`.",
                                            "enum": [
                                              "input_file"
                                            ],
                                            "type": "string"
                                          }
                                        },
                                        "required": [
                                          "type"
                                        ],
                                        "title": "Input file",
                                        "type": "object"
                                      }
                                    ]
                                  },
                                  "description": "Optional map of values to substitute in for variables in your\nprompt. The substitution values can either be strings, or other\nResponse input types like images or files.\n",
                                  "title": "Prompt Variables",
                                  "type": "object"
                                },
                                {
                                  "type": "null"
                                }
                              ]
                            },
                            "version": {
                              "anyOf": [
                                {
                                  "description": "Optional version of the prompt template.",
                                  "type": "string"
                                },
                                {
                                  "type": "null"
                                }
                              ]
                            }
                          },
                          "required": [
                            "id"
                          ],
                          "type": "object"
                        },
                        {
                          "type": "null"
                        }
                      ]
                    },
                    "tool_choice": {
                      "anyOf": [
                        {
                          "description": "Controls which (if any) tool is called by the model.\n\n`none` means the model will not call any tool and instead generates a message.\n\n`auto` means the model can pick between generating a message or calling one or\nmore tools.\n\n`required` means the model must call one or more tools.\n",
                          "enum": [
                            "none",
                            "auto",
                            "required"
                          ],
                          "title": "Tool choice mode",
                          "type": "string"
                        },
                        {
                          "description": "Use this option to force the model to call a specific function.\n",
                          "properties": {
                            "name": {
                              "description": "The name of the function to call.",
                              "type": "string"
                            },
                            "type": {
                              "description": "For function calling, the type is always `function`.",
                              "enum": [
                                "function"
                              ],
                              "type": "string"
                            }
                          },
                          "required": [
                            "type",
                            "name"
                          ],
                          "title": "Function tool",
                          "type": "object"
                        },
                        {
                          "description": "Use this option to force the model to call a specific tool on a remote MCP server.\n",
                          "properties": {
                            "name": {
                              "anyOf": [
                                {
                                  "description": "The name of the tool to call on the server.\n",
                                  "type": "string"
                                },
                                {
                                  "type": "null"
                                }
                              ]
                            },
                            "server_label": {
                              "description": "The label of the MCP server to use.\n",
                              "type": "string"
                            },
                            "type": {
                              "description": "For MCP tools, the type is always `mcp`.",
                              "enum": [
                                "mcp"
                              ],
                              "type": "string"
                            }
                          },
                          "required": [
                            "type",
                            "server_label"
                          ],
                          "title": "MCP tool",
                          "type": "object"
                        }
                      ],
                      "default": "auto",
                      "description": "How the model chooses tools. Provide one of the string modes or force a specific\nfunction/MCP tool.\n"
                    },
                    "tools": {
                      "description": "Tools available to the model.",
                      "items": {
                        "anyOf": [
                          {
                            "properties": {
                              "description": {
                                "description": "The description of the function, including guidance on when and how\nto call it, and guidance about what to tell the user when calling\n(if anything).\n",
                                "type": "string"
                              },
                              "name": {
                                "description": "The name of the function.",
                                "type": "string"
                              },
                              "parameters": {
                                "description": "Parameters of the function in JSON Schema.",
                                "type": "object"
                              },
                              "type": {
                                "description": "The type of the tool, i.e. `function`.",
                                "enum": [
                                  "function"
                                ],
                                "type": "string"
                              }
                            },
                            "title": "Function tool",
                            "type": "object"
                          },
                          {
                            "description": "Give the model access to additional tools via remote Model Context Protocol\n(MCP) servers. [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n",
                            "properties": {
                              "allowed_tools": {
                                "anyOf": [
                                  {
                                    "anyOf": [
                                      {
                                        "description": "A string array of allowed tool names",
                                        "items": {
                                          "type": "string"
                                        },
                                        "title": "MCP allowed tools",
                                        "type": "array"
                                      },
                                      {
                                        "additionalProperties": false,
                                        "description": "A filter object to specify which tools are allowed.\n",
                                        "properties": {
                                          "read_only": {
                                            "description": "Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n",
                                            "type": "boolean"
                                          },
                                          "tool_names": {
                                            "description": "List of allowed tool names.",
                                            "items": {
                                              "type": "string"
                                            },
                                            "title": "MCP allowed tools",
                                            "type": "array"
                                          }
                                        },
                                        "required": [],
                                        "title": "MCP tool filter",
                                        "type": "object"
                                      }
                                    ],
                                    "description": "List of allowed tool names or a filter object.\n"
                                  },
                                  {
                                    "type": "null"
                                  }
                                ]
                              },
                              "authorization": {
                                "description": "An OAuth access token that can be used with a remote MCP server, either\nwith a custom MCP server URL or a service connector. Your application\nmust handle the OAuth authorization flow and provide the token here.\n",
                                "type": "string"
                              },
                              "connector_id": {
                                "description": "Identifier for service connectors, like those available in ChatGPT. One of\n`server_url` or `connector_id` must be provided. Learn more about service\nconnectors [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).\n\nCurrently supported `connector_id` values are:\n\n- Dropbox: `connector_dropbox`\n- Gmail: `connector_gmail`\n- Google Calendar: `connector_googlecalendar`\n- Google Drive: `connector_googledrive`\n- Microsoft Teams: `connector_microsoftteams`\n- Outlook Calendar: `connector_outlookcalendar`\n- Outlook Email: `connector_outlookemail`\n- SharePoint: `connector_sharepoint`\n",
                                "enum": [
                                  "connector_dropbox",
                                  "connector_gmail",
                                  "connector_googlecalendar",
                                  "connector_googledrive",
                                  "connector_microsoftteams",
                                  "connector_outlookcalendar",
                                  "connector_outlookemail",
                                  "connector_sharepoint"
                                ],
                                "type": "string"
                              },
                              "headers": {
                                "anyOf": [
                                  {
                                    "additionalProperties": {
                                      "type": "string"
                                    },
                                    "description": "Optional HTTP headers to send to the MCP server. Use for authentication\nor other purposes.\n",
                                    "type": "object"
                                  },
                                  {
                                    "type": "null"
                                  }
                                ]
                              },
                              "require_approval": {
                                "anyOf": [
                                  {
                                    "anyOf": [
                                      {
                                        "additionalProperties": false,
                                        "description": "Specify which of the MCP server's tools require approval. Can be\n`always`, `never`, or a filter object associated with tools\nthat require approval.\n",
                                        "properties": {
                                          "always": {
                                            "additionalProperties": false,
                                            "description": "A filter object to specify which tools are allowed.\n",
                                            "properties": {
                                              "read_only": {
                                                "description": "Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n",
                                                "type": "boolean"
                                              },
                                              "tool_names": {
                                                "description": "List of allowed tool names.",
                                                "items": {
                                                  "type": "string"
                                                },
                                                "title": "MCP allowed tools",
                                                "type": "array"
                                              }
                                            },
                                            "required": [],
                                            "title": "MCP tool filter",
                                            "type": "object"
                                          },
                                          "never": {
                                            "additionalProperties": false,
                                            "description": "A filter object to specify which tools are allowed.\n",
                                            "properties": {
                                              "read_only": {
                                                "description": "Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n",
                                                "type": "boolean"
                                              },
                                              "tool_names": {
                                                "description": "List of allowed tool names.",
                                                "items": {
                                                  "type": "string"
                                                },
                                                "title": "MCP allowed tools",
                                                "type": "array"
                                              }
                                            },
                                            "required": [],
                                            "title": "MCP tool filter",
                                            "type": "object"
                                          }
                                        },
                                        "title": "MCP tool approval filter",
                                        "type": "object"
                                      },
                                      {
                                        "description": "Specify a single approval policy for all tools. One of `always` or\n`never`. When set to `always`, all tools will require approval. When\nset to `never`, all tools will not require approval.\n",
                                        "enum": [
                                          "always",
                                          "never"
                                        ],
                                        "title": "MCP tool approval setting",
                                        "type": "string"
                                      }
                                    ],
                                    "default": "always",
                                    "description": "Specify which of the MCP server's tools require approval."
                                  },
                                  {
                                    "type": "null"
                                  }
                                ]
                              },
                              "server_description": {
                                "description": "Optional description of the MCP server, used to provide more context.\n",
                                "type": "string"
                              },
                              "server_label": {
                                "description": "A label for this MCP server, used to identify it in tool calls.\n",
                                "type": "string"
                              },
                              "server_url": {
                                "description": "The URL for the MCP server. One of `server_url` or `connector_id` must be\nprovided.\n",
                                "type": "string"
                              },
                              "type": {
                                "description": "The type of the MCP tool. Always `mcp`.",
                                "enum": [
                                  "mcp"
                                ],
                                "type": "string"
                              }
                            },
                            "required": [
                              "type",
                              "server_label"
                            ],
                            "title": "MCP tool",
                            "type": "object"
                          }
                        ],
                        "discriminator": {
                          "propertyName": "type"
                        }
                      },
                      "type": "array"
                    },
                    "tracing": {
                      "anyOf": [
                        {
                          "default": "auto",
                          "description": "Default tracing mode for the session.\n",
                          "enum": [
                            "auto"
                          ],
                          "type": "string"
                        },
                        {
                          "description": "Granular configuration for tracing.\n",
                          "properties": {
                            "group_id": {
                              "description": "The group id to attach to this trace to enable filtering and\ngrouping in the Traces Dashboard.\n",
                              "type": "string"
                            },
                            "metadata": {
                              "description": "The arbitrary metadata to attach to this trace to enable\nfiltering in the Traces Dashboard.\n",
                              "type": "object"
                            },
                            "workflow_name": {
                              "description": "The name of the workflow to attach to this trace. This is used to\nname the trace in the Traces Dashboard.\n",
                              "type": "string"
                            }
                          },
                          "title": "Tracing Configuration",
                          "type": "object"
                        }
                      ],
                      "description": "Realtime API can write session traces to the [Traces Dashboard](/logs?api=traces). Set to null to disable tracing. Once\ntracing is enabled for a session, the configuration cannot be modified.\n\n`auto` will create a trace for the session with default values for the\nworkflow name, group id, and metadata.\n",
                      "nullable": true,
                      "title": "Tracing Configuration"
                    },
                    "truncation": {
                      "anyOf": [
                        {
                          "description": "The truncation strategy to use for the session. `auto` is the default truncation strategy. `disabled` will disable truncation and emit errors when the conversation exceeds the input token limit.",
                          "enum": [
                            "auto",
                            "disabled"
                          ],
                          "title": "RealtimeTruncationStrategy",
                          "type": "string"
                        },
                        {
                          "description": "Retain a fraction of the conversation tokens when the conversation exceeds the input token limit. This allows you to amortize truncations across multiple turns, which can help improve cached token usage.",
                          "properties": {
                            "retention_ratio": {
                              "description": "Fraction of post-instruction conversation tokens to retain (0.0 - 1.0) when the conversation exceeds the input token limit.\n",
                              "maximum": 1,
                              "minimum": 0,
                              "type": "number"
                            },
                            "type": {
                              "description": "Use retention ratio truncation.",
                              "enum": [
                                "retention_ratio"
                              ],
                              "type": "string"
                            }
                          },
                          "required": [
                            "type",
                            "retention_ratio"
                          ],
                          "title": "Retention ratio truncation",
                          "type": "object"
                        }
                      ],
                      "description": "Controls how the realtime conversation is truncated prior to model inference.\nThe default is `auto`.\n",
                      "title": "Realtime Truncation Controls"
                    },
                    "type": {
                      "description": "The type of session to create. Always `realtime` for the Realtime API.\n",
                      "enum": [
                        "realtime"
                      ],
                      "type": "string"
                    }
                  },
                  "required": [
                    "type"
                  ],
                  "title": "Realtime session configuration",
                  "type": "object"
                }
              ],
              "description": "Optional session configuration to apply before the realtime session is\ncreated. Use the same parameters you would send in a [`create client secret`](https://platform.openai.com/docs/api-reference/realtime-sessions/create-realtime-client-secret)\nrequest.",
              "title": "Session configuration"
            }
          },
          "required": [
            "sdp"
          ],
          "title": "Realtime call creation request",
          "type": "object"
        }
      }
    },
    "required": true
  },
  "responses": {
    "201": {
      "content": {
        "application/sdp": {
          "schema": {
            "description": "SDP answer produced by OpenAI for the peer connection.",
            "type": "string"
          }
        }
      },
      "description": "Realtime call created successfully.",
      "headers": {
        "Location": {
          "description": "Relative URL containing the call ID for subsequent control requests.",
          "schema": {
            "type": "string"
          }
        }
      }
    }
  },
  "summary": "Create call",
  "tags": [
    "Realtime"
  ]
}
