{
  "operationId": "PreRecordedController_initPreRecordedJob_v2",
  "parameters": [],
  "requestBody": {
    "content": {
      "application/json": {
        "schema": {
          "$ref": "#/components/schemas/InitTranscriptionRequest"
        }
      }
    },
    "required": true
  },
  "responses": {
    "201": {
      "content": {
        "application/json": {
          "schema": {
            "$ref": "#/components/schemas/InitPreRecordedTranscriptionResponse"
          }
        }
      },
      "description": "The pre recorded job has been initiated"
    },
    "400": {
      "content": {
        "application/json": {
          "schema": {
            "$ref": "#/components/schemas/BadRequestErrorResponse"
          }
        }
      },
      "description": "Something is wrong with the request"
    },
    "401": {
      "content": {
        "application/json": {
          "schema": {
            "$ref": "#/components/schemas/UnauthorizedErrorResponse"
          }
        }
      },
      "description": "You don't have the permissions to initiate a new pre recorded job"
    },
    "422": {
      "content": {
        "application/json": {
          "schema": {
            "$ref": "#/components/schemas/UnprocessableEntityErrorResponse"
          }
        }
      },
      "description": "The parameters you gave are incorrect"
    }
  },
  "security": [
    {
      "x_gladia_key": []
    }
  ],
  "summary": "Initiate a new pre recorded job",
  "tags": [
    "Pre-recorded V2"
  ],
  "components": {
    "schemas": {
      "InitTranscriptionRequest": {
        "properties": {
          "audio_to_llm": {
            "default": false,
            "description": "**[Alpha]** Enable audio to llm processing for this audio",
            "type": "boolean"
          },
          "audio_to_llm_config": {
            "allOf": [
              {
                "$ref": "#/components/schemas/AudioToLlmListConfigDTO"
              }
            ],
            "description": "**[Alpha]** Audio to llm configuration, if `audio_to_llm` is enabled"
          },
          "audio_url": {
            "description": "URL to a Gladia file or to an external audio or video file",
            "example": "http://files.gladia.io/example/audio-transcription/split_infinity.wav",
            "format": "uri",
            "type": "string"
          },
          "callback": {
            "default": false,
            "description": "Enable callback for this transcription. If true, the `callback_config` property will be used to customize the callback behaviour",
            "type": "boolean"
          },
          "callback_config": {
            "allOf": [
              {
                "$ref": "#/components/schemas/CallbackConfigDto"
              }
            ],
            "description": "Customize the callback behaviour (url and http method)"
          },
          "callback_url": {
            "deprecated": true,
            "description": "**[Deprecated]** Use `callback`/`callback_config` instead. Callback URL we will do a `POST` request to with the result of the transcription",
            "example": "http://callback.example",
            "format": "uri",
            "type": "string"
          },
          "chapterization": {
            "default": false,
            "description": "**[Alpha]** Enable chapterization for this audio",
            "type": "boolean"
          },
          "code_switching_config": {
            "allOf": [
              {
                "$ref": "#/components/schemas/CodeSwitchingConfigDTO"
              }
            ],
            "deprecated": true,
            "description": "**[Deprecated]** Use `language_config` instead. Specify the configuration for code switching"
          },
          "context_prompt": {
            "deprecated": true,
            "description": "**[Deprecated]** Context to feed the transcription model with for possible better accuracy",
            "type": "string"
          },
          "custom_metadata": {
            "additionalProperties": true,
            "description": "Custom metadata you can attach to this transcription",
            "example": {
              "user": "John Doe"
            },
            "type": "object"
          },
          "custom_spelling": {
            "default": false,
            "description": "**[Alpha]** Enable custom spelling for this audio",
            "type": "boolean"
          },
          "custom_spelling_config": {
            "allOf": [
              {
                "$ref": "#/components/schemas/CustomSpellingConfigDTO"
              }
            ],
            "description": "**[Alpha]** Custom spelling configuration, if `custom_spelling` is enabled"
          },
          "custom_vocabulary": {
            "default": false,
            "description": "**[Beta]** Can be either boolean to enable custom_vocabulary for this audio or an array with specific vocabulary list to feed the transcription model with",
            "type": "boolean"
          },
          "custom_vocabulary_config": {
            "allOf": [
              {
                "$ref": "#/components/schemas/CustomVocabularyConfigDTO"
              }
            ],
            "description": "**[Beta]** Custom vocabulary configuration, if `custom_vocabulary` is enabled"
          },
          "detect_language": {
            "default": true,
            "deprecated": true,
            "description": "**[Deprecated]** Use `language_config` instead. Detect the language from the given audio",
            "type": "boolean"
          },
          "diarization": {
            "default": false,
            "description": "Enable speaker recognition (diarization) for this audio",
            "type": "boolean"
          },
          "diarization_config": {
            "allOf": [
              {
                "$ref": "#/components/schemas/DiarizationConfigDTO"
              }
            ],
            "description": "Speaker recognition configuration, if `diarization` is enabled"
          },
          "display_mode": {
            "default": false,
            "description": "**[Alpha]** Allows to change the output display_mode for this audio. The output will be reordered, creating new utterances when speakers overlapped",
            "type": "boolean"
          },
          "enable_code_switching": {
            "default": false,
            "deprecated": true,
            "description": "**[Deprecated]** Use `language_config` instead.Detect multiple languages in the given audio",
            "type": "boolean"
          },
          "language": {
            "allOf": [
              {
                "$ref": "#/components/schemas/TranscriptionLanguageCodeEnum"
              }
            ],
            "deprecated": true,
            "description": "**[Deprecated]** Use `language_config` instead. Set the spoken language for the given audio (ISO 639 standard)",
            "example": "en"
          },
          "language_config": {
            "allOf": [
              {
                "$ref": "#/components/schemas/LanguageConfig"
              }
            ],
            "description": "Specify the language configuration"
          },
          "moderation": {
            "default": false,
            "description": "**[Alpha]** Enable moderation for this audio",
            "type": "boolean"
          },
          "name_consistency": {
            "default": false,
            "description": "**[Alpha]** Enable names consistency for this audio",
            "type": "boolean"
          },
          "named_entity_recognition": {
            "default": false,
            "description": "**[Alpha]** Enable named entity recognition for this audio",
            "type": "boolean"
          },
          "pii_redaction": {
            "default": false,
            "description": "Enable PII redaction for this audio",
            "type": "boolean"
          },
          "pii_redaction_config": {
            "allOf": [
              {
                "$ref": "#/components/schemas/PiiRedactionConfigDTO"
              }
            ],
            "description": "PII redaction configuration, if `pii_redaction` is enabled"
          },
          "punctuation_enhanced": {
            "default": false,
            "description": "**[Alpha]** Use enhanced punctuation for this audio",
            "type": "boolean"
          },
          "sentences": {
            "default": false,
            "description": "Enable sentences for this audio",
            "type": "boolean"
          },
          "sentiment_analysis": {
            "default": false,
            "description": "Enable sentiment analysis for this audio",
            "type": "boolean"
          },
          "structured_data_extraction": {
            "default": false,
            "description": "**[Alpha]** Enable structured data extraction for this audio",
            "type": "boolean"
          },
          "structured_data_extraction_config": {
            "allOf": [
              {
                "$ref": "#/components/schemas/StructuredDataExtractionConfigDTO"
              }
            ],
            "description": "**[Alpha]** Structured data extraction configuration, if `structured_data_extraction` is enabled"
          },
          "subtitles": {
            "default": false,
            "description": "Enable subtitles generation for this transcription",
            "type": "boolean"
          },
          "subtitles_config": {
            "allOf": [
              {
                "$ref": "#/components/schemas/SubtitlesConfigDTO"
              }
            ],
            "description": "Configuration for subtitles generation if `subtitles` is enabled"
          },
          "summarization": {
            "default": false,
            "description": "**[Beta]** Enable summarization for this audio",
            "type": "boolean"
          },
          "summarization_config": {
            "allOf": [
              {
                "$ref": "#/components/schemas/SummarizationConfigDTO"
              }
            ],
            "description": "**[Beta]** Summarization configuration, if `summarization` is enabled"
          },
          "translation": {
            "default": false,
            "description": "**[Beta]** Enable translation for this audio",
            "type": "boolean"
          },
          "translation_config": {
            "allOf": [
              {
                "$ref": "#/components/schemas/TranslationConfigDTO"
              }
            ],
            "description": "**[Beta]** Translation configuration, if `translation` is enabled"
          }
        },
        "required": [
          "audio_url"
        ],
        "type": "object"
      },
      "InitPreRecordedTranscriptionResponse": {
        "properties": {
          "id": {
            "description": "Id of the job",
            "example": "45463597-20b7-4af7-b3b3-f5fb778203ab",
            "format": "uuid",
            "type": "string"
          },
          "result_url": {
            "description": "Prebuilt URL with your transcription `id` to fetch the result",
            "example": "https://api.gladia.io/v2/transcription/45463597-20b7-4af7-b3b3-f5fb778203ab",
            "format": "uri",
            "type": "string"
          }
        },
        "required": [
          "id",
          "result_url"
        ],
        "type": "object"
      },
      "BadRequestErrorResponse": {
        "properties": {
          "message": {
            "description": "Error message",
            "example": "Content-Type is missing Multipart Boundary.",
            "type": "string"
          },
          "path": {
            "description": "Path to the API endpoint",
            "example": "/v2/transcription/45463597-20b7-4af7-b3b3-f5fb778203ab",
            "type": "string"
          },
          "request_id": {
            "description": "Debug id",
            "example": "G-821fe9df",
            "type": "string"
          },
          "statusCode": {
            "description": "HTTP status code of the error",
            "example": 400,
            "type": "number"
          },
          "timestamp": {
            "description": "Date of when the error occurred",
            "example": "2023-12-28T09:04:17.210Z",
            "type": "string"
          },
          "validation_errors": {
            "description": "List of validation errors, if any",
            "example": [
              "Field \"language\" must be a string",
              "Field \"min_speakers\" must be a number"
            ],
            "items": {
              "type": "string"
            },
            "type": "array"
          }
        },
        "required": [
          "timestamp",
          "path",
          "request_id",
          "statusCode",
          "message"
        ],
        "type": "object"
      },
      "UnauthorizedErrorResponse": {
        "properties": {
          "message": {
            "description": "Error message",
            "example": "gladia key not found",
            "type": "string"
          },
          "path": {
            "description": "Path to the API endpoint",
            "example": "/v2/transcription/45463597-20b7-4af7-b3b3-f5fb778203ab",
            "type": "string"
          },
          "request_id": {
            "description": "Debug id",
            "example": "G-821fe9df",
            "type": "string"
          },
          "statusCode": {
            "description": "HTTP status code of the error",
            "example": 401,
            "type": "number"
          },
          "timestamp": {
            "description": "Date of when the error occurred",
            "example": "2023-12-28T09:04:17.210Z",
            "type": "string"
          }
        },
        "required": [
          "timestamp",
          "path",
          "request_id",
          "statusCode",
          "message"
        ],
        "type": "object"
      },
      "UnprocessableEntityErrorResponse": {
        "properties": {
          "message": {
            "description": "Error message",
            "example": "Invalid parameter",
            "type": "string"
          },
          "path": {
            "description": "Path to the API endpoint",
            "example": "/v2/transcription/45463597-20b7-4af7-b3b3-f5fb778203ab",
            "type": "string"
          },
          "request_id": {
            "description": "Debug id",
            "example": "G-821fe9df",
            "type": "string"
          },
          "statusCode": {
            "description": "HTTP status code of the error",
            "example": 422,
            "type": "number"
          },
          "timestamp": {
            "description": "Date of when the error occurred",
            "example": "2023-12-28T09:04:17.210Z",
            "type": "string"
          }
        },
        "required": [
          "timestamp",
          "path",
          "request_id",
          "statusCode",
          "message"
        ],
        "type": "object"
      },
      "AudioToLlmListConfigDTO": {
        "properties": {
          "prompts": {
            "description": "The list of prompts applied on the audio transcription",
            "example": [
              "Extract the key points from the transcription"
            ],
            "items": {
              "type": "array"
            },
            "minItems": 1,
            "type": "array"
          }
        },
        "required": [
          "prompts"
        ],
        "type": "object"
      },
      "CallbackConfigDto": {
        "properties": {
          "method": {
            "allOf": [
              {
                "$ref": "#/components/schemas/CallbackMethodEnum"
              }
            ],
            "default": "POST",
            "description": "The HTTP method to be used. Allowed values are `POST` or `PUT` (default: `POST`)",
            "example": "POST"
          },
          "url": {
            "description": "The URL to be called with the result of the transcription",
            "example": "http://callback.example",
            "format": "uri",
            "type": "string"
          }
        },
        "required": [
          "url"
        ],
        "type": "object"
      },
      "CodeSwitchingConfigDTO": {
        "properties": {
          "languages": {
            "default": [],
            "description": "Specify the languages you want to use when detecting multiple languages",
            "items": {
              "$ref": "#/components/schemas/TranscriptionLanguageCodeEnum"
            },
            "type": "array"
          }
        },
        "type": "object"
      },
      "CustomSpellingConfigDTO": {
        "properties": {
          "spelling_dictionary": {
            "additionalProperties": {
              "items": {
                "type": "string"
              },
              "type": "array"
            },
            "description": "The list of spelling applied on the audio transcription",
            "example": {
              "Gettleman": [
                "gettleman"
              ],
              "SQL": [
                "Sequel"
              ]
            },
            "type": "object"
          }
        },
        "required": [
          "spelling_dictionary"
        ],
        "type": "object"
      },
      "CustomVocabularyConfigDTO": {
        "properties": {
          "default_intensity": {
            "description": "Default intensity for the custom vocabulary",
            "example": 0.5,
            "maximum": 1,
            "minimum": 0,
            "type": "number"
          },
          "vocabulary": {
            "description": "Specific vocabulary list to feed the transcription model with. Each item can be a string or an object with the following properties: value, intensity, pronunciations, language.",
            "example": [
              "Westeros",
              {
                "value": "Stark"
              },
              {
                "intensity": 0.4,
                "language": "en",
                "pronunciations": [
                  "Nightz Watch"
                ],
                "value": "Night's Watch"
              }
            ],
            "items": {
              "oneOf": [
                {
                  "$ref": "#/components/schemas/CustomVocabularyEntryDTO"
                },
                {
                  "type": "string"
                }
              ]
            },
            "type": "array"
          }
        },
        "required": [
          "vocabulary"
        ],
        "type": "object"
      },
      "DiarizationConfigDTO": {
        "properties": {
          "max_speakers": {
            "description": "Maximum number of speakers in the audio",
            "example": 2,
            "minimum": 0,
            "type": "integer"
          },
          "min_speakers": {
            "description": "Minimum number of speakers in the audio",
            "example": 1,
            "minimum": 0,
            "type": "integer"
          },
          "number_of_speakers": {
            "description": "Exact number of speakers in the audio",
            "example": 3,
            "minimum": 1,
            "type": "integer"
          }
        },
        "type": "object"
      },
      "TranscriptionLanguageCodeEnum": {
        "description": "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language.",
        "enum": [
          "af",
          "am",
          "ar",
          "as",
          "az",
          "ba",
          "be",
          "bg",
          "bn",
          "bo",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fo",
          "fr",
          "gl",
          "gu",
          "ha",
          "haw",
          "he",
          "hi",
          "hr",
          "ht",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jw",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "la",
          "lb",
          "ln",
          "lo",
          "lt",
          "lv",
          "mg",
          "mi",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "mt",
          "my",
          "ne",
          "nl",
          "nn",
          "no",
          "oc",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "sn",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "tg",
          "th",
          "tk",
          "tl",
          "tr",
          "tt",
          "uk",
          "ur",
          "uz",
          "vi",
          "yi",
          "yo",
          "zh"
        ],
        "type": "string"
      },
      "LanguageConfig": {
        "properties": {
          "code_switching": {
            "default": false,
            "description": "If true, language will be auto-detected on each utterance. Otherwise, language will be auto-detected on first utterance and then used for the rest of the transcription. If one language is set, this option will be ignored.",
            "type": "boolean"
          },
          "languages": {
            "default": [],
            "description": "If one language is set, it will be used for the transcription. Otherwise, language will be auto-detected by the model.",
            "items": {
              "$ref": "#/components/schemas/TranscriptionLanguageCodeEnum"
            },
            "type": "array"
          }
        },
        "type": "object"
      },
      "PiiRedactionConfigDTO": {
        "properties": {
          "entity_types": {
            "allOf": [
              {
                "$ref": "#/components/schemas/PiiRedactionEntityTypeEnum"
              }
            ],
            "description": "The entity types to redact",
            "example": [
              5,
              7,
              8,
              12,
              20,
              37,
              48
            ]
          },
          "processed_text_type": {
            "description": "The type of processed text to return (marker or mask)",
            "enum": [
              "MARKER",
              "MASK"
            ],
            "example": "MARKER",
            "type": "string"
          }
        },
        "required": [
          "entity_types",
          "processed_text_type"
        ],
        "type": "object"
      },
      "StructuredDataExtractionConfigDTO": {
        "properties": {
          "classes": {
            "description": "The list of classes to extract from the audio transcription",
            "example": [
              "Persons",
              "Organizations"
            ],
            "items": {
              "type": "array"
            },
            "minItems": 1,
            "type": "array"
          }
        },
        "required": [
          "classes"
        ],
        "type": "object"
      },
      "SubtitlesConfigDTO": {
        "properties": {
          "formats": {
            "default": [
              "srt"
            ],
            "description": "Subtitles formats you want your transcription to be formatted to",
            "example": [
              "srt"
            ],
            "items": {
              "$ref": "#/components/schemas/SubtitlesFormatEnum"
            },
            "minItems": 1,
            "type": "array"
          },
          "maximum_characters_per_row": {
            "description": "Maximum number of characters per row in a subtitle",
            "minimum": 1,
            "type": "integer"
          },
          "maximum_duration": {
            "description": "Maximum duration of a subtitle in seconds",
            "maximum": 30,
            "minimum": 1,
            "type": "number"
          },
          "maximum_rows_per_caption": {
            "description": "Maximum number of rows per caption",
            "maximum": 5,
            "minimum": 1,
            "type": "integer"
          },
          "minimum_duration": {
            "description": "Minimum duration of a subtitle in seconds",
            "minimum": 0,
            "type": "number"
          },
          "style": {
            "allOf": [
              {
                "$ref": "#/components/schemas/SubtitlesStyleEnum"
              }
            ],
            "default": "default",
            "description": "Style of the subtitles. Compliance mode refers to : https://loc.gov/preservation/digital/formats//fdd/fdd000569.shtml#:~:text=SRT%20files%20are%20basic%20text,alongside%2C%20example%3A%20%22MyVideo123 "
          }
        },
        "type": "object"
      },
      "SummarizationConfigDTO": {
        "properties": {
          "type": {
            "allOf": [
              {
                "$ref": "#/components/schemas/SummaryTypesEnum"
              }
            ],
            "default": "general",
            "description": "The type of summarization to apply"
          }
        },
        "type": "object"
      },
      "TranslationConfigDTO": {
        "properties": {
          "context": {
            "description": "Context information to improve translation accuracy",
            "type": "string"
          },
          "context_adaptation": {
            "default": true,
            "description": "Enables or disables context-aware translation features that allow the model to adapt translations based on provided context.",
            "type": "boolean"
          },
          "informal": {
            "default": false,
            "description": "Forces the translation to use informal language forms when available in the target language.",
            "type": "boolean"
          },
          "lipsync": {
            "default": true,
            "description": "Whether to apply lipsync to the translated transcription. ",
            "type": "boolean"
          },
          "match_original_utterances": {
            "default": true,
            "description": "Align translated utterances with the original ones",
            "type": "boolean"
          },
          "model": {
            "allOf": [
              {
                "$ref": "#/components/schemas/TranslationModelEnum"
              }
            ],
            "default": "base",
            "description": "Model you want the translation model to use to translate"
          },
          "target_languages": {
            "description": "Target language in `iso639-1` format you want the transcription translated to",
            "example": [
              "en"
            ],
            "items": {
              "$ref": "#/components/schemas/TranslationLanguageCodeEnum"
            },
            "minItems": 1,
            "type": "array"
          }
        },
        "required": [
          "target_languages"
        ],
        "type": "object"
      },
      "CallbackMethodEnum": {
        "description": "The HTTP method to be used. Allowed values are `POST` or `PUT` (default: `POST`)",
        "enum": [
          "POST",
          "PUT"
        ],
        "type": "string"
      },
      "CustomVocabularyEntryDTO": {
        "properties": {
          "intensity": {
            "description": "The global intensity of the feature.",
            "example": 0.5,
            "maximum": 1,
            "minimum": 0,
            "type": "number"
          },
          "language": {
            "allOf": [
              {
                "$ref": "#/components/schemas/TranscriptionLanguageCodeEnum"
              }
            ],
            "description": "Specify the language in which it will be pronounced when sound comparison occurs. Default to transcription language.",
            "example": "en"
          },
          "pronunciations": {
            "description": "The pronunciations used in the transcription.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "value": {
            "description": "The text used to replace in the transcription.",
            "example": "Gladia",
            "type": "string"
          }
        },
        "required": [
          "value"
        ],
        "type": "object"
      },
      "PiiRedactionEntityTypeEnum": {
        "description": "The entity types to redact",
        "enum": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81
        ],
        "type": "number"
      },
      "SubtitlesFormatEnum": {
        "description": "Subtitles formats you want your transcription to be formatted to",
        "enum": [
          "srt",
          "vtt"
        ],
        "type": "string"
      },
      "SubtitlesStyleEnum": {
        "description": "Style of the subtitles. Compliance mode refers to : https://loc.gov/preservation/digital/formats//fdd/fdd000569.shtml#:~:text=SRT%20files%20are%20basic%20text,alongside%2C%20example%3A%20%22MyVideo123 ",
        "enum": [
          "default",
          "compliance"
        ],
        "type": "string"
      },
      "SummaryTypesEnum": {
        "description": "The type of summarization to apply",
        "enum": [
          "general",
          "bullet_points",
          "concise"
        ],
        "type": "string"
      },
      "TranslationModelEnum": {
        "description": "Model you want the translation model to use to translate",
        "enum": [
          "base",
          "enhanced"
        ],
        "type": "string"
      },
      "TranslationLanguageCodeEnum": {
        "description": "Target language in `iso639-1` format you want the transcription translated to",
        "enum": [
          "af",
          "am",
          "ar",
          "as",
          "az",
          "ba",
          "be",
          "bg",
          "bn",
          "bo",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fo",
          "fr",
          "gl",
          "gu",
          "ha",
          "haw",
          "he",
          "hi",
          "hr",
          "ht",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jw",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "la",
          "lb",
          "ln",
          "lo",
          "lt",
          "lv",
          "mg",
          "mi",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "mt",
          "my",
          "ne",
          "nl",
          "nn",
          "no",
          "oc",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "sn",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "tg",
          "th",
          "tk",
          "tl",
          "tr",
          "tt",
          "uk",
          "ur",
          "uz",
          "vi",
          "wo",
          "yi",
          "yo",
          "zh"
        ],
        "type": "string"
      }
    }
  }
}
