{
  "components": {
    "schemas": {
      "Annotation": {
        "properties": {
          "type": {
            "description": "The type of the annotation. Only supported type currently is `url_citation`.",
            "type": "string"
          },
          "url": {
            "description": "The URL of the web resource.",
            "type": "string"
          }
        },
        "required": ["type", "url"],
        "type": "object"
      },
      "ApiKey": {
        "properties": {
          "acls": {
            "description": "A list of ACLs authorized with the API key, e.g. `\"api-key:endpoint:*\"`, `\"api-key:model:*\"`.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "api_key_blocked": {
            "description": "Indicates whether the API key is blocked.",
            "type": "boolean"
          },
          "api_key_disabled": {
            "description": "Indicates whether the API key is disabled.",
            "type": "boolean"
          },
          "api_key_id": {
            "description": "ID of the API key.",
            "type": "string"
          },
          "create_time": {
            "description": "Creation time of the API key in Unix timestamp.",
            "type": "string"
          },
          "modified_by": {
            "description": "User ID of the user who last modified the API key.",
            "type": "string"
          },
          "modify_time": {
            "description": "Last modification time of the API key in Unix timestamp.",
            "type": "string"
          },
          "name": {
            "description": "The name of the API key specified by user.",
            "type": "string"
          },
          "redacted_api_key": {
            "description": "The redacted API key.",
            "type": "string"
          },
          "team_blocked": {
            "description": "Indicates whether the team that owns the API key.",
            "type": "boolean"
          },
          "team_id": {
            "description": "The team ID of the team that owns the API key.",
            "type": "string"
          },
          "user_id": {
            "description": "User ID the API key belongs to.",
            "type": "string"
          }
        },
        "required": [
          "redacted_api_key",
          "user_id",
          "name",
          "create_time",
          "modify_time",
          "modified_by",
          "team_id",
          "acls",
          "api_key_id",
          "team_blocked",
          "api_key_blocked",
          "api_key_disabled"
        ],
        "type": "object"
      },
      "ChatRequest": {
        "description": "The chat request body for `/v1/chat/completions` endpoint.",
        "properties": {
          "deferred": {
            "default": false,
            "description": "If set to `true`, the request returns a `request_id`. You can then get the deferred response by GET `/v1/chat/deferred-completion/{request_id}`.",
            "type": ["boolean", "null"]
          },
          "frequency_penalty": {
            "default": 0,
            "description": "(Not supported by reasoning models) Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.",
            "format": "float",
            "maximum": 2,
            "minimum": -2,
            "type": ["number", "null"]
          },
          "logit_bias": {
            "additionalProperties": {
              "format": "float",
              "type": "number"
            },
            "description": "(Unsupported) A JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.",
            "propertyNames": {
              "format": "int32",
              "type": "integer"
            },
            "type": ["object", "null"]
          },
          "logprobs": {
            "default": false,
            "description": "Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the content of message.",
            "type": ["boolean", "null"]
          },
          "max_completion_tokens": {
            "description": "An upper bound for the number of tokens that can be generated for a completion, only applies to visible output tokens (i.e. does not apply to tokens used for reasoning or function calls). Defaults to None, meaning the model will generate as many tokens as needed up until the model's maximum context length.",
            "example": 8192,
            "format": "int32",
            "type": ["integer", "null"]
          },
          "max_tokens": {
            "description": "\\[DEPRECATED\\] The maximum number of tokens that can be generated in the chat completion. Deprecated in favor of `max_completion_tokens`.",
            "example": 8192,
            "format": "int32",
            "type": ["integer", "null"]
          },
          "messages": {
            "description": "A list of messages that make up the the chat conversation. Different models support different message types, such as image and text.",
            "items": {
              "$ref": "#/components/schemas/Message"
            },
            "type": "array"
          },
          "model": {
            "description": "Model name for the model to use. Obtainable from <https://console.x.ai/team/default/models> or <https://docs.x.ai/docs/models>.",
            "example": "grok-4-0709",
            "type": "string"
          },
          "n": {
            "default": 1,
            "description": "How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep n as 1 to minimize costs.",
            "example": 1,
            "format": "int32",
            "minimum": 1,
            "type": ["integer", "null"]
          },
          "parallel_tool_calls": {
            "default": true,
            "description": "If set to false, the model can perform maximum one tool call.",
            "example": false,
            "type": ["boolean", "null"]
          },
          "presence_penalty": {
            "default": 0,
            "description": "(Not supported by `grok-3` and reasoning models) Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.",
            "format": "float",
            "maximum": 2,
            "minimum": -2,
            "type": ["number", "null"]
          },
          "reasoning_effort": {
            "description": "Constrains how hard a reasoning model thinks before responding. Not supported by `grok-4` and will result in error if used with `grok-4`. Possible values are `low` (uses fewer reasoning tokens) and `high` (uses more reasoning tokens).",
            "type": ["string", "null"]
          },
          "response_format": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/ResponseFormat",
                "description": "An object specifying the format that the model must output. Specify `{ \"type\": \"json_object\" }` for JSON output, or `{ \"type\": \"json_schema\", \"json_schema\": {...} }` for structured outputs. If `{ \\\"type\\\": \\\"text\\\" }`, the model will return a text response."
              }
            ]
          },
          "search_parameters": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/SearchParameters",
                "description": "Set the parameters to be used for searched data. If not set, no data will be acquired by the model."
              }
            ]
          },
          "seed": {
            "description": "If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result. Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.",
            "format": "int32",
            "type": ["integer", "null"]
          },
          "stop": {
            "description": "(Not supported by reasoning models) Up to 4 sequences where the API will stop generating further tokens.",
            "items": {
              "type": "string"
            },
            "type": ["array", "null"]
          },
          "stream": {
            "default": false,
            "description": "If set, partial message deltas will be sent. Tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a `data: [DONE]` message.",
            "example": true,
            "type": ["boolean", "null"]
          },
          "stream_options": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/StreamOptions",
                "description": "Options for streaming response. Only set this when you set `stream: true`."
              }
            ]
          },
          "temperature": {
            "default": 1,
            "description": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.",
            "example": 0.2,
            "format": "float",
            "maximum": 2,
            "minimum": 0,
            "type": ["number", "null"]
          },
          "tool_choice": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/ToolChoice",
                "description": "Controls which (if any) tool is called by the model. `none` means the model will not call any tool and instead generates a message. auto means the model can pick between generating a message or calling one or more tools. required means the model must call one or more tools. Specifying a particular tool via `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to call that tool. `none` is the default when no tools are present. `auto` is the default if tools are present."
              }
            ]
          },
          "tools": {
            "description": "A list of tools the model may call in JSON-schema. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.",
            "items": {
              "$ref": "#/components/schemas/Tool"
            },
            "maxItems": 128,
            "type": ["array", "null"]
          },
          "top_logprobs": {
            "description": "An integer between 0 and 8 specifying the number of most likely tokens to return at each token position, each with an associated log probability. logprobs must be set to true if this parameter is used.",
            "format": "int32",
            "maximum": 8,
            "minimum": 0,
            "type": ["integer", "null"]
          },
          "top_p": {
            "default": 1,
            "description": "An alternative to sampling with `temperature`, called nucleus sampling, where the model considers the results of the tokens with `top_p` probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. It is generally recommended to alter this or `temperature` but not both.",
            "exclusiveMinimum": 0,
            "format": "float",
            "maximum": 1,
            "type": ["number", "null"]
          },
          "user": {
            "description": "A unique identifier representing your end-user, which can help xAI to monitor and detect abuse.",
            "type": ["string", "null"]
          },
          "web_search_options": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/WebSearchOptions",
                "description": "Options to control the web search. This is only included for compatibility reason. Prefer\nthe usage of `realtime_data_parameters` instead."
              }
            ]
          }
        },
        "type": "object"
      },
      "ChatResponse": {
        "description": "The chat response body for `/v1/chat/completions` endpoint.",
        "properties": {
          "choices": {
            "description": "A list of response choices from the model. The length corresponds to the `n` in request body (default to 1).",
            "items": {
              "$ref": "#/components/schemas/Choice"
            },
            "type": "array"
          },
          "citations": {
            "description": "List of all the external pages used by the model to answer.",
            "items": {
              "type": "string"
            },
            "type": ["array", "null"]
          },
          "created": {
            "description": "The chat completion creation time in Unix timestamp.",
            "format": "int64",
            "type": "integer"
          },
          "debug_output": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/DebugOutput",
                "description": "Debug output. Only available to trusted testers."
              }
            ]
          },
          "id": {
            "description": "A unique ID for the chat response.",
            "type": "string"
          },
          "model": {
            "description": "Model ID used to create chat completion.",
            "example": "grok-4-0709",
            "type": "string"
          },
          "object": {
            "description": "The object type, which is always `\"chat.completion\"`.",
            "type": "string"
          },
          "system_fingerprint": {
            "description": "System fingerprint, used to indicate xAI system configuration changes.",
            "type": ["string", "null"]
          },
          "usage": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/Usage",
                "description": "Token usage information."
              }
            ]
          }
        },
        "required": ["id", "object", "created", "model", "choices"],
        "type": "object"
      },
      "ChatResponseChunk": {
        "properties": {
          "choices": {
            "description": "A list of response choices from the model. The length corresponds to the `n` in request body (default to 1).",
            "items": {
              "$ref": "#/components/schemas/ChoiceChunk"
            },
            "type": "array"
          },
          "citations": {
            "description": "List of all the external pages used by the model to answer. Only populated for the last chunk.",
            "items": {
              "type": "string"
            },
            "type": ["array", "null"]
          },
          "created": {
            "description": "The chat completion creation time in Unix timestamp.",
            "format": "int64",
            "type": "integer"
          },
          "debug_output": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/DebugOutput",
                "description": "Debug output. Only available to trusted testers."
              }
            ]
          },
          "id": {
            "description": "A unique ID for the chat response chunk.",
            "type": "string"
          },
          "model": {
            "description": "The model ID used to create chat completion.",
            "example": "grok-4-0709",
            "type": "string"
          },
          "object": {
            "description": "The object type, which is always `\"chat.completion.chunk\"`.",
            "type": "string"
          },
          "system_fingerprint": {
            "description": "System fingerprint, used to indicate xAI system configuration changes.",
            "type": ["string", "null"]
          },
          "usage": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/Usage",
                "description": "Token usage information."
              }
            ]
          }
        },
        "required": ["id", "object", "created", "model", "choices"],
        "type": "object"
      },
      "Choice": {
        "properties": {
          "finish_reason": {
            "description": "Finish reason. `\"stop\"` means the inference has reached a model-defined or user-supplied stop sequence in `stop`. `\"length\"` means the inference result has reached models' maximum allowed token length or user defined value in `max_tokens`. `\"end_turn\"` or `null` in streaming mode when the chunk is not the last.",
            "type": ["string", "null"]
          },
          "index": {
            "description": "Index of the choice within the response choices, starting from 0.",
            "format": "int32",
            "type": "integer"
          },
          "logprobs": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/LogProbs",
                "description": "The log probabilities of each output token returned in the content of message."
              }
            ]
          },
          "message": {
            "$ref": "#/components/schemas/ChoiceMessage",
            "description": "The generated chat completion message."
          }
        },
        "required": ["index", "message"],
        "type": "object"
      },
      "ChoiceChunk": {
        "properties": {
          "delta": {
            "$ref": "#/components/schemas/Delta",
            "description": "Additional difference (delta) of the result."
          },
          "finish_reason": {
            "description": "Finish reason. `\"stop\"` means the inference has reached a model-defined or user-supplied stop sequence in `stop`. `\"length\"` means the inference result has reached models' maximum allowed token length or user defined value in `max_tokens`. `\"end_turn\"` or `null` in streaming mode when the chunk is not the last.",
            "type": ["string", "null"]
          },
          "index": {
            "description": "Index of the choice.",
            "format": "int32",
            "type": "integer"
          },
          "logprobs": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/LogProbs",
                "description": "The log probabilities of each output token returned in the content of message."
              }
            ]
          }
        },
        "required": ["index", "delta"],
        "type": "object"
      },
      "ChoiceMessage": {
        "properties": {
          "content": {
            "description": "The content of the message.",
            "type": ["string", "null"]
          },
          "reasoning_content": {
            "description": "The reasoning trace generated by the model.",
            "type": ["string", "null"]
          },
          "refusal": {
            "description": "The reason given by model if the model is unable to generate a response. null if model is able to generate.",
            "type": ["string", "null"]
          },
          "role": {
            "description": "The role that the message belongs to, the response from model is always `\"assistant\"`.",
            "type": "string"
          },
          "tool_calls": {
            "description": "A list of tool calls asked by model for user to perform.",
            "items": {
              "$ref": "#/components/schemas/ToolCall"
            },
            "type": ["array", "null"]
          }
        },
        "required": ["role"],
        "type": "object"
      },
      "CompleteRequest": {
        "description": "(Legacy) Anthropic compatible complete request on `/v1/complete` endpoint.",
        "properties": {
          "max_tokens_to_sample": {
            "description": "The maximum number of tokens to generate before stopping.",
            "format": "int32",
            "type": "integer"
          },
          "metadata": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/MessageMetadata",
                "description": "An object describing metadata about the request."
              }
            ]
          },
          "model": {
            "description": "Model to use for completion.",
            "type": "string"
          },
          "prompt": {
            "description": "Prompt for the model to perform completion on.",
            "type": "string"
          },
          "stop_sequences": {
            "description": "(Not supported by reasoning models) Up to 4 sequences where the API will stop generating further tokens.",
            "items": {
              "type": "string"
            },
            "type": ["array", "null"]
          },
          "stream": {
            "description": "(Unsupported) If set, partial message deltas will be sent. Tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a `data: [DONE]` message.",
            "type": ["boolean", "null"]
          },
          "temperature": {
            "default": 1,
            "description": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.",
            "example": 0.2,
            "format": "float",
            "maximum": 2,
            "minimum": 0,
            "type": ["number", "null"]
          },
          "top_k": {
            "description": "(Unsupported) When generating next tokens, randomly selecting the next token from the k most likely options.",
            "format": "int32",
            "type": ["integer", "null"]
          },
          "top_p": {
            "default": 1,
            "description": "An alternative to sampling with `temperature`, called nucleus sampling, where the model considers the results of the tokens with `top_p` probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. It is generally recommended to alter this or `temperature` but not both.",
            "exclusiveMinimum": 0,
            "format": "float",
            "maximum": 1,
            "type": ["number", "null"]
          }
        },
        "type": "object"
      },
      "CompleteResponse": {
        "description": "(Legacy) Anthropic compatible complete response on `/v1/complete` endpoint.",
        "properties": {
          "completion": {
            "description": "The completion content up to and excluding stop sequences.",
            "type": "string"
          },
          "id": {
            "description": "ID of the completion response.",
            "type": "string"
          },
          "model": {
            "description": "The model that handled the request.",
            "type": "string"
          },
          "stop_reason": {
            "description": "The reason to stop completion. `\"stop_sequence\"` means the inference has reached a model-defined or user-supplied stop sequence in `stop`. `\"length\"` means the inference result has reached models' maximum allowed token length or user defined value in `max_tokens`. `\"end_turn\"` or `null` in streaming mode when the chunk is not the last.",
            "type": ["string", "null"]
          },
          "type": {
            "description": "Completion response object type. This is always `\"completion\"`.",
            "type": "string"
          }
        },
        "required": ["type", "id", "completion", "model"],
        "type": "object"
      },
      "CompletionUsageDetail": {
        "description": "Details of completion usage.",
        "properties": {
          "accepted_prediction_tokens": {
            "description": "The number of tokens in the prediction that appeared in the completion.",
            "format": "int32",
            "type": "integer"
          },
          "audio_tokens": {
            "description": "Audio input tokens generated by the model.",
            "format": "int32",
            "type": "integer"
          },
          "reasoning_tokens": {
            "description": "Tokens generated by the model for reasoning.",
            "format": "int32",
            "type": "integer"
          },
          "rejected_prediction_tokens": {
            "description": "The number of tokens in the prediction that did not appear in the completion.",
            "format": "int32",
            "type": "integer"
          }
        },
        "required": [
          "reasoning_tokens",
          "audio_tokens",
          "accepted_prediction_tokens",
          "rejected_prediction_tokens"
        ],
        "type": "object"
      },
      "Content": {
        "description": "Content of each chat message.",
        "oneOf": [
          {
            "description": "Text prompt.",
            "type": "string"
          },
          {
            "description": "An array of content parts of different types, such as image, text or text file.",
            "items": {
              "$ref": "#/components/schemas/ContentPart"
            },
            "type": "array"
          }
        ]
      },
      "ContentPart": {
        "properties": {
          "detail": {
            "description": "Specifies the detail level of the image.",
            "type": ["string", "null"]
          },
          "image_url": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/ImageUrl",
                "description": "A public URL of image prompt, only available for vision models."
              }
            ]
          },
          "text": {
            "description": "Text prompt.",
            "type": ["string", "null"]
          },
          "text_file": {
            "description": "File path to a text file to be used as prompt.",
            "type": ["string", "null"]
          },
          "type": {
            "description": "The type of the content part.",
            "type": "string"
          }
        },
        "required": ["type"],
        "type": "object"
      },
      "DebugOutput": {
        "properties": {
          "attempts": {
            "description": "Number of attempts made to the model.",
            "format": "int32",
            "type": "integer"
          },
          "cache_read_count": {
            "description": "Number of cache reads",
            "format": "int32",
            "minimum": 0,
            "type": "integer"
          },
          "cache_read_input_bytes": {
            "description": "Size of cache read",
            "format": "int64",
            "minimum": 0,
            "type": "integer"
          },
          "cache_write_count": {
            "description": "Number of cache writes",
            "format": "int32",
            "minimum": 0,
            "type": "integer"
          },
          "cache_write_input_bytes": {
            "description": "Size of cache write",
            "format": "int64",
            "minimum": 0,
            "type": "integer"
          },
          "chunks": {
            "description": "The individual chunks returned from the pipeline of samplers.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "engine_request": {
            "description": "JSON-serialized request sent to the inference engine.",
            "type": "string"
          },
          "lb_address": {
            "description": "The load balancer address",
            "type": "string"
          },
          "prompt": {
            "description": "The prompt sent to the model in text form.",
            "type": "string"
          },
          "request": {
            "description": "The request received from the user.",
            "type": "string"
          },
          "responses": {
            "description": "The response(s) received from the model.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "sampler_tag": {
            "description": "The tag of the actual engines sitting behind the GTP address. Eg \"grok-4-code-eapi-lap4-unified-sblbm-0\"",
            "type": "string"
          }
        },
        "required": [
          "attempts",
          "request",
          "prompt",
          "engine_request",
          "responses",
          "chunks",
          "cache_read_count",
          "cache_read_input_bytes",
          "cache_write_count",
          "cache_write_input_bytes",
          "lb_address",
          "sampler_tag"
        ],
        "type": "object"
      },
      "DeleteStoredCompletionResponse": {
        "description": "Response to delete a stored completion.",
        "properties": {
          "deleted": {
            "description": "Whether the response was successfully deleted.",
            "type": "boolean"
          },
          "id": {
            "description": "The response_id to be deleted.",
            "type": "string"
          },
          "object": {
            "description": "The deleted object type, which is always `response`.",
            "type": "string"
          }
        },
        "required": ["id", "object", "deleted"],
        "type": "object"
      },
      "Delta": {
        "properties": {
          "content": {
            "type": ["string", "null"]
          },
          "images": {
            "description": "Images generated by the model.",
            "items": {
              "type": "string"
            },
            "type": ["array", "null"]
          },
          "reasoning_content": {
            "type": ["string", "null"]
          },
          "role": {
            "type": ["string", "null"]
          },
          "tool_calls": {
            "items": {
              "$ref": "#/components/schemas/ToolCall"
            },
            "type": ["array", "null"]
          }
        },
        "type": "object"
      },
      "DocumentsSource": {
        "description": "DocumentsSource defines the source of documents to search over.",
        "properties": {
          "collection_ids": {
            "description": "The collection IDs to search in.",
            "items": {
              "type": "string"
            },
            "type": "array"
          }
        },
        "required": ["collection_ids"],
        "type": "object"
      },
      "EditImageRequest": {
        "description": "Request for editing image",
        "properties": {
          "image": {
            "$ref": "#/components/schemas/ImageUrl",
            "description": "Input image to perform edit on."
          },
          "mask": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/ImageUrl"
              }
            ]
          },
          "model": {
            "description": "Model to be used.",
            "example": "grok-2-image",
            "type": ["string", "null"]
          },
          "n": {
            "description": "Number of image edits to be generated.",
            "format": "int32",
            "type": ["integer", "null"]
          },
          "prompt": {
            "description": "Prompt for image editing.",
            "type": "string"
          },
          "response_format": {
            "default": "url",
            "description": "Response format to return the image in. Can be `url` or `b64_json`. If `b64_json` is specified, the image will be returned as a base64-encoded string instead of a url to the generated image file.",
            "type": ["string", "null"]
          },
          "size": {
            "description": "(Not supported) Size of the image.",
            "type": ["string", "null"]
          },
          "style": {
            "description": "(Not supported) Style of the image.",
            "type": ["string", "null"]
          },
          "user": {
            "description": "A unique identifier representing your end-user, which can help xAI to monitor and detect abuse.",
            "type": ["string", "null"]
          }
        },
        "required": ["prompt", "image"],
        "type": "object"
      },
      "Embedding": {
        "properties": {
          "embedding": {
            "$ref": "#/components/schemas/EmbeddingContent",
            "description": "Embedding content."
          },
          "index": {
            "description": "Index of the embedding object in the data list.",
            "format": "int32",
            "type": "integer"
          },
          "object": {
            "description": "The object type, which is always `\"embedding\"`.",
            "type": "string"
          }
        },
        "required": ["index", "embedding", "object"],
        "type": "object"
      },
      "EmbeddingContent": {
        "oneOf": [
          {
            "description": "Embedding in base64 string.",
            "type": "string"
          },
          {
            "description": "Embedding as an array of floats.",
            "items": {
              "format": "float",
              "type": "number"
            },
            "type": "array"
          }
        ]
      },
      "EmbeddingInput": {
        "oneOf": [
          {
            "description": "A strings to be embedded. For best performance, prepend \"query: \" in front of query content and prepend \"passage: \" in front of passage/text",
            "properties": {
              "String": {
                "description": "A strings to be embedded. For best performance, prepend \"query: \" in front of query content and prepend \"passage: \" in front of passage/text",
                "type": "string"
              }
            },
            "required": ["String"],
            "type": "object"
          },
          {
            "description": "An array of strings to be embedded",
            "properties": {
              "StringArray": {
                "description": "An array of strings to be embedded",
                "items": {
                  "type": "string"
                },
                "type": "array"
              }
            },
            "required": ["StringArray"],
            "type": "object"
          },
          {
            "description": "A token in integer to be embedded",
            "properties": {
              "Ints": {
                "description": "A token in integer to be embedded",
                "items": {
                  "format": "int32",
                  "type": "integer"
                },
                "type": "array"
              }
            },
            "required": ["Ints"],
            "type": "object"
          },
          {
            "description": "An array of tokens in integers to be embedded",
            "properties": {
              "IntsArray": {
                "description": "An array of tokens in integers to be embedded",
                "items": {
                  "items": {
                    "format": "int32",
                    "type": "integer"
                  },
                  "type": "array"
                },
                "type": "array"
              }
            },
            "required": ["IntsArray"],
            "type": "object"
          }
        ]
      },
      "EmbeddingModel": {
        "description": "Details of an embedding model",
        "properties": {
          "aliases": {
            "description": "Alias ID(s) of the model that user can use in a request's model field.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "created": {
            "description": "Model creation time in Unix timestamp.",
            "format": "int64",
            "type": "integer"
          },
          "fingerprint": {
            "description": "Fingerprint of the xAI system configuration hosting the model.",
            "type": "string"
          },
          "id": {
            "description": "Model ID. Obtainable from <https://console.x.ai/team/default/models> or <https://docs.x.ai/docs/models>.",
            "type": "string"
          },
          "input_modalities": {
            "description": "The input modalities supported by the model.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "object": {
            "description": "Object type, should be model.",
            "type": "string"
          },
          "output_modalities": {
            "description": "The output modalities supported by the model.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "owned_by": {
            "description": "Owner of the model.",
            "type": "string"
          },
          "prompt_image_token_price": {
            "description": "Price of the prompt image token in USD cents per million token.",
            "format": "int64",
            "type": "integer"
          },
          "prompt_text_token_price": {
            "description": "Price of the prompt text token in USD cents per million token.",
            "format": "int64",
            "type": "integer"
          },
          "version": {
            "description": "Version of the model.",
            "type": "string"
          }
        },
        "required": [
          "id",
          "fingerprint",
          "created",
          "object",
          "owned_by",
          "version",
          "input_modalities",
          "output_modalities",
          "prompt_text_token_price",
          "prompt_image_token_price",
          "aliases"
        ],
        "type": "object"
      },
      "EmbeddingRequest": {
        "properties": {
          "dimensions": {
            "description": "The number of dimensions the resulting output embeddings should have.",
            "format": "int32",
            "type": ["integer", "null"]
          },
          "encoding_format": {
            "description": "The format to return the embeddings in. Can be either `float` or `base64`.",
            "type": ["string", "null"]
          },
          "input": {
            "$ref": "#/components/schemas/EmbeddingInput",
            "description": "Input text to embed, encoded as a string or list of tokens. To embed multiple inputs in a single request, pass a list of strings or list of token lists. The total tokens in the input must not exceed the context window for the model and cannot be an empty string. If the input is a list, the maximum length of the list is 128."
          },
          "model": {
            "description": "ID of the model to use.",
            "example": "v1",
            "type": "string"
          },
          "preview": {
            "description": "Flag to use the new format of the API.",
            "type": ["boolean", "null"]
          },
          "user": {
            "description": "A unique identifier representing your end-user, which can help xAI to monitor and detect abuse.",
            "type": ["string", "null"]
          }
        },
        "type": "object"
      },
      "EmbeddingResponse": {
        "properties": {
          "data": {
            "description": "A list of embedding objects.",
            "items": {
              "$ref": "#/components/schemas/Embedding"
            },
            "type": "array"
          },
          "model": {
            "description": "Model ID used to create embedding.",
            "type": "string"
          },
          "object": {
            "description": "The object type of `data` field, which is always `\"list\"`.",
            "type": "string"
          },
          "usage": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/EmbeddingUsage",
                "description": "Token usage information."
              }
            ]
          }
        },
        "required": ["object", "model", "data"],
        "type": "object"
      },
      "EmbeddingUsage": {
        "properties": {
          "prompt_tokens": {
            "description": "Prompt token used.",
            "format": "int32",
            "type": "integer"
          },
          "total_tokens": {
            "description": "Total token used.",
            "format": "int32",
            "type": "integer"
          }
        },
        "required": ["prompt_tokens", "total_tokens"],
        "type": "object"
      },
      "Function": {
        "properties": {
          "arguments": {
            "type": "string"
          },
          "name": {
            "type": "string"
          }
        },
        "required": ["name", "arguments"],
        "type": "object"
      },
      "FunctionCall": {
        "properties": {
          "arguments": {
            "description": "Arguments available to the function.",
            "type": "string"
          },
          "name": {
            "description": "Name of the function.",
            "type": "string"
          }
        },
        "required": ["name", "arguments"],
        "type": "object"
      },
      "FunctionChoice": {
        "description": "Function name.",
        "properties": {
          "name": {
            "type": "string"
          }
        },
        "required": ["name"],
        "type": "object"
      },
      "FunctionDefinition": {
        "description": "Definition of the tool call made available to the model.",
        "properties": {
          "description": {
            "description": "A description of the function to indicate to the model when to call it.",
            "type": ["string", "null"]
          },
          "name": {
            "description": "The name of the function. If the model calls the function, this name is used in the\nresponse.",
            "type": "string"
          },
          "parameters": {
            "description": "A JSON schema describing the function parameters. The model _should_ follow the schema,\nhowever, this is not enforced at the moment."
          },
          "strict": {
            "description": "Not supported. Only maintained for compatibility reasons.",
            "type": ["boolean", "null"]
          }
        },
        "required": ["name", "parameters"],
        "type": "object"
      },
      "FunctionToolCall": {
        "description": "A tool call to run a function.",
        "properties": {
          "arguments": {
            "description": "The arguments to pass to the function, as a JSON string.",
            "type": "string"
          },
          "call_id": {
            "description": "The unique ID of the function tool call generated by the model.",
            "type": "string"
          },
          "id": {
            "description": "The unique ID of the function tool call.",
            "type": "string"
          },
          "name": {
            "description": "The name of the function.",
            "type": "string"
          },
          "status": {
            "description": "Status of the item. One of `completed`, `in_progress` or `incomplete`.",
            "type": "string"
          },
          "type": {
            "description": "The type of the function tool call, which is always `function_call`.",
            "type": "string"
          }
        },
        "required": ["arguments", "call_id", "name", "type"],
        "type": "object"
      },
      "FunctionToolCallOutput": {
        "description": "The output of a function tool call.",
        "properties": {
          "call_id": {
            "description": "The unique ID of the function tool call generated by the model.",
            "type": "string"
          },
          "output": {
            "description": "The output of the function tool call, as a JSON string.",
            "type": "string"
          },
          "type": {
            "description": "The type of the function tool call, which is always `function_call_output`.",
            "type": "string"
          }
        },
        "required": ["call_id", "output", "type"],
        "type": "object"
      },
      "GenerateImageRequest": {
        "description": "Request to generate image for `/v1/image/generations` endpoint",
        "properties": {
          "model": {
            "description": "Model to be used.",
            "example": "grok-2-image",
            "type": ["string", "null"]
          },
          "n": {
            "default": 1,
            "description": "Number of images to be generated",
            "format": "int32",
            "maximum": 10,
            "minimum": 1,
            "type": ["integer", "null"]
          },
          "prompt": {
            "description": "Prompt for image generation.",
            "type": "string"
          },
          "quality": {
            "description": "(Not supported) Quality of the image.",
            "type": ["string", "null"]
          },
          "response_format": {
            "default": "url",
            "description": "Response format to return the image in. Can be url or b64_json. If b64_json is specified, the image will be returned as a base64-encoded string instead of a url to the generated image file.",
            "type": ["string", "null"]
          },
          "size": {
            "description": "(Not supported) Size of the image.",
            "type": ["string", "null"]
          },
          "style": {
            "description": "(Not supported) Style of the image.",
            "type": ["string", "null"]
          },
          "user": {
            "description": "A unique identifier representing your end-user, which can help xAI to monitor and detect abuse.",
            "type": ["string", "null"]
          }
        },
        "type": "object"
      },
      "GeneratedImage": {
        "description": "Generated images",
        "properties": {
          "b64_json": {
            "description": "A base64-encoded string representation of the generated image in `jpeg` encoding, if `b64_json` is specified as `response_format` in the request.",
            "type": ["string", "null"]
          },
          "revised_prompt": {
            "description": "The revised prompt generated by a chat model from the original prompt. This prompt is used in the final image generation.",
            "type": "string"
          },
          "url": {
            "description": "A url to the generated image, if `response_format` is not specified or with `url` in the request.",
            "type": ["string", "null"]
          }
        },
        "required": ["revised_prompt"],
        "type": "object"
      },
      "GeneratedImageResponse": {
        "description": "Image generation response for `/v1/image/generations` endpoint",
        "properties": {
          "data": {
            "description": "A list of generated image objects.",
            "items": {
              "$ref": "#/components/schemas/GeneratedImage"
            },
            "type": "array"
          }
        },
        "required": ["data"],
        "type": "object"
      },
      "ImageGenerationModel": {
        "description": "Details of an image generation model",
        "properties": {
          "aliases": {
            "description": "Alias ID(s) of the model that user can use in a request's model field.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "created": {
            "description": "Model creation time in Unix timestamp.",
            "format": "int64",
            "type": "integer"
          },
          "fingerprint": {
            "description": "Fingerprint of the xAI system configuration hosting the model.",
            "type": "string"
          },
          "id": {
            "description": "Model ID.",
            "type": "string"
          },
          "image_price": {
            "description": "Price of a single image in USD cents.",
            "format": "int64",
            "type": "integer"
          },
          "input_modalities": {
            "description": "The input modalities supported by the model.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "max_prompt_length": {
            "format": "int64",
            "type": "integer"
          },
          "object": {
            "description": "The object type, which is always `\"model\"`.",
            "type": "string"
          },
          "output_modalities": {
            "description": "The output modalities supported by the model.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "owned_by": {
            "description": "Owner of the model.",
            "type": "string"
          },
          "version": {
            "description": "Version of the model.",
            "type": "string"
          }
        },
        "required": [
          "id",
          "fingerprint",
          "max_prompt_length",
          "created",
          "object",
          "owned_by",
          "version",
          "input_modalities",
          "output_modalities",
          "image_price",
          "aliases"
        ],
        "type": "object"
      },
      "ImageUrl": {
        "description": "Image URL object of Image prompt",
        "properties": {
          "detail": {
            "description": "Specifies the detail level of the image.",
            "type": ["string", "null"]
          },
          "url": {
            "description": "URL of the image.",
            "type": "string"
          }
        },
        "required": ["url"],
        "type": "object"
      },
      "IncompleteDetails": {
        "description": "Details about why a response is incomplete.",
        "properties": {
          "reason": {
            "description": "The reason why the response is incomplete.",
            "type": "string"
          }
        },
        "required": ["reason"],
        "type": "object"
      },
      "InputTokensDetails": {
        "properties": {
          "cached_tokens": {
            "description": "Token cached by xAI from previous requests and reused for this request.",
            "format": "int32",
            "type": "integer"
          }
        },
        "required": ["cached_tokens"],
        "type": "object"
      },
      "LanguageModel": {
        "description": "Details of a language model",
        "properties": {
          "aliases": {
            "description": "Alias ID(s) of the model that user can use in a request's model field.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "cached_prompt_text_token_price": {
            "description": "Price of a prompt text token (in USD cents per 100 million tokens) that was cached previously.",
            "format": "int64",
            "type": "integer"
          },
          "completion_text_token_price": {
            "description": "Price of the completion text token in USD cents per 100 million token.",
            "format": "int64",
            "type": "integer"
          },
          "created": {
            "description": "Creation time of the model in Unix timestamp.",
            "format": "int64",
            "type": "integer"
          },
          "fingerprint": {
            "description": "Fingerprint of the xAI system configuration hosting the model.",
            "type": "string"
          },
          "id": {
            "description": "Model ID. Obtainable from <https://console.x.ai/team/default/models> or <https://docs.x.ai/docs/models>.",
            "type": "string"
          },
          "input_modalities": {
            "description": "The input modalities supported by the model, e.g. `\"text\"`, `\"image\"`.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "object": {
            "description": "The object type, which is always `\"model\"`.",
            "type": "string"
          },
          "output_modalities": {
            "description": "The output modalities supported by the model, e.g. `\"text\"`, `\"image\"`.",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "owned_by": {
            "description": "Owner of the model.",
            "type": "string"
          },
          "prompt_image_token_price": {
            "description": "Price of the prompt image token in USD cents per 100 million token.",
            "format": "int64",
            "type": "integer"
          },
          "prompt_text_token_price": {
            "description": "Price of the prompt text token in USD cents per 100 million token.",
            "format": "int64",
            "type": "integer"
          },
          "search_price": {
            "description": "Price of the search in USD cents per 100 million searches.",
            "format": "int64",
            "type": "integer"
          },
          "version": {
            "description": "Version of the model.",
            "type": "string"
          }
        },
        "required": [
          "id",
          "fingerprint",
          "created",
          "object",
          "owned_by",
          "version",
          "input_modalities",
          "output_modalities",
          "prompt_text_token_price",
          "cached_prompt_text_token_price",
          "prompt_image_token_price",
          "completion_text_token_price",
          "search_price",
          "aliases"
        ],
        "type": "object"
      },
      "ListEmbeddingModelsResponse": {
        "properties": {
          "models": {
            "description": "Array of available embedding models.",
            "items": {
              "$ref": "#/components/schemas/EmbeddingModel"
            },
            "type": "array"
          }
        },
        "required": ["models"],
        "type": "object"
      },
      "ListImageGenerationModelsResponse": {
        "properties": {
          "models": {
            "description": "Array of available image generation models.",
            "items": {
              "$ref": "#/components/schemas/ImageGenerationModel"
            },
            "type": "array"
          }
        },
        "required": ["models"],
        "type": "object"
      },
      "ListLanguageModelsResponse": {
        "properties": {
          "models": {
            "description": "Array of available language models.",
            "items": {
              "$ref": "#/components/schemas/LanguageModel"
            },
            "type": "array"
          }
        },
        "required": ["models"],
        "type": "object"
      },
      "ListModelsResponse": {
        "properties": {
          "data": {
            "description": "A list of models with with minimalized information.",
            "items": {
              "$ref": "#/components/schemas/Model"
            },
            "type": "array"
          },
          "object": {
            "description": "The object type of `data` field, which is always `\"list\"`.",
            "type": "string"
          }
        },
        "required": ["data", "object"],
        "type": "object"
      },
      "LogProbs": {
        "properties": {
          "content": {
            "description": "An array the log probabilities of each output token returned.",
            "items": {
              "$ref": "#/components/schemas/TokenLogProb"
            },
            "type": ["array", "null"]
          }
        },
        "type": "object"
      },
      "Message": {
        "description": "Chat message objects.",
        "oneOf": [
          {
            "description": "System message, usually instructions for the model to respond in a certain way.",
            "properties": {
              "content": {
                "$ref": "#/components/schemas/Content",
                "description": "System prompt content."
              },
              "name": {
                "description": "A unique identifier representing your end-user, which can help xAI to monitor and detect abuse.",
                "type": ["string", "null"]
              },
              "role": {
                "enum": ["system"],
                "type": "string"
              }
            },
            "required": ["content", "role"],
            "type": "object"
          },
          {
            "description": "User message, typically request from user for the model to answer.",
            "properties": {
              "content": {
                "$ref": "#/components/schemas/Content",
                "description": "System prompt content."
              },
              "name": {
                "description": "A unique identifier representing your end-user, which can help xAI to monitor and detect abuse.",
                "type": ["string", "null"]
              },
              "role": {
                "enum": ["user"],
                "type": "string"
              }
            },
            "required": ["content", "role"],
            "type": "object"
          },
          {
            "description": "Assistant role message, previous chat messages from the model.",
            "properties": {
              "content": {
                "oneOf": [
                  {
                    "type": "null"
                  },
                  {
                    "$ref": "#/components/schemas/Content",
                    "description": "Assistant prompt content."
                  }
                ]
              },
              "name": {
                "description": "A unique identifier representing your end-user, which can help xAI to monitor and detect abuse.",
                "type": ["string", "null"]
              },
              "reasoning_content": {
                "description": "Assistant reasoning content.",
                "type": ["string", "null"]
              },
              "role": {
                "enum": ["assistant"],
                "type": "string"
              },
              "tool_calls": {
                "description": "An array of tool calls available to the model on your machine.",
                "items": {
                  "$ref": "#/components/schemas/ToolCall"
                },
                "type": ["array", "null"]
              }
            },
            "required": ["role"],
            "type": "object"
          },
          {
            "description": "Tool call role message, used to return function call result to the model.",
            "properties": {
              "content": {
                "$ref": "#/components/schemas/Content",
                "description": "Content of the tool call result."
              },
              "role": {
                "enum": ["tool"],
                "type": "string"
              },
              "tool_call_id": {
                "description": "The ID of the tool call received from assistant message response.",
                "type": ["string", "null"]
              }
            },
            "required": ["content", "role"],
            "type": "object"
          },
          {
            "description": "Function call role message. Deprecated in favor of `{\"role\": \"tool\"}`.",
            "properties": {
              "content": {
                "$ref": "#/components/schemas/Content",
                "description": "Content of the tool call result."
              },
              "name": {
                "description": "A unique identifier representing your end-user, which can help xAI to monitor and detect abuse.",
                "type": ["string", "null"]
              },
              "role": {
                "enum": ["function"],
                "type": "string"
              }
            },
            "required": ["content", "role"],
            "type": "object"
          }
        ]
      },
      "MessageBody": {
        "description": "Anthropic compatible message body",
        "properties": {
          "content": {
            "$ref": "#/components/schemas/MessageContent",
            "description": "The content message."
          },
          "role": {
            "description": "The role that the message belongs to, `\"system\"` for system prompt, `\"user\"` for user prompt, and `\"assistant\"` for response from the model.",
            "type": "string"
          }
        },
        "required": ["role", "content"],
        "type": "object"
      },
      "MessageContent": {
        "oneOf": [
          {
            "description": "Text prompt.",
            "type": "string"
          },
          {
            "description": "An array of message content parts.",
            "items": {
              "$ref": "#/components/schemas/MessageContentPart"
            },
            "type": "array"
          }
        ]
      },
      "MessageContentPart": {
        "oneOf": [
          {
            "description": "Text prompt message content part.",
            "properties": {
              "cache_control": {
                "description": "(Unsupported) Cache control."
              },
              "text": {
                "description": "Text prompt.",
                "type": "string"
              },
              "type": {
                "enum": ["text"],
                "type": "string"
              }
            },
            "required": ["text", "type"],
            "type": "object"
          },
          {
            "description": "Image prompt message content part.",
            "properties": {
              "cache_control": {
                "description": "(Unsupported) Cache control."
              },
              "source": {
                "$ref": "#/components/schemas/MessageImageContent",
                "description": "Image source."
              },
              "type": {
                "enum": ["image"],
                "type": "string"
              }
            },
            "required": ["source", "type"],
            "type": "object"
          },
          {
            "description": "Tool call message content part. Received from model.",
            "properties": {
              "cache_control": {
                "description": "(Unsupported) Cache control."
              },
              "id": {
                "description": "ID of the tool call.",
                "type": "string"
              },
              "input": {
                "description": "Input for tool call."
              },
              "name": {
                "description": "Name of the tool call.",
                "type": "string"
              },
              "type": {
                "enum": ["tool_use"],
                "type": "string"
              }
            },
            "required": ["id", "name", "input", "type"],
            "type": "object"
          },
          {
            "description": "Tool call result.",
            "properties": {
              "cache_control": {
                "description": "(Unsupported) Cache control."
              },
              "content": {
                "description": "Result content of the tool call.",
                "type": "string"
              },
              "is_error": {
                "description": "Whether the tool call returns an error.",
                "type": ["boolean", "null"]
              },
              "tool_use_id": {
                "description": "ID of the tool call given by the model.",
                "type": "string"
              },
              "type": {
                "enum": ["tool_result"],
                "type": "string"
              }
            },
            "required": ["tool_use_id", "content", "type"],
            "type": "object"
          },
          {
            "description": "(Redacted) Thinking of the model.",
            "properties": {
              "data": {
                "description": "Encrypted data of the redacted thinking.",
                "type": "string"
              },
              "type": {
                "enum": ["redacted_thinking"],
                "type": "string"
              }
            },
            "required": ["data", "type"],
            "type": "object"
          },
          {
            "description": "Thinking of the model.",
            "properties": {
              "thinking": {
                "description": "Thinking.",
                "type": "string"
              },
              "type": {
                "enum": ["thinking"],
                "type": "string"
              }
            },
            "required": ["thinking", "type"],
            "type": "object"
          }
        ]
      },
      "MessageImageContent": {
        "oneOf": [
          {
            "properties": {
              "data": {
                "description": "Base64 encoded image string.",
                "type": "string"
              },
              "media_type": {
                "description": "Media type of the image source. Available options: `image/jpeg`, `image/png`, `image/webp`.",
                "type": "string"
              },
              "type": {
                "enum": ["base64"],
                "type": "string"
              }
            },
            "required": ["media_type", "data", "type"],
            "type": "object"
          },
          {
            "properties": {
              "type": {
                "enum": ["url"],
                "type": "string"
              },
              "url": {
                "description": "URL of the image.",
                "type": "string"
              }
            },
            "required": ["url", "type"],
            "type": "object"
          }
        ]
      },
      "MessageMetadata": {
        "properties": {
          "user_id": {
            "description": "A unique identifier representing your end-user, which can help xAI to monitor and detect abuse.",
            "type": ["string", "null"]
          }
        },
        "type": "object"
      },
      "MessageRequest": {
        "description": "Request message for `/v1/messages`",
        "properties": {
          "max_tokens": {
            "description": "The maximum number of tokens to generate before stopping. The model may stop before the max_tokens when it reaches the stop sequence.",
            "format": "int32",
            "type": "integer"
          },
          "messages": {
            "description": "Input messages.",
            "items": {
              "$ref": "#/components/schemas/MessageBody"
            },
            "type": "array"
          },
          "metadata": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/MessageMetadata",
                "description": "An object describing metadata about the request."
              }
            ]
          },
          "model": {
            "description": "Model name for the model to use.",
            "example": "grok-4-0709",
            "type": "string"
          },
          "stop_sequences": {
            "description": "(Not supported by reasoning models) Up to 4 sequences where the API will stop generating further tokens.",
            "items": {
              "type": "string"
            },
            "type": ["array", "null"]
          },
          "stream": {
            "description": "If set, partial message deltas will be sent. Tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a `data: [DONE]` message.",
            "type": ["boolean", "null"]
          },
          "system": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/SystemMessageContent",
                "description": "System prompt message for the model, defining how the model should behave to user messages."
              }
            ]
          },
          "temperature": {
            "default": 1,
            "description": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. It may not work well with reasoning models.",
            "format": "float",
            "maximum": 2,
            "minimum": 0,
            "type": ["number", "null"]
          },
          "tool_choice": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/MessageToolChoice",
                "description": "Controls which (if any) tool is called by the model. `\"none\"` means the model will not call any tool and instead generates a message. `\"auto\"` means the model can pick between generating a message or calling one or more tools. `\"any\"` means the model must call one or more tools. Specifying a particular tool via `{\"type\": \"tool\", \"function\": {\"name\": \"get_weather\"}}` forces the model to call that tool. `\"none\"` is the default when no tools are provided. `\"auto\"` is the default if tools are provided."
              }
            ]
          },
          "tools": {
            "description": "A list of tools the model may call in JSON-schema. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.",
            "items": {
              "$ref": "#/components/schemas/MessageTools"
            },
            "type": ["array", "null"]
          },
          "top_k": {
            "description": "(Unsupported) When generating next tokens, randomly selecting the next token from the k most likely options.",
            "format": "int32",
            "type": ["integer", "null"]
          },
          "top_p": {
            "default": 1,
            "description": "An alternative to sampling with `temperature`, called nucleus sampling, where the model considers the results of the tokens with `top_p` probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. It is generally recommended to alter this or `temperature` but not both.",
            "exclusiveMinimum": 0,
            "format": "float",
            "maximum": 1,
            "type": ["number", "null"]
          }
        },
        "type": "object"
      },
      "MessageResponse": {
        "description": "Response message for `/v1/messages`",
        "properties": {
          "content": {
            "description": "Response message content.",
            "items": {
              "$ref": "#/components/schemas/MessageResponseContent"
            },
            "type": "array"
          },
          "id": {
            "description": "Unique object identifier.",
            "type": "string"
          },
          "model": {
            "description": "Model name that handled the request.",
            "example": "grok-4-0709",
            "type": "string"
          },
          "role": {
            "description": "Role of the generated message. Always `\"assistant\"`",
            "type": "string"
          },
          "stop_reason": {
            "description": "Reason to stop. `\"stop_sequence\"` means the inference has reached a model-defined or user-supplied stop sequence in `stop`. `\"max_tokens\"` means the inference result has reached models' maximum allowed token length or user defined value in `max_tokens`. `\"end_turn\"` or `null` in streaming mode when the chunk is not the last. `\"tool_use\"` means the model has called a tool and is waiting for the tool response.",
            "type": ["string", "null"]
          },
          "stop_sequence": {
            "description": "Custom stop sequence used to stop the generation.",
            "type": ["string", "null"]
          },
          "type": {
            "description": "Object type. This is always `\"message\"` for message types.",
            "example": "message",
            "type": "string"
          },
          "usage": {
            "$ref": "#/components/schemas/MessageUsage",
            "description": "Token usage information."
          }
        },
        "required": ["id", "type", "role", "content", "model", "usage"],
        "type": "object"
      },
      "MessageResponseContent": {
        "oneOf": [
          {
            "description": "Text response from the model.",
            "properties": {
              "text": {
                "type": "string"
              },
              "type": {
                "enum": ["text"],
                "type": "string"
              }
            },
            "required": ["text", "type"],
            "type": "object"
          },
          {
            "description": "Thinking response for the model",
            "properties": {
              "signature": {
                "description": "Signature of the content",
                "type": "string"
              },
              "thinking": {
                "description": "Thinking content",
                "type": "string"
              },
              "type": {
                "enum": ["thinking"],
                "type": "string"
              }
            },
            "required": ["signature", "thinking", "type"],
            "type": "object"
          },
          {
            "description": "Redacted thinking response for the model",
            "properties": {
              "data": {
                "description": "Signature of the content",
                "type": "string"
              },
              "type": {
                "enum": ["redacted_thinking"],
                "type": "string"
              }
            },
            "required": ["data", "type"],
            "type": "object"
          },
          {
            "description": "Request by the model to invoke a tool call.",
            "properties": {
              "id": {
                "description": "Tool call ID.",
                "type": "string"
              },
              "input": {
                "description": "Input to the tool call follwing the `input_schema`."
              },
              "name": {
                "description": "Name of the tool call to be used.",
                "type": "string"
              },
              "type": {
                "enum": ["tool_use"],
                "type": "string"
              }
            },
            "required": ["id", "name", "input", "type"],
            "type": "object"
          }
        ]
      },
      "MessageToolChoice": {
        "description": "Tool choice option.",
        "oneOf": [
          {
            "description": "Allows the model to automatically decide whether to call the tool",
            "properties": {
              "type": {
                "enum": ["auto"],
                "type": "string"
              }
            },
            "required": ["type"],
            "type": "object"
          },
          {
            "description": "Forces the model to use at least one tool, without specifying the tool.",
            "properties": {
              "type": {
                "enum": ["any"],
                "type": "string"
              }
            },
            "required": ["type"],
            "type": "object"
          },
          {
            "description": "Forces the model to use the named tool",
            "properties": {
              "name": {
                "description": "Name of the tool to use.",
                "type": "string"
              },
              "type": {
                "enum": ["tool"],
                "type": "string"
              }
            },
            "required": ["name", "type"],
            "type": "object"
          }
        ]
      },
      "MessageToolInputSchema": {
        "properties": {
          "properties": {
            "description": "JSON-object of the tool input schema."
          },
          "required": {
            "description": "Required properties of the tool input schema, if any.",
            "items": {
              "type": "string"
            },
            "type": ["array", "null"]
          },
          "type": {
            "description": "Type of the schema. This is always `\"object\"`.",
            "type": "string"
          }
        },
        "required": ["type", "properties"],
        "type": "object"
      },
      "MessageTools": {
        "properties": {
          "cache_control": {
            "description": "(Unsupported) Cache control."
          },
          "description": {
            "description": "Description of the tool.",
            "type": "string"
          },
          "input_schema": {
            "$ref": "#/components/schemas/MessageToolInputSchema",
            "description": "Input schema allowed by the tool."
          },
          "name": {
            "description": "Name of the tool.",
            "type": "string"
          }
        },
        "required": ["name", "description", "input_schema"],
        "type": "object"
      },
      "MessageUsage": {
        "properties": {
          "cache_creation_input_tokens": {
            "description": "(Unsupported) Number of tokens written to the cache when creating a new entry.",
            "format": "int32",
            "type": "integer"
          },
          "cache_read_input_tokens": {
            "description": "Number of tokens retrieved from the cache for this request.",
            "format": "int32",
            "type": "integer"
          },
          "input_tokens": {
            "description": "Number of input tokens used",
            "format": "int32",
            "type": "integer"
          },
          "output_tokens": {
            "description": "Number of output tokens used",
            "format": "int32",
            "type": "integer"
          }
        },
        "required": [
          "input_tokens",
          "cache_creation_input_tokens",
          "cache_read_input_tokens",
          "output_tokens"
        ],
        "type": "object"
      },
      "Model": {
        "description": "Same as `LanguageModel` but fully compliant with the OpenAI API.",
        "properties": {
          "created": {
            "description": "Model creation time in Unix timestamp.",
            "format": "int64",
            "type": "integer"
          },
          "id": {
            "description": "Model ID. Obtainable from <https://console.x.ai/team/default/models> or <https://docs.x.ai/docs/models>.",
            "type": "string"
          },
          "object": {
            "description": "The object type, which is always `\"model\"`.",
            "type": "string"
          },
          "owned_by": {
            "description": "Owner of the model.",
            "type": "string"
          }
        },
        "required": ["id", "created", "object", "owned_by"],
        "type": "object"
      },
      "ModelInput": {
        "description": "Content of the input passed to a `/v1/response` request.",
        "oneOf": [
          {
            "description": "Text input.",
            "type": "string"
          },
          {
            "description": "A list of input items to the model. Can be of different types.",
            "items": {
              "$ref": "#/components/schemas/ModelInputPart"
            },
            "type": "array"
          }
        ]
      },
      "ModelInputContent": {
        "oneOf": [
          {
            "description": "Text input.",
            "type": "string"
          },
          {
            "description": "A list of input items to the model. Can include text and images.",
            "items": {
              "$ref": "#/components/schemas/ModelInputContentItem"
            },
            "type": "array"
          }
        ]
      },
      "ModelInputContentItem": {
        "oneOf": [
          {
            "description": "Text input.",
            "properties": {
              "text": {
                "description": "Text input.",
                "type": "string"
              },
              "type": {
                "enum": ["input_text"],
                "type": "string"
              }
            },
            "required": ["text", "type"],
            "type": "object"
          },
          {
            "description": "Image input. Note: Storing and fetching images is not fully supported at the moment.",
            "properties": {
              "detail": {
                "description": "Specifies the detail level of the image. One of `high`, `low` or `auto`. Defaults to `auto`.",
                "type": ["string", "null"]
              },
              "file_id": {
                "description": "Only included for compatibility.",
                "type": ["string", "null"]
              },
              "image_url": {
                "description": "A public URL of image prompt, only available for vision models.",
                "type": "string"
              },
              "type": {
                "enum": ["input_image"],
                "type": "string"
              }
            },
            "required": ["image_url", "type"],
            "type": "object"
          }
        ]
      },
      "ModelInputItem": {
        "oneOf": [
          {
            "allOf": [
              {
                "$ref": "#/components/schemas/ModelOutput"
              }
            ]
          },
          {
            "allOf": [
              {
                "$ref": "#/components/schemas/FunctionToolCallOutput"
              }
            ]
          }
        ]
      },
      "ModelInputPart": {
        "oneOf": [
          {
            "description": "Message input to the model.",
            "properties": {
              "content": {
                "$ref": "#/components/schemas/ModelInputContent",
                "description": "Text, image or audio input."
              },
              "name": {
                "description": "A unique identifier representing your end-user, which can help xAI to monitor and detect abuse. Only supported for `user` messages.",
                "type": ["string", "null"]
              },
              "role": {
                "description": "The role of the message. Possible values are `user`, `assistant`, `system` and `developer`.",
                "type": "string"
              },
              "type": {
                "description": "The type of the message, which is always `message`.",
                "type": ["string", "null"]
              }
            },
            "required": ["content", "role"],
            "type": "object"
          },
          {
            "allOf": [
              {
                "$ref": "#/components/schemas/ModelInputItem"
              }
            ],
            "description": "Previous responses of the model and tool call outputs."
          }
        ]
      },
      "ModelOutput": {
        "oneOf": [
          {
            "allOf": [
              {
                "$ref": "#/components/schemas/OutputMessage"
              }
            ]
          },
          {
            "allOf": [
              {
                "$ref": "#/components/schemas/FunctionToolCall"
              }
            ]
          },
          {
            "allOf": [
              {
                "$ref": "#/components/schemas/Reasoning"
              }
            ]
          }
        ]
      },
      "ModelRequest": {
        "description": "The request body for `/v1/responses` endpoint.",
        "properties": {
          "background": {
            "default": false,
            "description": "(Unsupported) Whether to process the response asynchronously in the background.",
            "type": ["boolean", "null"]
          },
          "include": {
            "description": "What additional output data to include in the response. Currently the only supported value is `reasoning.encrypted_content` which returns an encrypted version of the reasoning tokens.",
            "items": {
              "type": "string"
            },
            "type": ["array", "null"]
          },
          "input": {
            "$ref": "#/components/schemas/ModelInput",
            "description": "The input passed to the model. Can be text, image or file."
          },
          "instructions": {
            "description": "An alternate way to specify the system prompt. Note that this cannot be used alongside `previous_response_id`, where the system prompt of the previous message will be used.",
            "type": ["string", "null"]
          },
          "logprobs": {
            "default": false,
            "description": "Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the content of message.",
            "type": ["boolean", "null"]
          },
          "max_output_tokens": {
            "description": "Max number of tokens that can be generated in a response. This includes both output and reasoning tokens.",
            "format": "int32",
            "type": ["integer", "null"]
          },
          "metadata": {
            "description": "Not supported. Only maintained for compatibility reasons."
          },
          "model": {
            "description": "Model name for the model to use. Obtainable from <https://console.x.ai/team/default/models> or <https://docs.x.ai/docs/models>.",
            "example": "grok-4-0709",
            "type": "string"
          },
          "parallel_tool_calls": {
            "default": true,
            "description": "Whether to allow the model to run parallel tool calls.",
            "type": ["boolean", "null"]
          },
          "previous_response_id": {
            "description": "The ID of the previous response from the model.",
            "type": ["string", "null"]
          },
          "reasoning": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/ReasoningConfiguration",
                "description": "Reasoning configuration. Only for reasoning models."
              }
            ]
          },
          "search_parameters": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/SearchParameters",
                "description": "Set the parameters to be used for searched data. Takes precedence over `web_search_preview` tool if specified in the tools."
              }
            ]
          },
          "service_tier": {
            "description": "Not supported. Only maintained for compatibility reasons.",
            "type": ["string", "null"]
          },
          "store": {
            "default": true,
            "description": "Whether to store the input message(s) and model response for later retrieval.",
            "type": ["boolean", "null"]
          },
          "stream": {
            "default": false,
            "description": "If set, partial message deltas will be sent. Tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a `data: [DONE]` message.",
            "example": true,
            "type": ["boolean", "null"]
          },
          "temperature": {
            "default": 1,
            "description": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.",
            "example": 0.2,
            "format": "float",
            "maximum": 2,
            "minimum": 0,
            "type": ["number", "null"]
          },
          "text": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/ModelResponseConfiguration",
                "description": "Settings for customizing a text response from the model."
              }
            ]
          },
          "tool_choice": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/ToolChoice",
                "description": "Controls which (if any) tool is called by the model. `none` means the model will not call any tool and instead generates a message. auto means the model can pick between generating a message or calling one or more tools. required means the model must call one or more tools. Specifying a particular tool via `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to call that tool. `none` is the default when no tools are present. `auto` is the default if tools are present."
              }
            ]
          },
          "tools": {
            "description": "A list of tools the model may call in JSON-schema. Currently, only functions and web search are supported as tools. A max of 128 tools are supported.`web_search_preview` tool, if specified, will be overridden by `search_parameters`.",
            "items": {
              "$ref": "#/components/schemas/ModelTool"
            },
            "maxItems": 128,
            "type": ["array", "null"]
          },
          "top_logprobs": {
            "description": "An integer between 0 and 8 specifying the number of most likely tokens to return at each token position, each with an associated log probability. logprobs must be set to true if this parameter is used.",
            "format": "int32",
            "maximum": 8,
            "minimum": 0,
            "type": ["integer", "null"]
          },
          "top_p": {
            "default": 1,
            "description": "An alternative to sampling with `temperature`, called nucleus sampling, where the model considers the results of the tokens with `top_p` probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. It is generally recommended to alter this or `temperature` but not both.",
            "exclusiveMinimum": 0,
            "format": "float",
            "maximum": 1,
            "type": ["number", "null"]
          },
          "truncation": {
            "description": "Not supported. Only maintained for compatibility reasons.",
            "type": ["string", "null"]
          },
          "user": {
            "description": "A unique identifier representing your end-user, which can help xAI to monitor and detect abuse.",
            "type": ["string", "null"]
          }
        },
        "required": ["input"],
        "type": "object"
      },
      "ModelResponse": {
        "description": "The response body for `/v1/responses` endpoint.",
        "properties": {
          "background": {
            "default": false,
            "description": "Whether to process the response asynchronously in the background.",
            "type": ["boolean", "null"]
          },
          "created_at": {
            "description": "The Unix timestamp (in seconds) for the response creation time.",
            "format": "int64",
            "type": "integer"
          },
          "debug_output": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/DebugOutput",
                "description": "Debug output. Only available to trusted testers."
              }
            ]
          },
          "id": {
            "description": "Unique ID of the response.",
            "type": "string"
          },
          "incomplete_details": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/IncompleteDetails",
                "description": "Details about why the response is incomplete."
              }
            ]
          },
          "max_output_tokens": {
            "description": "Max number of tokens that can be generated in a response. This includes both output and reasoning tokens.",
            "format": "int32",
            "type": ["integer", "null"]
          },
          "metadata": {
            "description": "Only included for compatibility."
          },
          "model": {
            "description": "Model name used to generate the response.",
            "type": "string"
          },
          "object": {
            "description": "The object type of this resource. Always set to `response`.",
            "type": "string"
          },
          "output": {
            "description": "The response generated by the model.",
            "items": {
              "$ref": "#/components/schemas/ModelOutput"
            },
            "type": "array"
          },
          "parallel_tool_calls": {
            "description": "Whether to allow the model to run parallel tool calls.",
            "type": "boolean"
          },
          "previous_response_id": {
            "description": "The ID of the previous response from the model.",
            "type": ["string", "null"]
          },
          "reasoning": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/ReasoningConfiguration",
                "description": "Reasoning configuration. Only for reasoning models."
              }
            ]
          },
          "status": {
            "description": "Status of the response. One of `completed`, `in_progress` or `incomplete`.",
            "type": "string"
          },
          "store": {
            "default": true,
            "description": "Whether to store the input message(s) and model response for later retrieval.",
            "type": "boolean"
          },
          "temperature": {
            "default": 1,
            "description": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.",
            "format": "float",
            "maximum": 2,
            "minimum": 0,
            "type": ["number", "null"]
          },
          "text": {
            "$ref": "#/components/schemas/ModelResponseConfiguration",
            "description": "Settings for customizing a text response from the model."
          },
          "tool_choice": {
            "$ref": "#/components/schemas/ToolChoice",
            "description": "Controls which (if any) tool is called by the model. auto means the model can pick between generating a message or calling one or more tools. required means the model must call one or more tools. Specifying a particular tool via `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to call that tool. `none` is the default when no tools are present. `auto` is the default if tools are present."
          },
          "tools": {
            "description": "A list of tools the model may call in JSON-schema. Currently, only functions and web search are supported as tools. A max of 128 tools are supported.",
            "items": {
              "$ref": "#/components/schemas/ModelTool"
            },
            "maxItems": 128,
            "type": "array"
          },
          "top_p": {
            "default": 1,
            "description": "An alternative to sampling with `temperature`, called nucleus sampling, where the model considers the results of the tokens with `top_p` probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. It is generally recommended to alter this or `temperature` but not both.",
            "exclusiveMinimum": 0,
            "format": "float",
            "maximum": 1,
            "type": ["number", "null"]
          },
          "usage": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/ModelUsage",
                "description": "Token usage information."
              }
            ]
          },
          "user": {
            "description": "A unique identifier representing your end-user, which can help xAI to monitor and detect abuse.",
            "type": ["string", "null"]
          }
        },
        "required": [
          "created_at",
          "id",
          "model",
          "object",
          "output",
          "parallel_tool_calls",
          "text",
          "tool_choice",
          "tools",
          "status",
          "store",
          "metadata"
        ],
        "type": "object"
      },
      "ModelResponseConfiguration": {
        "properties": {
          "format": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/ModelResponseFormat",
                "description": "An object specifying the format that the model must output. Specify `{ \"type\": \"json_object\" }` for JSON output, or `{ \"type\": \"json_schema\", \"json_schema\": {...} }` for structured outputs. If `{ \\\"type\\\": \\\"text\\\" }`, the model will return a text response."
              }
            ]
          }
        },
        "type": "object"
      },
      "ModelResponseFormat": {
        "description": "Response format parameter for structured outputs.",
        "oneOf": [
          {
            "description": "Specify text response format, always `\"text\"`.",
            "properties": {
              "type": {
                "enum": ["text"],
                "type": "string"
              }
            },
            "required": ["type"],
            "type": "object"
          },
          {
            "description": "Specify json_object response format, always `json_object`. Used for backward compatibility. Prefer to use `\"json_schema\"` instead of this.",
            "properties": {
              "type": {
                "enum": ["json_object"],
                "type": "string"
              }
            },
            "required": ["type"],
            "type": "object"
          },
          {
            "description": "Specify json_schema response format with a given schema. Type is always `\"json_schema\"`.",
            "properties": {
              "description": {
                "description": "Only included for compatibility.",
                "type": ["string", "null"]
              },
              "name": {
                "description": "Only included for compatibility.",
                "type": ["string", "null"]
              },
              "schema": {
                "description": "A json schema representing the desired response schema."
              },
              "strict": {
                "description": "Only included for compatibility.",
                "type": ["boolean", "null"]
              },
              "type": {
                "enum": ["json_schema"],
                "type": "string"
              }
            },
            "required": ["schema", "type"],
            "type": "object"
          }
        ]
      },
      "ModelTool": {
        "description": "Definition of one tool that the model can call.",
        "oneOf": [
          {
            "allOf": [
              {
                "$ref": "#/components/schemas/FunctionDefinition"
              },
              {
                "description": "A function that the model can call.",
                "properties": {
                  "type": {
                    "enum": ["function"],
                    "type": "string"
                  }
                },
                "required": ["type"],
                "type": "object"
              }
            ],
            "description": "A function that the model can call."
          },
          {
            "allOf": [
              {
                "$ref": "#/components/schemas/WebSearchOptions"
              },
              {
                "properties": {
                  "allowed_domains": {
                    "description": "List of website domains to allow in the search results. This parameter act as a whitelist\nwhere only those websites can be selected. A maximum of 5 websites can be selected.\n\nNote: This parameter cannot be set with `excluded_domains`.",
                    "example": ["wikipedia.com"],
                    "items": {
                      "type": "string"
                    },
                    "maxItems": 5,
                    "type": ["array", "null"]
                  },
                  "enable_image_understanding": {
                    "description": "Enable image understanding during web search.",
                    "type": ["boolean", "null"]
                  },
                  "excluded_domains": {
                    "description": "List of website domains to exclude from the search results without protocol specification or\nsubdomains. A maximum of 5 websites can be excluded.\n\nNote: This parameter cannot be set with `allowed_domains`",
                    "example": ["wikipedia.com"],
                    "items": {
                      "type": "string"
                    },
                    "maxItems": 5,
                    "type": ["array", "null"]
                  }
                },
                "type": "object"
              },
              {
                "description": "Search the web.",
                "properties": {
                  "type": {
                    "enum": ["web_search"],
                    "type": "string"
                  }
                },
                "required": ["type"],
                "type": "object"
              }
            ],
            "description": "Search the web."
          },
          {
            "description": "Search X.",
            "properties": {
              "allowed_x_handles": {
                "description": "List of X Handles of the users from whom to consider the posts.\n\nNote: This parameter cannot be set with `excluded_x_handles`.",
                "example": ["elonmusk"],
                "items": {
                  "type": "string"
                },
                "maxItems": 10,
                "type": ["array", "null"]
              },
              "enable_image_understanding": {
                "description": "Enable image understanding during X search.",
                "type": ["boolean", "null"]
              },
              "enable_video_understanding": {
                "description": "Enable video understanding during X search.",
                "type": ["boolean", "null"]
              },
              "excluded_x_handles": {
                "description": "List of X Handles of the users from whom to exclude the posts.\n\nNote: This parameter cannot be set with `allowed_x_handles`.",
                "example": ["elonmusk"],
                "items": {
                  "type": "string"
                },
                "maxItems": 10,
                "type": ["array", "null"]
              },
              "from_date": {
                "description": "Date from which to consider the results in ISO-8601 YYYY-MM-DD. See\n<https://en.wikipedia.org/wiki/ISO_8601>.",
                "example": "2024-06-24",
                "format": "date",
                "type": ["string", "null"]
              },
              "to_date": {
                "description": "Date up to which to consider the results in ISO-8601 YYYY-MM-DD. See\n<https://en.wikipedia.org/wiki/ISO_8601>.",
                "example": "2024-12-24",
                "format": "date",
                "type": ["string", "null"]
              },
              "type": {
                "enum": ["x_search"],
                "type": "string"
              }
            },
            "required": ["type"],
            "type": "object"
          },
          {
            "description": "Execute code.",
            "properties": {
              "type": {
                "enum": ["code_interpreter"],
                "type": "string"
              }
            },
            "required": ["type"],
            "type": "object"
          }
        ]
      },
      "ModelUsage": {
        "properties": {
          "input_tokens": {
            "description": "Number of input tokens used.",
            "format": "int32",
            "type": "integer"
          },
          "input_tokens_details": {
            "$ref": "#/components/schemas/InputTokensDetails",
            "description": "Breakdown of the input tokens."
          },
          "output_tokens": {
            "description": "Number of output tokens used.",
            "format": "int32",
            "type": "integer"
          },
          "output_tokens_details": {
            "$ref": "#/components/schemas/OutputTokensDetails",
            "description": "Breakdown of the output tokens."
          },
          "total_tokens": {
            "description": "Total tokens used.",
            "format": "int32",
            "type": "integer"
          }
        },
        "required": [
          "input_tokens",
          "input_tokens_details",
          "output_tokens",
          "output_tokens_details",
          "total_tokens"
        ],
        "type": "object"
      },
      "OutputMessage": {
        "description": "An output message from the model.",
        "properties": {
          "content": {
            "description": "Content of the output message.",
            "items": {
              "$ref": "#/components/schemas/OutputMessageContent"
            },
            "type": "array"
          },
          "id": {
            "description": "The unique ID of the output message.",
            "type": "string"
          },
          "role": {
            "description": "The role of the output message, which is always `assistant`.",
            "type": "string"
          },
          "status": {
            "description": "Status of the item. One of `completed`, `in_progress` or `incomplete`.",
            "type": "string"
          },
          "type": {
            "description": "The type of the output message, which is always `message`.",
            "type": "string"
          }
        },
        "required": ["content", "role", "type"],
        "type": "object"
      },
      "OutputMessageContent": {
        "oneOf": [
          {
            "description": "Text output.",
            "properties": {
              "annotations": {
                "description": "Citations.",
                "items": {
                  "$ref": "#/components/schemas/Annotation"
                },
                "type": "array"
              },
              "logprobs": {
                "oneOf": [
                  {
                    "type": "null"
                  },
                  {
                    "$ref": "#/components/schemas/LogProbs",
                    "description": "The log probabilities of each output token returned in the content of message."
                  }
                ]
              },
              "text": {
                "description": "The text output from the model.",
                "type": "string"
              },
              "type": {
                "enum": ["output_text"],
                "type": "string"
              }
            },
            "required": ["text", "annotations", "type"],
            "type": "object"
          },
          {
            "description": "Refusal.",
            "properties": {
              "refusal": {
                "description": "The reason for the refusal.",
                "type": "string"
              },
              "type": {
                "enum": ["refusal"],
                "type": "string"
              }
            },
            "required": ["refusal", "type"],
            "type": "object"
          }
        ]
      },
      "OutputTokensDetails": {
        "properties": {
          "reasoning_tokens": {
            "description": "Tokens generated by the model for reasoning.",
            "format": "int32",
            "type": "integer"
          }
        },
        "required": ["reasoning_tokens"],
        "type": "object"
      },
      "PromptUsageDetail": {
        "description": "Details of prompt usage.",
        "properties": {
          "audio_tokens": {
            "description": "Audio prompt token used.",
            "format": "int32",
            "type": "integer"
          },
          "cached_tokens": {
            "description": "Token cached by xAI from previous requests and reused for this request.",
            "format": "int32",
            "type": "integer"
          },
          "image_tokens": {
            "description": "Image prompt token used.",
            "format": "int32",
            "type": "integer"
          },
          "text_tokens": {
            "description": "Text prompt token used.",
            "format": "int32",
            "type": "integer"
          }
        },
        "required": [
          "text_tokens",
          "audio_tokens",
          "image_tokens",
          "cached_tokens"
        ],
        "type": "object"
      },
      "Reasoning": {
        "description": "The reasoning done by the model.",
        "properties": {
          "encrypted_content": {
            "description": "The enrypted reasoning. Returned when `reasoning.encrypted_content` is passed in `include`.",
            "type": ["string", "null"]
          },
          "id": {
            "description": "The unique ID of the reasoning content.",
            "type": "string"
          },
          "status": {
            "description": "Status of the item. One of `completed`, `in_progress` or `incomplete`.",
            "type": "string"
          },
          "summary": {
            "description": "The reasoning text contents.",
            "items": {
              "$ref": "#/components/schemas/ReasoningText"
            },
            "type": "array"
          },
          "type": {
            "description": "The type of the object, which is always `reasoning`.",
            "type": "string"
          }
        },
        "required": ["summary", "type"],
        "type": "object"
      },
      "ReasoningConfiguration": {
        "properties": {
          "effort": {
            "default": "medium",
            "description": "Constrains how hard a reasoning model thinks before responding. Possible values are `low` (uses fewer reasoning tokens), `medium` and `high` (uses more reasoning tokens).",
            "type": ["string", "null"]
          },
          "generate_summary": {
            "description": "Only included for compatibility.",
            "type": ["string", "null"]
          },
          "summary": {
            "description": "A summary of the model's reasoning process. Possible values are `auto`, `concise` and `detailed`. Only included for compatibility. The model shall always return `detailed`.",
            "type": ["string", "null"]
          }
        },
        "type": "object"
      },
      "ReasoningText": {
        "properties": {
          "text": {
            "description": "Reasoning done by the model.",
            "type": "string"
          },
          "type": {
            "description": "The type of the object, which is always `summary_text`.",
            "type": "string"
          }
        },
        "required": ["text", "type"],
        "type": "object"
      },
      "ResponseFormat": {
        "description": "Response format parameter for structured outputs.",
        "oneOf": [
          {
            "description": "Specify text response format, always `\"text\"`.",
            "properties": {
              "type": {
                "enum": ["text"],
                "type": "string"
              }
            },
            "required": ["type"],
            "type": "object"
          },
          {
            "description": "Specify json_object response format, always `json_object`. Used for backward compatibility. Prefer to use `\"json_schema\"` instead of this.",
            "properties": {
              "type": {
                "enum": ["json_object"],
                "type": "string"
              }
            },
            "required": ["type"],
            "type": "object"
          },
          {
            "description": "Specify json_schema response format with a given schema. Type is always `\"json_schema\"`.",
            "properties": {
              "json_schema": {
                "description": "A json schema representing the desired response schema. Includes the schema as a `\"schema\"` field."
              },
              "type": {
                "enum": ["json_schema"],
                "type": "string"
              }
            },
            "required": ["json_schema", "type"],
            "type": "object"
          }
        ]
      },
      "SampleChoice": {
        "properties": {
          "finish_reason": {
            "description": "Finish reason. `\"stop\"` means the inference has reached a model-defined or user-supplied stop sequence in `stop`. `\"length\"` means the inference result has reached models' maximum allowed token length or user defined value in `max_tokens`. `\"end_turn\"` or `null` in streaming mode when the chunk is not the last.",
            "type": "string"
          },
          "index": {
            "description": "Index of the choice.",
            "format": "int32",
            "type": "integer"
          },
          "text": {
            "description": "Text response.",
            "type": "string"
          }
        },
        "required": ["index", "text", "finish_reason"],
        "type": "object"
      },
      "SampleContent": {
        "oneOf": [
          {
            "description": "Text prompt.",
            "type": "string"
          },
          {
            "description": "An array of strings, a token list, or an array of token lists.",
            "items": {
              "type": "string"
            },
            "type": "array"
          }
        ]
      },
      "SampleRequest": {
        "description": "(Legacy) Request for `/v1/completions` endpoint",
        "properties": {
          "best_of": {
            "description": "(Unsupported) Generates multiple completions internally and returns the top-scoring one. Not functional yet.",
            "format": "int32",
            "type": ["integer", "null"]
          },
          "echo": {
            "description": "Option to include the original prompt in the response along with the generated completion.",
            "type": ["boolean", "null"]
          },
          "frequency_penalty": {
            "description": "(Unsupported) Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.",
            "format": "float",
            "type": ["number", "null"]
          },
          "logit_bias": {
            "additionalProperties": {
              "format": "float",
              "type": "number"
            },
            "description": "(Unsupported) Accepts a JSON object that maps tokens to an associated bias value from -100 to 100. You can use this tokenizer tool to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.",
            "propertyNames": {
              "format": "int32",
              "type": "integer"
            },
            "type": ["object", "null"]
          },
          "logprobs": {
            "description": "Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the logprob of the sampled token, so there may be up to `logprobs+1` elements in the response.",
            "type": ["boolean", "null"]
          },
          "max_tokens": {
            "description": "Limits the number of tokens that can be produced in the output. Ensure the sum of prompt tokens and `max_tokens` does not exceed the model's context limit.",
            "format": "int32",
            "type": ["integer", "null"]
          },
          "model": {
            "description": "Specifies the model to be used for the request.",
            "type": "string"
          },
          "n": {
            "description": "Determines how many completion sequences to produce for each prompt. Be cautious with its use due to high token consumption; adjust `max_tokens` and stop sequences accordingly.",
            "format": "int32",
            "type": ["integer", "null"]
          },
          "presence_penalty": {
            "description": "(Not supported by `grok-3` and reasoning models) Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.",
            "format": "float",
            "type": ["number", "null"]
          },
          "prompt": {
            "$ref": "#/components/schemas/SampleContent",
            "description": "Input for generating completions, which can be a string, list of strings, token list, or list of token lists. `<|endoftext|>` is used as a document separator, implying a new context start if omitted."
          },
          "seed": {
            "description": "If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend.",
            "format": "int32",
            "type": ["integer", "null"]
          },
          "stop": {
            "description": "(Not supported by reasoning models) Up to 4 sequences where the API will stop generating further tokens.",
            "items": {
              "type": "string"
            },
            "type": ["array", "null"]
          },
          "stream": {
            "description": "Whether to stream back partial progress. If set, tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a `data: [DONE]` message.",
            "type": ["boolean", "null"]
          },
          "stream_options": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/StreamOptions",
                "description": "Options for streaming response. Only set this when you set `stream: true`."
              }
            ]
          },
          "suffix": {
            "description": "(Unsupported) Optional string to append after the generated text.",
            "type": ["string", "null"]
          },
          "temperature": {
            "default": 1,
            "description": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both.",
            "example": 0.2,
            "format": "float",
            "maximum": 2,
            "minimum": 0,
            "type": ["number", "null"]
          },
          "top_p": {
            "description": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with `top_p` probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature but not both.",
            "format": "float",
            "type": ["number", "null"]
          },
          "user": {
            "description": "A unique identifier representing your end-user, which can help xAI to monitor and detect abuse.",
            "type": ["string", "null"]
          }
        },
        "type": "object"
      },
      "SampleResponse": {
        "description": "(Legacy) Response for `/v1/completions` endpoint",
        "properties": {
          "choices": {
            "description": "A list of response choices from the model. The length corresponds to the `n` in request body (default to 1).",
            "items": {
              "$ref": "#/components/schemas/SampleChoice"
            },
            "type": "array"
          },
          "created": {
            "description": "The chat completion creation time in Unix timestamp.",
            "format": "int64",
            "type": "integer"
          },
          "id": {
            "description": "ID of the request.",
            "type": "string"
          },
          "model": {
            "description": "Model to be used.",
            "example": "grok-4-0709",
            "type": "string"
          },
          "object": {
            "description": "Object type of the response. This is always `\"text_completion\"`.",
            "type": "string"
          },
          "system_fingerprint": {
            "description": "System fingerprint, used to indicate xAI system configuration changes.",
            "type": ["string", "null"]
          },
          "usage": {
            "oneOf": [
              {
                "type": "null"
              },
              {
                "$ref": "#/components/schemas/Usage",
                "description": "Token usage information."
              }
            ]
          }
        },
        "required": ["id", "object", "created", "model", "choices"],
        "type": "object"
      },
      "SearchMatch": {
        "description": "SearchMatch defines a single match from a search request.",
        "properties": {
          "chunk_content": {
            "description": "The chunk content.",
            "type": "string"
          },
          "chunk_id": {
            "description": "The chunk ID.",
            "type": "string"
          },
          "collection_ids": {
            "description": "The collection ID(s).",
            "items": {
              "type": "string"
            },
            "type": "array"
          },
          "file_id": {
            "description": "The document ID.",
            "type": "string"
          },
          "score": {
            "description": "The relevance score.",
            "format": "float",
            "type": "number"
          }
        },
        "required": [
          "file_id",
          "chunk_id",
          "chunk_content",
          "score",
          "collection_ids"
        ],
        "type": "object"
      },
      "SearchParameters": {
        "description": "Parameters to control realtime data.",
        "properties": {
          "from_date": {
            "description": "Date from which to consider the results in ISO-8601 YYYY-MM-DD. See\n<https://en.wikipedia.org/wiki/ISO_8601>.",
            "example": "2024-06-24",
            "format": "date",
            "type": ["string", "null"]
          },
          "max_search_results": {
            "default": 15,
            "description": "Maximum number of search results to use.",
            "format": "int32",
            "maximum": 30,
            "minimum": 1,
            "type": ["integer", "null"]
          },
          "mode": {
            "default": "auto",
            "description": "Choose the mode to query realtime data:\n* `off`: no search performed and no external will be considered.\n* `on` (default): the model will search in every sources for relevant data.\n* `auto`: the model choose whether to search data or not and where to search the data.",
            "example": "auto",
            "type": ["string", "null"]
          },
          "return_citations": {
            "default": true,
            "description": "Whether to return citations in the response or not.",
            "type": ["boolean", "null"]
          },
          "sources": {
            "description": "List of sources to search in. If no sources specified, the model will look over the web and X by default.",
            "items": {
              "$ref": "#/components/schemas/SearchSource"
            },
            "type": ["array", "null"]
          },
          "to_date": {
            "description": "Date up to which to consider the results in ISO-8601 YYYY-MM-DD. See\n<https://en.wikipedia.org/wiki/ISO_8601>.",
            "example": "2024-12-24",
            "format": "date",
            "type": ["string", "null"]
          }
        },
        "type": "object"
      },
      "SearchRequest": {
        "description": "SearchRequest defines the request to search for documents.",
        "properties": {
          "instructions": {
            "description": "User-defined instructions to be included in the search query. Defaults to generic search instructions.",
            "type": ["string", "null"]
          },
          "limit": {
            "description": "The number of chunks to return.\nWill always return the top matching chunks.\nOptional, defaults to 10",
            "format": "int32",
            "type": ["integer", "null"]
          },
          "query": {
            "description": "The query to search for which will be embedded using the\nsame embedding model as the one used for the source to query.",
            "type": "string"
          },
          "ranking_metric": {
            "description": "The ranking metric to use for the search ('RANKING_METRIC_COSINE_SIMILARITY', 'RANKING_METRIC_L2_DISTANCE').\nDefaults to `RANKING_METRIC_L2_DISTANCE`.",
            "type": ["string", "null"]
          },
          "source": {
            "$ref": "#/components/schemas/DocumentsSource",
            "description": "The source to query."
          }
        },
        "required": ["query", "source"],
        "type": "object"
      },
      "SearchResponse": {
        "description": "SearchResponse defines the response to a search request.",
        "properties": {
          "matches": {
            "description": "The search matches.",
            "items": {
              "$ref": "#/components/schemas/SearchMatch"
            },
            "type": "array"
          }
        },
        "required": ["matches"],
        "type": "object"
      },
      "SearchSource": {
        "oneOf": [
          {
            "properties": {
              "excluded_x_handles": {
                "description": "List of X handles to exclude from the search results. X posts returned will not include\nany posts authored by these handles.",
                "items": {
                  "type": "string"
                },
                "type": ["array", "null"]
              },
              "included_x_handles": {
                "description": " NOTE: `included_x_handles` and `x_handles` are the same parameter.\n`included_x_handles` is the new name but we keep both for backward compatibility.\n\nX Handles of the users from whom to consider the posts. Only available if mode is `auto`, `on` or `x`.",
                "items": {
                  "type": "string"
                },
                "type": ["array", "null"]
              },
              "post_favorite_count": {
                "description": "The minimum favorite count of the X posts to consider.",
                "format": "int32",
                "type": ["integer", "null"]
              },
              "post_view_count": {
                "description": "The minimum view count of the X posts to consider.",
                "format": "int32",
                "type": ["integer", "null"]
              },
              "type": {
                "enum": ["x"],
                "type": "string"
              },
              "x_handles": {
                "deprecated": true,
                "description": "DEPRECATED in favor of `included_x_handles`. Use `included_x_handles` instead.\nX Handles of the users from whom to consider the posts. Only available if mode is `auto`, `on` or `x`.",
                "items": {
                  "type": "string"
                },
                "type": ["array", "null"]
              }
            },
            "required": ["type"],
            "type": "object"
          },
          {
            "properties": {
              "allowed_websites": {
                "description": "List of website to allow in the search results. This parameter act as a whitelist\nwhere only those websites can be selected. A maximum of 5 websites can be selected.\n\nNote 1: If no relevant information is found on those websites, the number of results\nreturned might be smaller than `max_search_results`.\n\nNote 2: This parameter cannot be set with `excluded_websites`.",
                "example": ["wikipedia.com"],
                "items": {
                  "type": "string"
                },
                "maxItems": 5,
                "type": ["array", "null"]
              },
              "country": {
                "description": "ISO alpha-2 code of the country. If the country is set, only data coming from this country\nwill be considered. See <https://en.wikipedia.org/wiki/ISO_3166-2>.",
                "example": "BE",
                "format": "iso3166-1-alpha-2",
                "type": ["string", "null"]
              },
              "excluded_websites": {
                "description": "List of website to exclude from the search results without protocol specification or\nsubdomains. A maximum of 5 websites can be excluded.\n\nNote 2: This parameter cannot be set with `allowed_websites`",
                "example": ["wikipedia.com"],
                "items": {
                  "type": "string"
                },
                "maxItems": 5,
                "type": ["array", "null"]
              },
              "safe_search": {
                "description": "If set to true, mature content won't be considered during the search. Default to `true`.",
                "type": ["boolean", "null"]
              },
              "type": {
                "enum": ["web"],
                "type": "string"
              }
            },
            "required": ["type"],
            "type": "object"
          },
          {
            "properties": {
              "country": {
                "description": "ISO alpha-2 code of the country. If the country is set, only data coming from this country\nwill be considered. See <https://en.wikipedia.org/wiki/ISO_3166-2>.",
                "example": "BE",
                "format": "iso3166-1-alpha-2",
                "type": ["string", "null"]
              },
              "excluded_websites": {
                "description": "List of website to exclude from the search results without protocol specification or\nsubdomains. A maximum of 5 websites can be excluded.",
                "example": ["foxnews.com"],
                "items": {
                  "type": "string"
                },
                "maxItems": 5,
                "type": ["array", "null"]
              },
              "safe_search": {
                "description": "If set to true, mature content won't be considered during the search. Default to `true`.",
                "type": ["boolean", "null"]
              },
              "type": {
                "enum": ["news"],
                "type": "string"
              }
            },
            "required": ["type"],
            "type": "object"
          },
          {
            "properties": {
              "links": {
                "description": "Links of the RSS feeds.",
                "example": ["https://status.x.ai/feed.xml"],
                "items": {
                  "type": "string"
                },
                "maxItems": 1,
                "minItems": 1,
                "type": "array"
              },
              "type": {
                "enum": ["rss"],
                "type": "string"
              }
            },
            "required": ["links", "type"],
            "type": "object"
          }
        ]
      },
      "StartDeferredChatResponse": {
        "properties": {
          "request_id": {
            "description": "A unique request ID for the chat response.",
            "type": "string"
          }
        },
        "required": ["request_id"],
        "type": "object"
      },
      "StreamOptions": {
        "description": "Options available when using streaming response.",
        "properties": {
          "include_usage": {
            "description": "Set an additional chunk to be streamed before the `data: [DONE]` message. The other chunks will return `null` in `usage` field.",
            "type": "boolean"
          }
        },
        "required": ["include_usage"],
        "type": "object"
      },
      "SystemMessageContent": {
        "oneOf": [
          {
            "description": "Text content of system prompt.",
            "type": "string"
          },
          {
            "description": "An array of system prompt parts.",
            "items": {
              "$ref": "#/components/schemas/SystemMessagePart"
            },
            "type": "array"
          }
        ]
      },
      "SystemMessagePart": {
        "properties": {
          "cache_control": {
            "description": "(Unsupported) Cache control."
          },
          "text": {
            "description": "System prompt text.",
            "type": "string"
          },
          "type": {
            "description": "Type of the object. This is always `\"text\"`.",
            "type": "string"
          }
        },
        "required": ["type", "text"],
        "type": "object"
      },
      "TokenLogProb": {
        "properties": {
          "bytes": {
            "description": "The ASCII encoding of the output character.",
            "items": {
              "format": "int32",
              "minimum": 0,
              "type": "integer"
            },
            "type": ["array", "null"]
          },
          "logprob": {
            "description": "The log probability of returning this token.",
            "format": "float",
            "type": "number"
          },
          "token": {
            "description": "The token.",
            "type": "string"
          },
          "top_logprobs": {
            "description": "An array of the most likely tokens to return at this token position.",
            "items": {
              "$ref": "#/components/schemas/TopLogProb"
            },
            "type": "array"
          }
        },
        "required": ["token", "logprob", "top_logprobs"],
        "type": "object"
      },
      "TokenizeRequest": {
        "properties": {
          "model": {
            "description": "The model to tokenize with.",
            "type": "string"
          },
          "text": {
            "description": "The text content to be tokenized.",
            "type": "string"
          },
          "user": {
            "description": "Optional user identifier.",
            "type": ["string", "null"]
          }
        },
        "type": "object"
      },
      "TokenizeResponse": {
        "properties": {
          "token_ids": {
            "description": "A list of tokens.",
            "items": {
              "$ref": "#/components/schemas/TokenizeResponseToken"
            },
            "type": "array"
          }
        },
        "required": ["token_ids"],
        "type": "object"
      },
      "TokenizeResponseToken": {
        "properties": {
          "string_token": {
            "description": "The string of the token.",
            "type": "string"
          },
          "token_bytes": {
            "description": "The bytes that constituted the token.",
            "items": {
              "format": "int32",
              "minimum": 0,
              "type": "integer"
            },
            "type": "array"
          },
          "token_id": {
            "description": "The integer representation of the token for the model.",
            "format": "int32",
            "minimum": 0,
            "type": "integer"
          }
        },
        "required": ["token_id", "string_token", "token_bytes"],
        "type": "object"
      },
      "Tool": {
        "description": "Definition of one tool that the model can call.",
        "oneOf": [
          {
            "properties": {
              "function": {
                "$ref": "#/components/schemas/FunctionDefinition",
                "description": "Definition of tool call available to the model."
              },
              "type": {
                "enum": ["function"],
                "type": "string"
              }
            },
            "required": ["function", "type"],
            "type": "object"
          },
          {
            "properties": {
              "sources": {
                "items": {
                  "$ref": "#/components/schemas/SearchSource"
                },
                "type": "array"
              },
              "type": {
                "enum": ["live_search"],
                "type": "string"
              }
            },
            "required": ["sources", "type"],
            "type": "object"
          }
        ]
      },
      "ToolCall": {
        "properties": {
          "function": {
            "$ref": "#/components/schemas/Function",
            "description": "Function to call for the tool call."
          },
          "id": {
            "description": "A unique ID of the tool call generated by xAI. After performing tool call's function, user provides this ID with tool call's result in the subsequent request to xAI. xAI can then match the tool call result sent with tool call request.",
            "type": "string"
          },
          "index": {
            "description": "Index of the tool call.",
            "format": "int32",
            "type": ["integer", "null"]
          },
          "type": {
            "description": "Type of tool call, should always be `\"function\"`",
            "type": ["string", "null"]
          }
        },
        "required": ["id", "function"],
        "type": "object"
      },
      "ToolChoice": {
        "description": "Parameter to control how model chooses the tools.",
        "oneOf": [
          {
            "description": "Controls tool access by the model. `\"none\"` makes model ignore tools, `\"auto\"` let the model automatically decide whether to call a tool, `\"required\"` forces model to pick a tool to call.",
            "type": "string"
          },
          {
            "properties": {
              "function": {
                "oneOf": [
                  {
                    "type": "null"
                  },
                  {
                    "$ref": "#/components/schemas/FunctionChoice",
                    "description": "Name of the function to use."
                  }
                ]
              },
              "type": {
                "description": "Type is always `\"function\"`.",
                "type": "string"
              }
            },
            "required": ["type"],
            "type": "object"
          }
        ]
      },
      "TopLogProb": {
        "properties": {
          "bytes": {
            "description": "The ASCII encoding of the output character.",
            "items": {
              "format": "int32",
              "minimum": 0,
              "type": "integer"
            },
            "type": ["array", "null"]
          },
          "logprob": {
            "description": "The log probability of returning this token.",
            "format": "float",
            "type": "number"
          },
          "token": {
            "description": "The token.",
            "type": "string"
          }
        },
        "required": ["token", "logprob"],
        "type": "object"
      },
      "Usage": {
        "properties": {
          "completion_tokens": {
            "description": "Total completion token used.",
            "format": "int32",
            "type": "integer"
          },
          "completion_tokens_details": {
            "$ref": "#/components/schemas/CompletionUsageDetail",
            "description": "Breakdown of completion token usage of different types."
          },
          "num_sources_used": {
            "description": "Number of individual live search source used.",
            "format": "int32",
            "type": "integer"
          },
          "prompt_tokens": {
            "description": "Total prompt token used.",
            "format": "int32",
            "type": "integer"
          },
          "prompt_tokens_details": {
            "$ref": "#/components/schemas/PromptUsageDetail",
            "description": "Breakdown of prompt token usage of different types."
          },
          "total_tokens": {
            "description": "Total token used, the sum of prompt token and completion token amount.",
            "format": "int32",
            "type": "integer"
          }
        },
        "required": [
          "prompt_tokens",
          "completion_tokens",
          "total_tokens",
          "prompt_tokens_details",
          "completion_tokens_details",
          "num_sources_used"
        ],
        "type": "object"
      },
      "WebSearchOptions": {
        "properties": {
          "filters": {
            "description": "Only included for compatibility."
          },
          "search_context_size": {
            "default": "medium",
            "description": "This field included for compatibility reason with OpenAI's API. It is mapped to `max_search`.",
            "example": "medium",
            "type": ["string", "null"]
          },
          "user_location": {
            "description": "Only included for compatibility."
          }
        },
        "type": "object"
      }
    },
    "securitySchemes": {
      "bearerAuth": {
        "scheme": "bearer",
        "type": "http"
      }
    }
  },
  "info": {
    "description": "REST API for xAI compatible with other providers.",
    "license": {
      "name": ""
    },
    "title": "xAI's REST API",
    "version": "1.0.0"
  },
  "openapi": "3.1.0",
  "paths": {
    "/v1/api-key": {
      "get": {
        "operationId": "handle_get_api_key_info_request",
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "acls": ["api-key:model:*", "api-key:endpoint:*"],
                  "api_key_blocked": false,
                  "api_key_disabled": false,
                  "api_key_id": "ae1e1841-4326-4b36-a8a9-8a1a7237db11",
                  "create_time": "2024-01-01T12:55:18.139305Z",
                  "modified_by": "3d38b4dc-4eb7-4785-ae26-c3fa8997ffc7",
                  "modify_time": "2024-08-28T17:20:12.343321Z",
                  "name": "My API Key",
                  "redacted_api_key": "xai-...b14o",
                  "team_blocked": false,
                  "team_id": "5ea6f6bd-7815-4b8a-9135-28b2d7ba6722",
                  "user_id": "59fbe5f2-040b-46d5-8325-868bb8f23eb2"
                },
                "schema": {
                  "$ref": "#/components/schemas/ApiKey"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "Get information about an API key, including name, status, permissions and users who created or modified this key.",
        "tags": ["v1"]
      }
    },
    "/v1/chat/completions": {
      "post": {
        "operationId": "handle_generic_completion_request",
        "requestBody": {
          "content": {
            "application/json": {
              "example": {
                "messages": [
                  {
                    "content": "You are a helpful assistant that can answer questions and help with tasks.",
                    "role": "system"
                  },
                  {
                    "content": "What is 101*3?",
                    "role": "user"
                  }
                ],
                "model": "grok-4-0709"
              },
              "schema": {
                "$ref": "#/components/schemas/ChatRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "choices": [
                    {
                      "finish_reason": "stop",
                      "index": 0,
                      "message": {
                        "content": "101 multiplied by 3 is 303.",
                        "refusal": null,
                        "role": "assistant"
                      }
                    }
                  ],
                  "created": 1752854522,
                  "id": "a3d1008e-4544-40d4-d075-11527e794e4a",
                  "model": "grok-4-0709",
                  "object": "chat.completion",
                  "system_fingerprint": "fp_3a7881249c",
                  "usage": {
                    "completion_tokens": 9,
                    "completion_tokens_details": {
                      "accepted_prediction_tokens": 0,
                      "audio_tokens": 0,
                      "reasoning_tokens": 94,
                      "rejected_prediction_tokens": 0
                    },
                    "num_sources_used": 0,
                    "prompt_tokens": 32,
                    "prompt_tokens_details": {
                      "audio_tokens": 0,
                      "cached_tokens": 6,
                      "image_tokens": 0,
                      "text_tokens": 32
                    },
                    "total_tokens": 135
                  }
                },
                "schema": {
                  "$ref": "#/components/schemas/ChatResponse"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          },
          "422": {
            "description": "Unprocessable Entity. There are missing fields in the request body."
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "Create a chat response from text/image chat prompts. This is the endpoint for making requests to chat and image understanding models.",
        "tags": ["v1"]
      }
    },
    "/v1/chat/deferred-completion/{request_id}": {
      "get": {
        "operationId": "handle_get_deferred_completion_request",
        "parameters": [
          {
            "description": "The deferred request id returned by a previous deferred chat request.",
            "in": "path",
            "name": "request_id",
            "required": true,
            "schema": {
              "type": "string"
            }
          }
        ],
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "choices": [
                    {
                      "finish_reason": "stop",
                      "index": 0,
                      "message": {
                        "content": "101 multiplied by 3 is 303.",
                        "refusal": null,
                        "role": "assistant"
                      }
                    }
                  ],
                  "created": 1743770624,
                  "id": "335b92e4-afa5-48e7-b99c-b9a4eabc1c8e",
                  "model": "grok-4-0709",
                  "object": "chat.completion",
                  "system_fingerprint": "fp_156d35dcaa",
                  "usage": {
                    "completion_tokens": 11,
                    "completion_tokens_details": {
                      "accepted_prediction_tokens": 0,
                      "audio_tokens": 0,
                      "reasoning_tokens": 0,
                      "rejected_prediction_tokens": 0
                    },
                    "prompt_tokens": 31,
                    "prompt_tokens_details": {
                      "audio_tokens": 0,
                      "cached_tokens": 0,
                      "image_tokens": 0,
                      "text_tokens": 31
                    },
                    "total_tokens": 42
                  }
                },
                "schema": {
                  "$ref": "#/components/schemas/ChatResponse"
                }
              }
            },
            "description": "Success"
          },
          "202": {
            "description": "Accepted. The request is processing, but haven't been completed. You can retry at a later time."
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          },
          "404": {
            "description": "Not found. No deferred completion could be found with the given request_id."
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "Tries to fetch a result for a previously-started deferred completion. Returns `200 Success` with the response body, if the request has been completed. Returns `202 Accepted` when the request is pending processing.",
        "tags": ["v1"]
      }
    },
    "/v1/complete": {
      "post": {
        "operationId": "handle_generic_complete_request",
        "requestBody": {
          "content": {
            "application/json": {
              "example": {
                "max_tokens_to_sample": 8,
                "model": "grok-3",
                "prompt": "\n\nHuman: Hello, how are you?\n\nAssistant:",
                "temperature": 0.1
              },
              "schema": {
                "$ref": "#/components/schemas/CompleteRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "completion": " Hey there! I'm doing great, thanks",
                  "id": "982044c5-760c-4c8d-8936-f906b5cedc26",
                  "model": "grok-3",
                  "stop_reason": "max_tokens",
                  "type": "completion"
                },
                "schema": {
                  "$ref": "#/components/schemas/CompleteResponse"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          },
          "422": {
            "description": "Unprocessable Entity. There are missing fields in the request body."
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "(Legacy - Not supported by reasoning models) Create a text completion response. This endpoint is compatible with the Anthropic API.",
        "tags": ["v1"]
      }
    },
    "/v1/completions": {
      "post": {
        "operationId": "handle_sample_request",
        "requestBody": {
          "content": {
            "application/json": {
              "example": {
                "max_tokens": 3,
                "model": "grok-3",
                "prompt": "1, 2, 3, 4, "
              },
              "schema": {
                "$ref": "#/components/schemas/SampleRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "choices": [
                    {
                      "finish_reason": "length",
                      "index": 0,
                      "text": "5, "
                    }
                  ],
                  "created": 1743771779,
                  "id": "873492b3-6144-4279-ac2e-2c45242c5ce6",
                  "model": "grok-3",
                  "object": "text_completion",
                  "system_fingerprint": "fp_156d35dcaa",
                  "usage": {
                    "completion_tokens": 3,
                    "completion_tokens_details": {
                      "accepted_prediction_tokens": 0,
                      "audio_tokens": 0,
                      "reasoning_tokens": 0,
                      "rejected_prediction_tokens": 0
                    },
                    "prompt_tokens": 12,
                    "prompt_tokens_details": {
                      "audio_tokens": 0,
                      "cached_tokens": 0,
                      "image_tokens": 0,
                      "text_tokens": 12
                    },
                    "total_tokens": 15
                  }
                },
                "schema": {
                  "$ref": "#/components/schemas/SampleResponse"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          },
          "422": {
            "description": "Unprocessable Entity. There are missing fields in the request body."
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "(Legacy - Not supported by reasoning models) Create a text completion response for a given prompt. Replaced by /v1/chat/completions.",
        "tags": ["v1"]
      }
    },
    "/v1/documents/search": {
      "post": {
        "operationId": "handle_document_search_request_v2",
        "requestBody": {
          "content": {
            "application/json": {
              "example": {
                "query": "What is the revenue in the last quarter?",
                "source": {
                  "collection_ids": [
                    "collection_80100614-300c-4609-959b-a138fa90f542"
                  ]
                }
              },
              "schema": {
                "$ref": "#/components/schemas/SearchRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "matches": [
                    {
                      "chunk_content": ", deferred revenue related to such customer payments amounted to $2.10 billion and $1.77 billion, respectively, mainly due to contractual payment terms. Revenue recognized from the deferred revenue balances as of December 31, 2024 and 2023 was $944 million and $873 million for the six months ended June 30, 2025 and 2024, respectively. We have elected the practical expedient to omit disclosure of the amount of the transaction price allocated to remaining performance obligations for contracts with an original expected contract length of one year or less. As of June 30, 2025, total transaction price allocated to performance obligations that were unsatisfied or partially unsatisfied for contracts with an original expected length of more than one year was $10.38 billion. Of this amount, we expect to recognize $5.47 billion in the next 12 months and the rest over the remaining performance obligation period. Changes in government and economic incentives or tariffs may impact the transaction price or our ability to e",
                      "chunk_id": "0199717c-511b-7a80-bab3-dfe9a27f82ab",
                      "collection_ids": [
                        "collection_80100614-300c-4609-959b-a138fa90f542"
                      ],
                      "file_id": "file_ac3c5728-7399-41fc-bd62-0fef0042de9c",
                      "score": 1.1447691
                    }
                  ]
                },
                "schema": {
                  "$ref": "#/components/schemas/SearchResponse"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "Search for content related to the query within the given collections.",
        "tags": ["v1"]
      }
    },
    "/v1/embedding-models": {
      "get": {
        "operationId": "handle_embedding_models_list_request",
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "models": [
                    {
                      "aliases": [],
                      "created": 1725148800,
                      "fingerprint": "fp_df37966059",
                      "id": "v1",
                      "input_modalities": ["text"],
                      "object": "model",
                      "owned_by": "xai",
                      "prompt_image_token_price": 0,
                      "prompt_text_token_price": 100,
                      "version": "0.1.0"
                    }
                  ]
                },
                "schema": {
                  "$ref": "#/components/schemas/ListEmbeddingModelsResponse"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "List all embedding models available to the authenticating API key with full information. Additional information compared to /v1/models includes modalities, pricing, fingerprint and alias(es).",
        "tags": ["v1"]
      }
    },
    "/v1/embedding-models/{model_id}": {
      "get": {
        "operationId": "handle_embedding_model_get_request",
        "parameters": [
          {
            "description": "ID of the model to get.",
            "in": "path",
            "name": "model_id",
            "required": true,
            "schema": {
              "type": "string"
            }
          }
        ],
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "aliases": [],
                  "created": 1725148800,
                  "id": "v1",
                  "input_modalities": ["text"],
                  "object": "model",
                  "owned_by": "xai",
                  "prompt_image_token_price": 0,
                  "prompt_text_token_price": 10,
                  "version": "0.1.0"
                },
                "schema": {
                  "$ref": "#/components/schemas/EmbeddingModel"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          },
          "404": {
            "description": "Model not found"
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "Get full information about an embedding model with its model_id.",
        "tags": ["v1"]
      }
    },
    "/v1/embeddings": {
      "post": {
        "operationId": "handle_embedding_request",
        "requestBody": {
          "content": {
            "application/json": {
              "example": "{\n            \"input\": [\"This is an example content to embed...\"],\n            \"model\": \"v1\",\n            \"encoding_format\": \"float\"\n        }",
              "schema": {
                "$ref": "#/components/schemas/EmbeddingRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "data": [
                    {
                      "embedding": [0.01567895, 0.063257694, 0.045925662],
                      "index": 0,
                      "object": "embedding"
                    }
                  ],
                  "model": "v1",
                  "object": "list",
                  "usage": {
                    "prompt_tokens": 1,
                    "total_tokens": 1
                  }
                },
                "schema": {
                  "$ref": "#/components/schemas/EmbeddingResponse"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          },
          "422": {
            "description": "Unprocessable Entity. There are missing fields in the request body."
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "Create an embedding vector representation corresponding to the input text. This is the endpoint for making requests to embedding models.",
        "tags": ["v1"]
      }
    },
    "/v1/image-generation-models": {
      "get": {
        "operationId": "handle_image_generation_models_list_request",
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "models": [
                    {
                      "aliases": [],
                      "created": 1738961600,
                      "fingerprint": "fp_ca78641a52",
                      "generated_image_token_price": 100000,
                      "id": "grok-2-image",
                      "max_prompt_length": 1024,
                      "object": "model",
                      "owned_by": "xai",
                      "prompt_image_token_price": 100000,
                      "prompt_text_token_price": 100000,
                      "version": "1.0.0"
                    }
                  ]
                },
                "schema": {
                  "$ref": "#/components/schemas/ListImageGenerationModelsResponse"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "List all image generation models available to the authenticating API key with full information. Additional information compared to /v1/models includes modalities, pricing, fingerprint and alias(es).",
        "tags": ["v1"]
      }
    },
    "/v1/image-generation-models/{model_id}": {
      "get": {
        "operationId": "handle_image_generation_model_get_request",
        "parameters": [
          {
            "description": "ID of the model to get.",
            "in": "path",
            "name": "model_id",
            "required": true,
            "schema": {
              "type": "string"
            }
          }
        ],
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "aliases": [],
                  "created": 1737961600,
                  "fingerprint": "fp_ca78641a52",
                  "generated_image_token_price": 100000,
                  "id": "grok-2-image",
                  "max_prompt_length": 1024,
                  "object": "model",
                  "owned_by": "xai",
                  "prompt_image_token_price": 100000,
                  "prompt_text_token_price": 100000,
                  "version": "1.0.0"
                },
                "schema": {
                  "$ref": "#/components/schemas/ImageGenerationModel"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          },
          "404": {
            "description": "Model not found"
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "Get full information about an image generation model with its model_id.",
        "tags": ["v1"]
      }
    },
    "/v1/images/generations": {
      "post": {
        "operationId": "handle_generate_image_request",
        "requestBody": {
          "content": {
            "application/json": {
              "example": {
                "model": "grok-2-image",
                "n": 2,
                "prompt": "A cat in a tree",
                "response_format": "url"
              },
              "schema": {
                "$ref": "#/components/schemas/GenerateImageRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "data": [
                    {
                      "revised_prompt": "A high-resolution photograph of a cat perched on a branch in a lush, green tree during the daytime. The cat, possibly a tabby with distinctive fur patterns, is the central focus of the image, looking curiously forward with its fur slightly ruffled. The background features a serene park setting with other trees and a clear sky, ensuring no distractions from the main subject. The lighting is soft and natural, enhancing the realistic and calm atmosphere of the scene.<|separator|><|eos|>",
                      "url": "..."
                    },
                    {
                      "revised_prompt": "1. A high-resolution photograph of a gray tabby cat perched on a branch of a lush, green tree in a suburban backyard during the day. The cat is facing forward, with its fur slightly ruffled by a gentle breeze. The background features other trees and a distant house, all slightly out of focus to emphasize the cat. The lighting is natural, with sunlight filtering through the leaves, creating a serene and realistic setting. The composition focuses primarily on the cat, ensuring it remains the central subject of the image.<|separator|><|eos|>",
                      "url": "..."
                    }
                  ]
                },
                "schema": {
                  "$ref": "#/components/schemas/GeneratedImageResponse"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          },
          "422": {
            "description": "Unprocessable Entity. There are missing fields in the request body."
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "Generate an image based on a prompt. This is the endpoint for making generation requests to image generation models.",
        "tags": ["v1"]
      }
    },
    "/v1/language-models": {
      "get": {
        "operationId": "handle_language_models_list_request",
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "models": [
                    {
                      "aliases": ["grok-3-latest", "grok-3-beta"],
                      "cached_prompt_text_token_price": 7500,
                      "completion_text_token_price": 150000,
                      "created": 1743724800,
                      "fingerprint": "fp_898ae9f31c",
                      "id": "grok-3",
                      "input_modalities": ["text"],
                      "object": "model",
                      "output_modalities": ["text"],
                      "owned_by": "xai",
                      "prompt_image_token_price": 0,
                      "prompt_text_token_price": 30000,
                      "search_price": 250000000,
                      "version": "1.0"
                    },
                    {
                      "aliases": ["grok-3-mini-latest", "grok-3-mini-beta"],
                      "cached_prompt_text_token_price": 750,
                      "completion_text_token_price": 5000,
                      "created": 1743724800,
                      "fingerprint": "fp_6a09108ff5",
                      "id": "grok-3-mini",
                      "input_modalities": ["text"],
                      "object": "model",
                      "output_modalities": ["text"],
                      "owned_by": "xai",
                      "prompt_image_token_price": 0,
                      "prompt_text_token_price": 3000,
                      "search_price": 250000000,
                      "version": "1.0"
                    },
                    {
                      "aliases": [],
                      "completion_text_token_price": 100000,
                      "created": 1733961600,
                      "fingerprint": "fp_daba7546e5",
                      "id": "grok-2-vision-1212",
                      "input_modalities": ["text", "image"],
                      "object": "model",
                      "output_modalities": ["text"],
                      "owned_by": "xai",
                      "prompt_image_token_price": 20000,
                      "prompt_text_token_price": 20000,
                      "version": "0.1.0"
                    }
                  ]
                },
                "schema": {
                  "$ref": "#/components/schemas/ListLanguageModelsResponse"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "List all chat and image understanding models available to the authenticating API key with full information. Additional information compared to /v1/models includes modalities, pricing, fingerprint and alias(es).",
        "tags": ["v1"]
      }
    },
    "/v1/language-models/{model_id}": {
      "get": {
        "operationId": "handle_language_model_get_request",
        "parameters": [
          {
            "description": "ID of the model to get.",
            "in": "path",
            "name": "model_id",
            "required": true,
            "schema": {
              "type": "string"
            }
          }
        ],
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "aliases": ["grok-4", "grok-4-latest"],
                  "cached_prompt_text_token_price": 0,
                  "completion_text_token_price": 100000,
                  "created": 1743724800,
                  "fingerprint": "fp_156d35dcaa",
                  "id": "grok-4-0709",
                  "input_modalities": ["text"],
                  "object": "model",
                  "output_modalities": ["text"],
                  "owned_by": "xai",
                  "prompt_image_token_price": 0,
                  "prompt_text_token_price": 20000,
                  "version": "1.0.0"
                },
                "schema": {
                  "$ref": "#/components/schemas/LanguageModel"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          },
          "404": {
            "description": "Model not found"
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "Get full information about a chat or image understanding model with its model_id.",
        "tags": ["v1"]
      }
    },
    "/v1/messages": {
      "post": {
        "operationId": "handle_generic_messages_request",
        "requestBody": {
          "content": {
            "application/json": {
              "example": {
                "max_tokens": 32,
                "messages": [
                  {
                    "content": "Hello, world",
                    "role": "user"
                  }
                ],
                "model": "grok-4-0709"
              },
              "schema": {
                "$ref": "#/components/schemas/MessageRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "content": [
                    {
                      "text": "Hello there! \"Hello, world\" is a classic, isn't it? Whether you're just saying hi or channeling your inner coder, I'm happy to greet you back",
                      "type": "text"
                    }
                  ],
                  "id": "4f224bfb-9d53-4c82-b40a-b7cd80831ec2",
                  "model": "grok-4-0709",
                  "role": "assistant",
                  "stop_reason": "max_tokens",
                  "stop_sequence": null,
                  "type": "message",
                  "usage": {
                    "cache_creation_input_tokens": 0,
                    "cache_read_input_tokens": 0,
                    "input_tokens": 9,
                    "output_tokens": 32
                  }
                },
                "schema": {
                  "$ref": "#/components/schemas/MessageResponse"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          },
          "422": {
            "description": "Unprocessable Entity. There are missing fields in the request body."
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "Create a messages response. This endpoint is compatible with the Anthropic API.",
        "tags": ["v1"]
      }
    },
    "/v1/models": {
      "get": {
        "operationId": "handle_models_list_request",
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "data": [
                    {
                      "created": 1752019200,
                      "id": "grok-4-0709",
                      "object": "model",
                      "owned_by": "xai"
                    },
                    {
                      "created": 1755993600,
                      "id": "grok-code-fast-1",
                      "object": "model",
                      "owned_by": "xai"
                    },
                    {
                      "created": 1743724800,
                      "id": "grok-3",
                      "object": "model",
                      "owned_by": "xai"
                    },
                    {
                      "created": 1743724800,
                      "id": "grok-3-mini",
                      "object": "model",
                      "owned_by": "xai"
                    },
                    {
                      "created": 1736726400,
                      "id": "grok-2-image-1212",
                      "object": "model",
                      "owned_by": "xai"
                    },
                    {
                      "created": 1733961600,
                      "id": "grok-2-vision-1212",
                      "object": "model",
                      "owned_by": "xai"
                    }
                  ],
                  "object": "list"
                },
                "schema": {
                  "$ref": "#/components/schemas/ListModelsResponse"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "List all models available to the authenticating API key with minimalized information, including model names (ID), creation times, etc.",
        "tags": ["v1"]
      }
    },
    "/v1/models/{model_id}": {
      "get": {
        "operationId": "handle_model_get_request",
        "parameters": [
          {
            "description": "ID of the model to get.",
            "in": "path",
            "name": "model_id",
            "required": true,
            "schema": {
              "type": "string"
            }
          }
        ],
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "created": 1743724800,
                  "id": "grok-4-0709",
                  "object": "model",
                  "owned_by": "xai"
                },
                "schema": {
                  "$ref": "#/components/schemas/Model"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          },
          "404": {
            "description": "Model not found"
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "Get minimalized information about a model with its model_id.",
        "tags": ["v1"]
      }
    },
    "/v1/responses": {
      "post": {
        "operationId": "handle_generic_model_request",
        "requestBody": {
          "content": {
            "application/json": {
              "example": {
                "input": [
                  {
                    "content": "You are a helpful assistant that can answer questions and help with tasks.",
                    "role": "system"
                  },
                  {
                    "content": "What is 101*3?",
                    "role": "user"
                  }
                ],
                "model": "grok-4-0709"
              },
              "schema": {
                "$ref": "#/components/schemas/ModelRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "created_at": 1754475266,
                  "id": "ad5663da-63e6-86c6-e0be-ff15effa8357",
                  "incomplete_details": null,
                  "max_output_tokens": null,
                  "model": "grok-4-0709",
                  "object": "response",
                  "output": [
                    {
                      "content": [
                        {
                          "annotations": [],
                          "logprobs": null,
                          "text": "101 multiplied by 3 is 303.",
                          "type": "output_text"
                        }
                      ],
                      "id": "msg_ad5663da-63e6-86c6-e0be-ff15effa8357",
                      "role": "assistant",
                      "status": "completed",
                      "type": "message"
                    }
                  ],
                  "parallel_tool_calls": true,
                  "previous_response_id": null,
                  "reasoning": null,
                  "status": "completed",
                  "store": true,
                  "temperature": null,
                  "text": {
                    "format": {
                      "type": "text"
                    }
                  },
                  "tool_choice": "auto",
                  "tools": [],
                  "top_p": null,
                  "usage": {
                    "completion_tokens": 9,
                    "completion_tokens_details": {
                      "accepted_prediction_tokens": 0,
                      "audio_tokens": 0,
                      "reasoning_tokens": 110,
                      "rejected_prediction_tokens": 0
                    },
                    "num_sources_used": 0,
                    "prompt_tokens": 32,
                    "prompt_tokens_details": {
                      "audio_tokens": 0,
                      "cached_tokens": 8,
                      "image_tokens": 0,
                      "text_tokens": 32
                    },
                    "total_tokens": 151
                  },
                  "user": null
                },
                "schema": {
                  "$ref": "#/components/schemas/ModelResponse"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          },
          "422": {
            "description": "Unprocessable Entity. There are missing fields in the request body."
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "Generates a response based on text or image prompts. The response ID can be used to retrieve the response later or to continue the conversation without repeating prior context. New responses will be stored for 30 days and then permanently deleted.",
        "tags": ["v1"]
      }
    },
    "/v1/responses/{response_id}": {
      "delete": {
        "operationId": "handle_delete_stored_completion_request",
        "parameters": [
          {
            "description": "The response id returned by a previous create response request.",
            "in": "path",
            "name": "response_id",
            "required": true,
            "schema": {
              "type": "string"
            }
          }
        ],
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "deleted": true,
                  "id": "ad5663da-63e6-86c6-e0be-ff15effa8357",
                  "object": "response"
                },
                "schema": {
                  "$ref": "#/components/schemas/DeleteStoredCompletionResponse"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          },
          "404": {
            "description": "Not found. No responses could be found with the given response_id."
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "Delete a previously generated response.",
        "tags": ["v1"]
      },
      "get": {
        "operationId": "handle_get_stored_completion_request",
        "parameters": [
          {
            "description": "The response id returned by a previous create response request.",
            "in": "path",
            "name": "response_id",
            "required": true,
            "schema": {
              "type": "string"
            }
          }
        ],
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "created_at": 1754475266,
                  "id": "ad5663da-63e6-86c6-e0be-ff15effa8357",
                  "incomplete_details": null,
                  "max_output_tokens": null,
                  "model": "grok-4-0709",
                  "object": "response",
                  "output": [
                    {
                      "content": [
                        {
                          "annotations": [],
                          "logprobs": null,
                          "text": "101 multiplied by 3 is 303.",
                          "type": "output_text"
                        }
                      ],
                      "id": "msg_ad5663da-63e6-86c6-e0be-ff15effa8357",
                      "role": "assistant",
                      "status": "completed",
                      "type": "message"
                    },
                    {
                      "id": "",
                      "status": "completed",
                      "summary": [
                        {
                          "text": "First, the user asked: \"What is 101*3?\"\n\nThis is a simple multiplication: 101 multiplied by 3.\n\nCalculating: 100 * 3 = 300, and 1 * 3 = 3, so 300 + 3 = 303.\n\nI should respond helpfully and directly, as per my system prompt: \"You are a helpful assistant that can answer questions and help with tasks.\"\n\nKeep the response concise and accurate. No need for extra fluff unless it adds value.\n\nFinal answer: 303.",
                          "type": "summary_text"
                        }
                      ],
                      "type": "reasoning"
                    }
                  ],
                  "parallel_tool_calls": true,
                  "previous_response_id": null,
                  "reasoning": null,
                  "status": "completed",
                  "store": true,
                  "temperature": null,
                  "text": {
                    "format": {
                      "type": "text"
                    }
                  },
                  "tool_choice": "auto",
                  "tools": [],
                  "top_p": null,
                  "usage": {
                    "completion_tokens": 9,
                    "completion_tokens_details": {
                      "accepted_prediction_tokens": 0,
                      "audio_tokens": 0,
                      "reasoning_tokens": 110,
                      "rejected_prediction_tokens": 0
                    },
                    "num_sources_used": 0,
                    "prompt_tokens": 32,
                    "prompt_tokens_details": {
                      "audio_tokens": 0,
                      "cached_tokens": 8,
                      "image_tokens": 0,
                      "text_tokens": 32
                    },
                    "total_tokens": 151
                  },
                  "user": null
                },
                "schema": {
                  "$ref": "#/components/schemas/ModelResponse"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          },
          "404": {
            "description": "Not found. No responses could be found with the given response_id."
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "Retrieve a previously generated response.",
        "tags": ["v1"]
      }
    },
    "/v1/tokenize-text": {
      "post": {
        "operationId": "handle_tokenize_text_request",
        "requestBody": {
          "content": {
            "application/json": {
              "example": {
                "model": "grok-4-0709",
                "text": "Hello world!"
              },
              "schema": {
                "$ref": "#/components/schemas/TokenizeRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "content": {
              "application/json": {
                "example": {
                  "token_ids": [
                    {
                      "string_token": "Hello",
                      "token_bytes": [72, 101, 108, 108, 111],
                      "token_id": 13902
                    },
                    {
                      "string_token": " world",
                      "token_bytes": [32, 119, 111, 114, 108, 100],
                      "token_id": 1749
                    },
                    {
                      "string_token": "!",
                      "token_bytes": [33],
                      "token_id": 161
                    }
                  ]
                },
                "schema": {
                  "$ref": "#/components/schemas/TokenizeResponse"
                }
              }
            },
            "description": "Success"
          },
          "400": {
            "description": "Bad request. The request is invalid or an invalid API key is provided."
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ],
        "summary": "Tokenize text with the specified model",
        "tags": ["v1"]
      }
    }
  }
}
