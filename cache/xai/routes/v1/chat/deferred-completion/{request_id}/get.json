{
  "operationId": "handle_get_deferred_completion_request",
  "parameters": [
    {
      "description": "The deferred request id returned by a previous deferred chat request.",
      "in": "path",
      "name": "request_id",
      "required": true,
      "schema": {
        "type": "string"
      }
    }
  ],
  "responses": {
    "200": {
      "content": {
        "application/json": {
          "example": {
            "choices": [
              {
                "finish_reason": "stop",
                "index": 0,
                "message": {
                  "content": "101 multiplied by 3 is 303.",
                  "refusal": null,
                  "role": "assistant"
                }
              }
            ],
            "created": 1743770624,
            "id": "335b92e4-afa5-48e7-b99c-b9a4eabc1c8e",
            "model": "grok-4-0709",
            "object": "chat.completion",
            "system_fingerprint": "fp_156d35dcaa",
            "usage": {
              "completion_tokens": 11,
              "completion_tokens_details": {
                "accepted_prediction_tokens": 0,
                "audio_tokens": 0,
                "reasoning_tokens": 0,
                "rejected_prediction_tokens": 0
              },
              "prompt_tokens": 31,
              "prompt_tokens_details": {
                "audio_tokens": 0,
                "cached_tokens": 0,
                "image_tokens": 0,
                "text_tokens": 31
              },
              "total_tokens": 42
            }
          },
          "schema": {
            "description": "The chat response body for `/v1/chat/completions` endpoint.",
            "properties": {
              "choices": {
                "description": "A list of response choices from the model. The length corresponds to the `n` in request body (default to 1).",
                "items": {
                  "properties": {
                    "finish_reason": {
                      "description": "Finish reason. `\"stop\"` means the inference has reached a model-defined or user-supplied stop sequence in `stop`. `\"length\"` means the inference result has reached models' maximum allowed token length or user defined value in `max_tokens`. `\"end_turn\"` or `null` in streaming mode when the chunk is not the last.",
                      "type": [
                        "string",
                        "null"
                      ]
                    },
                    "index": {
                      "description": "Index of the choice within the response choices, starting from 0.",
                      "format": "int32",
                      "type": "integer"
                    },
                    "logprobs": {
                      "oneOf": [
                        {
                          "type": "null"
                        },
                        {
                          "description": "The log probabilities of each output token returned in the content of message.",
                          "properties": {
                            "content": {
                              "description": "An array the log probabilities of each output token returned.",
                              "items": {
                                "properties": {
                                  "bytes": {
                                    "description": "The ASCII encoding of the output character.",
                                    "items": {
                                      "format": "int32",
                                      "minimum": 0,
                                      "type": "integer"
                                    },
                                    "type": [
                                      "array",
                                      "null"
                                    ]
                                  },
                                  "logprob": {
                                    "description": "The log probability of returning this token.",
                                    "format": "float",
                                    "type": "number"
                                  },
                                  "token": {
                                    "description": "The token.",
                                    "type": "string"
                                  },
                                  "top_logprobs": {
                                    "description": "An array of the most likely tokens to return at this token position.",
                                    "items": {
                                      "properties": {
                                        "bytes": {
                                          "description": "The ASCII encoding of the output character.",
                                          "items": {
                                            "format": "int32",
                                            "minimum": 0,
                                            "type": "integer"
                                          },
                                          "type": [
                                            "array",
                                            "null"
                                          ]
                                        },
                                        "logprob": {
                                          "description": "The log probability of returning this token.",
                                          "format": "float",
                                          "type": "number"
                                        },
                                        "token": {
                                          "description": "The token.",
                                          "type": "string"
                                        }
                                      },
                                      "required": [
                                        "token",
                                        "logprob"
                                      ],
                                      "type": "object"
                                    },
                                    "type": "array"
                                  }
                                },
                                "required": [
                                  "token",
                                  "logprob",
                                  "top_logprobs"
                                ],
                                "type": "object"
                              },
                              "type": [
                                "array",
                                "null"
                              ]
                            }
                          },
                          "type": "object"
                        }
                      ]
                    },
                    "message": {
                      "description": "The generated chat completion message.",
                      "properties": {
                        "content": {
                          "description": "The content of the message.",
                          "type": [
                            "string",
                            "null"
                          ]
                        },
                        "reasoning_content": {
                          "description": "The reasoning trace generated by the model.",
                          "type": [
                            "string",
                            "null"
                          ]
                        },
                        "refusal": {
                          "description": "The reason given by model if the model is unable to generate a response. null if model is able to generate.",
                          "type": [
                            "string",
                            "null"
                          ]
                        },
                        "role": {
                          "description": "The role that the message belongs to, the response from model is always `\"assistant\"`.",
                          "type": "string"
                        },
                        "tool_calls": {
                          "description": "A list of tool calls asked by model for user to perform.",
                          "items": {
                            "properties": {
                              "function": {
                                "description": "Function to call for the tool call.",
                                "properties": {
                                  "arguments": {
                                    "type": "string"
                                  },
                                  "name": {
                                    "type": "string"
                                  }
                                },
                                "required": [
                                  "name",
                                  "arguments"
                                ],
                                "type": "object"
                              },
                              "id": {
                                "description": "A unique ID of the tool call generated by xAI. After performing tool call's function, user provides this ID with tool call's result in the subsequent request to xAI. xAI can then match the tool call result sent with tool call request.",
                                "type": "string"
                              },
                              "index": {
                                "description": "Index of the tool call.",
                                "format": "int32",
                                "type": [
                                  "integer",
                                  "null"
                                ]
                              },
                              "type": {
                                "description": "Type of tool call, should always be `\"function\"`",
                                "type": [
                                  "string",
                                  "null"
                                ]
                              }
                            },
                            "required": [
                              "id",
                              "function"
                            ],
                            "type": "object"
                          },
                          "type": [
                            "array",
                            "null"
                          ]
                        }
                      },
                      "required": [
                        "role"
                      ],
                      "type": "object"
                    }
                  },
                  "required": [
                    "index",
                    "message"
                  ],
                  "type": "object"
                },
                "type": "array"
              },
              "citations": {
                "description": "List of all the external pages used by the model to answer.",
                "items": {
                  "type": "string"
                },
                "type": [
                  "array",
                  "null"
                ]
              },
              "created": {
                "description": "The chat completion creation time in Unix timestamp.",
                "format": "int64",
                "type": "integer"
              },
              "debug_output": {
                "oneOf": [
                  {
                    "type": "null"
                  },
                  {
                    "description": "Debug output. Only available to trusted testers.",
                    "properties": {
                      "attempts": {
                        "description": "Number of attempts made to the model.",
                        "format": "int32",
                        "type": "integer"
                      },
                      "cache_read_count": {
                        "description": "Number of cache reads",
                        "format": "int32",
                        "minimum": 0,
                        "type": "integer"
                      },
                      "cache_read_input_bytes": {
                        "description": "Size of cache read",
                        "format": "int64",
                        "minimum": 0,
                        "type": "integer"
                      },
                      "cache_write_count": {
                        "description": "Number of cache writes",
                        "format": "int32",
                        "minimum": 0,
                        "type": "integer"
                      },
                      "cache_write_input_bytes": {
                        "description": "Size of cache write",
                        "format": "int64",
                        "minimum": 0,
                        "type": "integer"
                      },
                      "chunks": {
                        "description": "The individual chunks returned from the pipeline of samplers.",
                        "items": {
                          "type": "string"
                        },
                        "type": "array"
                      },
                      "engine_request": {
                        "description": "JSON-serialized request sent to the inference engine.",
                        "type": "string"
                      },
                      "lb_address": {
                        "description": "The load balancer address",
                        "type": "string"
                      },
                      "prompt": {
                        "description": "The prompt sent to the model in text form.",
                        "type": "string"
                      },
                      "request": {
                        "description": "The request received from the user.",
                        "type": "string"
                      },
                      "responses": {
                        "description": "The response(s) received from the model.",
                        "items": {
                          "type": "string"
                        },
                        "type": "array"
                      },
                      "sampler_tag": {
                        "description": "The tag of the actual engines sitting behind the GTP address. Eg \"grok-4-code-eapi-lap4-unified-sblbm-0\"",
                        "type": "string"
                      }
                    },
                    "required": [
                      "attempts",
                      "request",
                      "prompt",
                      "engine_request",
                      "responses",
                      "chunks",
                      "cache_read_count",
                      "cache_read_input_bytes",
                      "cache_write_count",
                      "cache_write_input_bytes",
                      "lb_address",
                      "sampler_tag"
                    ],
                    "type": "object"
                  }
                ]
              },
              "id": {
                "description": "A unique ID for the chat response.",
                "type": "string"
              },
              "model": {
                "description": "Model ID used to create chat completion.",
                "example": "grok-4-0709",
                "type": "string"
              },
              "object": {
                "description": "The object type, which is always `\"chat.completion\"`.",
                "type": "string"
              },
              "system_fingerprint": {
                "description": "System fingerprint, used to indicate xAI system configuration changes.",
                "type": [
                  "string",
                  "null"
                ]
              },
              "usage": {
                "oneOf": [
                  {
                    "type": "null"
                  },
                  {
                    "description": "Token usage information.",
                    "properties": {
                      "completion_tokens": {
                        "description": "Total completion token used.",
                        "format": "int32",
                        "type": "integer"
                      },
                      "completion_tokens_details": {
                        "description": "Breakdown of completion token usage of different types.",
                        "properties": {
                          "accepted_prediction_tokens": {
                            "description": "The number of tokens in the prediction that appeared in the completion.",
                            "format": "int32",
                            "type": "integer"
                          },
                          "audio_tokens": {
                            "description": "Audio input tokens generated by the model.",
                            "format": "int32",
                            "type": "integer"
                          },
                          "reasoning_tokens": {
                            "description": "Tokens generated by the model for reasoning.",
                            "format": "int32",
                            "type": "integer"
                          },
                          "rejected_prediction_tokens": {
                            "description": "The number of tokens in the prediction that did not appear in the completion.",
                            "format": "int32",
                            "type": "integer"
                          }
                        },
                        "required": [
                          "reasoning_tokens",
                          "audio_tokens",
                          "accepted_prediction_tokens",
                          "rejected_prediction_tokens"
                        ],
                        "type": "object"
                      },
                      "num_sources_used": {
                        "description": "Number of individual live search source used.",
                        "format": "int32",
                        "type": "integer"
                      },
                      "prompt_tokens": {
                        "description": "Total prompt token used.",
                        "format": "int32",
                        "type": "integer"
                      },
                      "prompt_tokens_details": {
                        "description": "Breakdown of prompt token usage of different types.",
                        "properties": {
                          "audio_tokens": {
                            "description": "Audio prompt token used.",
                            "format": "int32",
                            "type": "integer"
                          },
                          "cached_tokens": {
                            "description": "Token cached by xAI from previous requests and reused for this request.",
                            "format": "int32",
                            "type": "integer"
                          },
                          "image_tokens": {
                            "description": "Image prompt token used.",
                            "format": "int32",
                            "type": "integer"
                          },
                          "text_tokens": {
                            "description": "Text prompt token used.",
                            "format": "int32",
                            "type": "integer"
                          }
                        },
                        "required": [
                          "text_tokens",
                          "audio_tokens",
                          "image_tokens",
                          "cached_tokens"
                        ],
                        "type": "object"
                      },
                      "total_tokens": {
                        "description": "Total token used, the sum of prompt token and completion token amount.",
                        "format": "int32",
                        "type": "integer"
                      }
                    },
                    "required": [
                      "prompt_tokens",
                      "completion_tokens",
                      "total_tokens",
                      "prompt_tokens_details",
                      "completion_tokens_details",
                      "num_sources_used"
                    ],
                    "type": "object"
                  }
                ]
              }
            },
            "required": [
              "id",
              "object",
              "created",
              "model",
              "choices"
            ],
            "type": "object"
          }
        }
      },
      "description": "Success"
    },
    "202": {
      "description": "Accepted. The request is processing, but haven't been completed. You can retry at a later time."
    },
    "400": {
      "description": "Bad request. The request is invalid or an invalid API key is provided."
    },
    "404": {
      "description": "Not found. No deferred completion could be found with the given request_id."
    }
  },
  "security": [
    {
      "bearerAuth": []
    }
  ],
  "summary": "Tries to fetch a result for a previously-started deferred completion. Returns `200 Success` with the response body, if the request has been completed. Returns `202 Accepted` when the request is pending processing.",
  "tags": [
    "v1"
  ]
}
