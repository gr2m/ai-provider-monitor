{
  "description": "[Legacy] Create a Text Completion.\n\nThe Text Completions API is a legacy API. We recommend using the [Messages API](https://docs.claude.com/en/api/messages) going forward.\n\nFuture models and features will not be compatible with Text Completions. See our [migration guide](https://docs.claude.com/en/api/migrating-from-text-completions-to-messages) for guidance in migrating from Text Completions to Messages.",
  "operationId": "complete_post",
  "parameters": [
    {
      "description": "The version of the Claude API you want to use.\n\nRead more about versioning and our version history [here](https://docs.claude.com/en/api/versioning).",
      "in": "header",
      "name": "anthropic-version",
      "required": false,
      "schema": {
        "description": "The version of the Claude API you want to use.\n\nRead more about versioning and our version history [here](https://docs.claude.com/en/api/versioning).",
        "title": "Anthropic-Version",
        "type": "string"
      }
    },
    {
      "description": "Optional header to specify the beta version(s) you want to use.\n\nTo use multiple betas, use a comma separated list like `beta1,beta2` or specify the header multiple times for each beta.",
      "in": "header",
      "name": "anthropic-beta",
      "required": false,
      "schema": {
        "description": "Optional header to specify the beta version(s) you want to use.\n\nTo use multiple betas, use a comma separated list like `beta1,beta2` or specify the header multiple times for each beta.",
        "items": {
          "type": "string"
        },
        "title": "Anthropic-Beta",
        "type": "string"
      }
    }
  ],
  "requestBody": {
    "content": {
      "application/json": {
        "schema": {
          "additionalProperties": false,
          "examples": [
            {
              "max_tokens_to_sample": 256,
              "model": "claude-2.1",
              "prompt": "\n\nHuman: Hello, world!\n\nAssistant:"
            }
          ],
          "properties": {
            "max_tokens_to_sample": {
              "description": "The maximum number of tokens to generate before stopping.\n\nNote that our models may stop _before_ reaching this maximum. This parameter only specifies the absolute maximum number of tokens to generate.",
              "examples": [
                256
              ],
              "minimum": 1,
              "title": "Max Tokens To Sample",
              "type": "integer"
            },
            "metadata": {
              "description": "An object describing metadata about the request.",
              "additionalProperties": false,
              "properties": {
                "user_id": {
                  "anyOf": [
                    {
                      "maxLength": 256,
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "An external identifier for the user who is associated with the request.\n\nThis should be a uuid, hash value, or other opaque identifier. Anthropic may use this id to help detect abuse. Do not include any identifying information such as name, email address, or phone number.",
                  "examples": [
                    "13803d75-b4b5-4c3e-b2a2-6f21399b021b"
                  ],
                  "title": "User Id"
                }
              },
              "title": "Metadata",
              "type": "object"
            },
            "model": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "const": "claude-3-7-sonnet-latest",
                  "description": "High-performance model with early extended thinking"
                },
                {
                  "const": "claude-3-7-sonnet-20250219",
                  "description": "High-performance model with early extended thinking"
                },
                {
                  "const": "claude-3-5-haiku-latest",
                  "description": "Fastest and most compact model for near-instant responsiveness"
                },
                {
                  "const": "claude-3-5-haiku-20241022",
                  "description": "Our fastest model"
                },
                {
                  "const": "claude-haiku-4-5",
                  "description": "Hybrid model, capable of near-instant responses and extended thinking"
                },
                {
                  "const": "claude-haiku-4-5-20251001",
                  "description": "Hybrid model, capable of near-instant responses and extended thinking"
                },
                {
                  "const": "claude-sonnet-4-20250514",
                  "description": "High-performance model with extended thinking"
                },
                {
                  "const": "claude-sonnet-4-0",
                  "description": "High-performance model with extended thinking"
                },
                {
                  "const": "claude-4-sonnet-20250514",
                  "description": "High-performance model with extended thinking"
                },
                {
                  "const": "claude-sonnet-4-5",
                  "description": "Our best model for real-world agents and coding"
                },
                {
                  "const": "claude-sonnet-4-5-20250929",
                  "description": "Our best model for real-world agents and coding"
                },
                {
                  "const": "claude-3-5-sonnet-latest",
                  "description": "Our previous most intelligent model"
                },
                {
                  "const": "claude-3-5-sonnet-20241022",
                  "description": "Our previous most intelligent model"
                },
                {
                  "const": "claude-3-5-sonnet-20240620"
                },
                {
                  "const": "claude-opus-4-0",
                  "description": "Our most capable model"
                },
                {
                  "const": "claude-opus-4-20250514",
                  "description": "Our most capable model"
                },
                {
                  "const": "claude-4-opus-20250514",
                  "description": "Our most capable model"
                },
                {
                  "const": "claude-opus-4-1-20250805",
                  "description": "Our most capable model"
                },
                {
                  "const": "claude-3-opus-latest",
                  "deprecated": true,
                  "description": "Excels at writing and complex tasks"
                },
                {
                  "const": "claude-3-opus-20240229",
                  "deprecated": true,
                  "description": "Excels at writing and complex tasks"
                },
                {
                  "const": "claude-3-haiku-20240307",
                  "description": "Our previous most fast and cost-effective"
                }
              ],
              "description": "The model that will complete your prompt.\\n\\nSee [models](https://docs.anthropic.com/en/docs/models-overview) for additional details and options.",
              "title": "Model"
            },
            "prompt": {
              "description": "The prompt that you want Claude to complete.\n\nFor proper response generation you will need to format your prompt using alternating `\\n\\nHuman:` and `\\n\\nAssistant:` conversational turns. For example:\n\n```\n\"\\n\\nHuman: {userQuestion}\\n\\nAssistant:\"\n```\n\nSee [prompt validation](https://docs.claude.com/en/api/prompt-validation) and our guide to [prompt design](https://docs.claude.com/en/docs/intro-to-prompting) for more details.",
              "examples": [
                "\n\nHuman: Hello, world!\n\nAssistant:"
              ],
              "minLength": 1,
              "title": "Prompt",
              "type": "string"
            },
            "stop_sequences": {
              "description": "Sequences that will cause the model to stop generating.\n\nOur models stop on `\"\\n\\nHuman:\"`, and may include additional built-in stop sequences in the future. By providing the stop_sequences parameter, you may include additional strings that will cause the model to stop generating.",
              "items": {
                "type": "string"
              },
              "title": "Stop Sequences",
              "type": "array"
            },
            "stream": {
              "description": "Whether to incrementally stream the response using server-sent events.\n\nSee [streaming](https://docs.claude.com/en/api/streaming) for details.",
              "title": "Stream",
              "type": "boolean"
            },
            "temperature": {
              "description": "Amount of randomness injected into the response.\n\nDefaults to `1.0`. Ranges from `0.0` to `1.0`. Use `temperature` closer to `0.0` for analytical / multiple choice, and closer to `1.0` for creative and generative tasks.\n\nNote that even with `temperature` of `0.0`, the results will not be fully deterministic.",
              "examples": [
                1
              ],
              "maximum": 1,
              "minimum": 0,
              "title": "Temperature",
              "type": "number"
            },
            "top_k": {
              "description": "Only sample from the top K options for each subsequent token.\n\nUsed to remove \"long tail\" low probability responses. [Learn more technical details here](https://towardsdatascience.com/how-to-sample-from-language-models-682bceb97277).\n\nRecommended for advanced use cases only. You usually only need to use `temperature`.",
              "examples": [
                5
              ],
              "minimum": 0,
              "title": "Top K",
              "type": "integer"
            },
            "top_p": {
              "description": "Use nucleus sampling.\n\nIn nucleus sampling, we compute the cumulative distribution over all the options for each subsequent token in decreasing probability order and cut it off once it reaches a particular probability specified by `top_p`. You should either alter `temperature` or `top_p`, but not both.\n\nRecommended for advanced use cases only. You usually only need to use `temperature`.",
              "examples": [
                0.7
              ],
              "maximum": 1,
              "minimum": 0,
              "title": "Top P",
              "type": "number"
            }
          },
          "required": [
            "max_tokens_to_sample",
            "model",
            "prompt"
          ],
          "title": "CompletionRequest",
          "type": "object"
        }
      }
    },
    "required": true
  },
  "responses": {
    "200": {
      "content": {
        "application/json": {
          "schema": {
            "example": {
              "completion": " Hello! My name is Claude.",
              "id": "compl_018CKm6gsux7P8yMcwZbeCPw",
              "model": "claude-2.1",
              "stop_reason": "stop_sequence",
              "type": "completion"
            },
            "properties": {
              "completion": {
                "description": "The resulting completion up to and excluding the stop sequences.",
                "examples": [
                  " Hello! My name is Claude."
                ],
                "title": "Completion",
                "type": "string"
              },
              "id": {
                "description": "Unique object identifier.\n\nThe format and length of IDs may change over time.",
                "title": "Id",
                "type": "string"
              },
              "model": {
                "anyOf": [
                  {
                    "type": "string"
                  },
                  {
                    "const": "claude-3-7-sonnet-latest",
                    "description": "High-performance model with early extended thinking"
                  },
                  {
                    "const": "claude-3-7-sonnet-20250219",
                    "description": "High-performance model with early extended thinking"
                  },
                  {
                    "const": "claude-3-5-haiku-latest",
                    "description": "Fastest and most compact model for near-instant responsiveness"
                  },
                  {
                    "const": "claude-3-5-haiku-20241022",
                    "description": "Our fastest model"
                  },
                  {
                    "const": "claude-haiku-4-5",
                    "description": "Hybrid model, capable of near-instant responses and extended thinking"
                  },
                  {
                    "const": "claude-haiku-4-5-20251001",
                    "description": "Hybrid model, capable of near-instant responses and extended thinking"
                  },
                  {
                    "const": "claude-sonnet-4-20250514",
                    "description": "High-performance model with extended thinking"
                  },
                  {
                    "const": "claude-sonnet-4-0",
                    "description": "High-performance model with extended thinking"
                  },
                  {
                    "const": "claude-4-sonnet-20250514",
                    "description": "High-performance model with extended thinking"
                  },
                  {
                    "const": "claude-sonnet-4-5",
                    "description": "Our best model for real-world agents and coding"
                  },
                  {
                    "const": "claude-sonnet-4-5-20250929",
                    "description": "Our best model for real-world agents and coding"
                  },
                  {
                    "const": "claude-3-5-sonnet-latest",
                    "description": "Our previous most intelligent model"
                  },
                  {
                    "const": "claude-3-5-sonnet-20241022",
                    "description": "Our previous most intelligent model"
                  },
                  {
                    "const": "claude-3-5-sonnet-20240620"
                  },
                  {
                    "const": "claude-opus-4-0",
                    "description": "Our most capable model"
                  },
                  {
                    "const": "claude-opus-4-20250514",
                    "description": "Our most capable model"
                  },
                  {
                    "const": "claude-4-opus-20250514",
                    "description": "Our most capable model"
                  },
                  {
                    "const": "claude-opus-4-1-20250805",
                    "description": "Our most capable model"
                  },
                  {
                    "const": "claude-3-opus-latest",
                    "deprecated": true,
                    "description": "Excels at writing and complex tasks"
                  },
                  {
                    "const": "claude-3-opus-20240229",
                    "deprecated": true,
                    "description": "Excels at writing and complex tasks"
                  },
                  {
                    "const": "claude-3-haiku-20240307",
                    "description": "Our previous most fast and cost-effective"
                  }
                ],
                "description": "The model that will complete your prompt.\\n\\nSee [models](https://docs.anthropic.com/en/docs/models-overview) for additional details and options.",
                "title": "Model"
              },
              "stop_reason": {
                "anyOf": [
                  {
                    "type": "string"
                  },
                  {
                    "type": "null"
                  }
                ],
                "description": "The reason that we stopped.\n\nThis may be one the following values:\n* `\"stop_sequence\"`: we reached a stop sequence â€” either provided by you via the `stop_sequences` parameter, or a stop sequence built into the model\n* `\"max_tokens\"`: we exceeded `max_tokens_to_sample` or the model's maximum",
                "examples": [
                  "stop_sequence"
                ],
                "title": "Stop Reason"
              },
              "type": {
                "const": "completion",
                "default": "completion",
                "description": "Object type.\n\nFor Text Completions, this is always `\"completion\"`.",
                "enum": [
                  "completion"
                ],
                "title": "Type",
                "type": "string"
              }
            },
            "required": [
              "completion",
              "id",
              "model",
              "stop_reason",
              "type"
            ],
            "title": "CompletionResponse",
            "type": "object"
          }
        }
      },
      "description": "Text Completion object."
    },
    "4XX": {
      "content": {
        "application/json": {
          "schema": {
            "properties": {
              "error": {
                "discriminator": {
                  "mapping": {
                    "api_error": "#/components/schemas/APIError",
                    "authentication_error": "#/components/schemas/AuthenticationError",
                    "billing_error": "#/components/schemas/BillingError",
                    "invalid_request_error": "#/components/schemas/InvalidRequestError",
                    "not_found_error": "#/components/schemas/NotFoundError",
                    "overloaded_error": "#/components/schemas/OverloadedError",
                    "permission_error": "#/components/schemas/PermissionError",
                    "rate_limit_error": "#/components/schemas/RateLimitError",
                    "timeout_error": "#/components/schemas/GatewayTimeoutError"
                  },
                  "propertyName": "type"
                },
                "oneOf": [
                  {
                    "properties": {
                      "message": {
                        "default": "Invalid request",
                        "title": "Message",
                        "type": "string"
                      },
                      "type": {
                        "const": "invalid_request_error",
                        "default": "invalid_request_error",
                        "enum": [
                          "invalid_request_error"
                        ],
                        "title": "Type",
                        "type": "string"
                      }
                    },
                    "required": [
                      "message",
                      "type"
                    ],
                    "title": "InvalidRequestError",
                    "type": "object"
                  },
                  {
                    "properties": {
                      "message": {
                        "default": "Authentication error",
                        "title": "Message",
                        "type": "string"
                      },
                      "type": {
                        "const": "authentication_error",
                        "default": "authentication_error",
                        "enum": [
                          "authentication_error"
                        ],
                        "title": "Type",
                        "type": "string"
                      }
                    },
                    "required": [
                      "message",
                      "type"
                    ],
                    "title": "AuthenticationError",
                    "type": "object"
                  },
                  {
                    "properties": {
                      "message": {
                        "default": "Billing error",
                        "title": "Message",
                        "type": "string"
                      },
                      "type": {
                        "const": "billing_error",
                        "default": "billing_error",
                        "enum": [
                          "billing_error"
                        ],
                        "title": "Type",
                        "type": "string"
                      }
                    },
                    "required": [
                      "message",
                      "type"
                    ],
                    "title": "BillingError",
                    "type": "object"
                  },
                  {
                    "properties": {
                      "message": {
                        "default": "Permission denied",
                        "title": "Message",
                        "type": "string"
                      },
                      "type": {
                        "const": "permission_error",
                        "default": "permission_error",
                        "enum": [
                          "permission_error"
                        ],
                        "title": "Type",
                        "type": "string"
                      }
                    },
                    "required": [
                      "message",
                      "type"
                    ],
                    "title": "PermissionError",
                    "type": "object"
                  },
                  {
                    "properties": {
                      "message": {
                        "default": "Not found",
                        "title": "Message",
                        "type": "string"
                      },
                      "type": {
                        "const": "not_found_error",
                        "default": "not_found_error",
                        "enum": [
                          "not_found_error"
                        ],
                        "title": "Type",
                        "type": "string"
                      }
                    },
                    "required": [
                      "message",
                      "type"
                    ],
                    "title": "NotFoundError",
                    "type": "object"
                  },
                  {
                    "properties": {
                      "message": {
                        "default": "Rate limited",
                        "title": "Message",
                        "type": "string"
                      },
                      "type": {
                        "const": "rate_limit_error",
                        "default": "rate_limit_error",
                        "enum": [
                          "rate_limit_error"
                        ],
                        "title": "Type",
                        "type": "string"
                      }
                    },
                    "required": [
                      "message",
                      "type"
                    ],
                    "title": "RateLimitError",
                    "type": "object"
                  },
                  {
                    "properties": {
                      "message": {
                        "default": "Request timeout",
                        "title": "Message",
                        "type": "string"
                      },
                      "type": {
                        "const": "timeout_error",
                        "default": "timeout_error",
                        "enum": [
                          "timeout_error"
                        ],
                        "title": "Type",
                        "type": "string"
                      }
                    },
                    "required": [
                      "message",
                      "type"
                    ],
                    "title": "GatewayTimeoutError",
                    "type": "object"
                  },
                  {
                    "properties": {
                      "message": {
                        "default": "Internal server error",
                        "title": "Message",
                        "type": "string"
                      },
                      "type": {
                        "const": "api_error",
                        "default": "api_error",
                        "enum": [
                          "api_error"
                        ],
                        "title": "Type",
                        "type": "string"
                      }
                    },
                    "required": [
                      "message",
                      "type"
                    ],
                    "title": "APIError",
                    "type": "object"
                  },
                  {
                    "properties": {
                      "message": {
                        "default": "Overloaded",
                        "title": "Message",
                        "type": "string"
                      },
                      "type": {
                        "const": "overloaded_error",
                        "default": "overloaded_error",
                        "enum": [
                          "overloaded_error"
                        ],
                        "title": "Type",
                        "type": "string"
                      }
                    },
                    "required": [
                      "message",
                      "type"
                    ],
                    "title": "OverloadedError",
                    "type": "object"
                  }
                ],
                "title": "Error"
              },
              "request_id": {
                "anyOf": [
                  {
                    "type": "string"
                  },
                  {
                    "type": "null"
                  }
                ],
                "default": null,
                "title": "Request Id"
              },
              "type": {
                "const": "error",
                "default": "error",
                "enum": [
                  "error"
                ],
                "title": "Type",
                "type": "string"
              }
            },
            "required": [
              "error",
              "request_id",
              "type"
            ],
            "title": "ErrorResponse",
            "type": "object"
          }
        }
      },
      "description": "Error response.\n\nSee our [errors documentation](https://docs.claude.com/en/api/errors) for more details."
    }
  },
  "summary": "Create a Text Completion"
}
